<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>德州扑克学习</title>
    <link href="/2023/09/25/%E5%BE%B7%E5%B7%9E%E6%89%91%E5%85%8B%E5%AD%A6%E4%B9%A0/"/>
    <url>/2023/09/25/%E5%BE%B7%E5%B7%9E%E6%89%91%E5%85%8B%E5%AD%A6%E4%B9%A0/</url>
    
    <content type="html"><![CDATA[<blockquote><p><em>博弈论的基础建立在理性人假设之上：玩家是理性且自利的</em></p></blockquote><span id="more"></span><h2 id="概率">概率</h2><blockquote><p>VScode的Markdown preview enhanced（MPE）插件支持 Mathjax 和 Katex，可以实时预览Latex公式，完全没必要花两个小时装Texlive</p></blockquote><table><thead><tr><th style="text-align:center">牌型</th><th style="text-align:center">翻牌后</th></tr></thead><tbody><tr><td style="text-align:center">Royal Flush</td><td style="text-align:center"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>4</mn><msubsup><mi>C</mi><mn>52</mn><mn>5</mn></msubsup></mfrac><mo>=</mo><mfrac><mn>1</mn><mn>649740</mn></mfrac><mo>≈</mo><mn>0.00015</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">\frac{4}{C^5_{52}} = \frac{1}{649740} \approx 0.00015\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.4367em;vertical-align:-0.5916em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.6264em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8051em;"><span style="top:-2.1885em;margin-left:-0.0715em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">52</span></span></span></span><span style="top:-2.8448em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3115em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">4</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5916em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">649740</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">0.00015%</span></span></span></span></td></tr><tr><td style="text-align:center">Straight Flush</td><td style="text-align:center"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mn>649740</mn></mfrac><mo>×</mo><mn>10</mn><mo>≈</mo><mn>0.0015</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">\frac{1}{649740} \times 10 \approx  0.0015\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">649740</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">10</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">0.0015%</span></span></span></span></td></tr><tr><td style="text-align:center">Four-of-a-Kind</td><td style="text-align:center"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mn>13</mn><mo>∗</mo><mn>48</mn></mrow><msubsup><mi>C</mi><mn>52</mn><mn>5</mn></msubsup></mfrac><mo>=</mo><mfrac><mn>1</mn><mn>4165</mn></mfrac><mo>≈</mo><mn>0.024</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">\frac{13*48}{C^5_{52}} = \frac{1}{4165} \approx 0.024\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.4367em;vertical-align:-0.5916em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.6264em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8051em;"><span style="top:-2.1885em;margin-left:-0.0715em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">52</span></span></span></span><span style="top:-2.8448em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3115em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">13</span><span class="mbin mtight">∗</span><span class="mord mtight">48</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5916em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">4165</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">0.024%</span></span></span></span></td></tr><tr><td style="text-align:center">Full House</td><td style="text-align:center"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mn>13</mn><mo>∗</mo><mn>4</mn><mo>∗</mo><mn>12</mn><mo>∗</mo><mn>6</mn></mrow><msubsup><mi>C</mi><mn>52</mn><mn>5</mn></msubsup></mfrac><mo>=</mo><mfrac><mn>1</mn><mn>694</mn></mfrac><mo>≈</mo><mn>0.144</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">\frac{13*4*12*6}{C^5_{52}} = \frac{1}{694} \approx 0.144\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.4367em;vertical-align:-0.5916em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.6264em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8051em;"><span style="top:-2.1885em;margin-left:-0.0715em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">52</span></span></span></span><span style="top:-2.8448em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3115em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">13</span><span class="mbin mtight">∗</span><span class="mord mtight">4</span><span class="mbin mtight">∗</span><span class="mord mtight">12</span><span class="mbin mtight">∗</span><span class="mord mtight">6</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5916em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">694</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">0.144%</span></span></span></span></td></tr><tr><td style="text-align:center">Flush</td><td style="text-align:center"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mn>4</mn><mo>∗</mo><msubsup><mi>C</mi><mn>13</mn><mn>5</mn></msubsup></mrow><msubsup><mi>C</mi><mn>52</mn><mn>5</mn></msubsup></mfrac><mo>≈</mo><mn>0.2</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">\frac{4*C^5_{13}}{C^5_{52}} \approx 0.2\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.7258em;vertical-align:-0.5916em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1341em;"><span style="top:-2.6264em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8051em;"><span style="top:-2.1885em;margin-left:-0.0715em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">52</span></span></span></span><span style="top:-2.8448em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3115em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.5102em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">4</span><span class="mbin mtight">∗</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.214em;margin-left:-0.0715em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">13</span></span></span></span><span style="top:-2.931em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5916em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">0.2%</span></span></span></span></td></tr><tr><td style="text-align:center">Straight</td><td style="text-align:center"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mn>10</mn><mo>∗</mo><msup><mn>4</mn><mn>5</mn></msup></mrow><msubsup><mi>C</mi><mn>52</mn><mn>5</mn></msubsup></mfrac><mo>≈</mo><mn>0.39</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">\frac{10*4^5}{C^5_{52}} \approx 0.39\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.6096em;vertical-align:-0.5916em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0179em;"><span style="top:-2.6264em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8051em;"><span style="top:-2.1885em;margin-left:-0.0715em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">52</span></span></span></span><span style="top:-2.8448em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3115em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">10</span><span class="mbin mtight">∗</span><span class="mord mtight"><span class="mord mtight">4</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.931em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">5</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5916em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">0.39%</span></span></span></span></td></tr><tr><td style="text-align:center">Three-of-a-Kind</td><td style="text-align:center"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mn>13</mn><mo>∗</mo><mn>4</mn><mo>∗</mo><msubsup><mi>C</mi><mn>12</mn><mn>2</mn></msubsup><mo>∗</mo><msup><mn>4</mn><mn>2</mn></msup></mrow><msubsup><mi>C</mi><mn>52</mn><mn>5</mn></msubsup></mfrac><mo>≈</mo><mn>2.1</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">\frac{13*4*C^2_{12}*4^2}{C^5_{52}} \approx 2.1\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.7258em;vertical-align:-0.5916em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1341em;"><span style="top:-2.6264em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8051em;"><span style="top:-2.1885em;margin-left:-0.0715em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">52</span></span></span></span><span style="top:-2.8448em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3115em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.5102em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">13</span><span class="mbin mtight">∗</span><span class="mord mtight">4</span><span class="mbin mtight">∗</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.214em;margin-left:-0.0715em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">12</span></span></span></span><span style="top:-2.931em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286em;"><span></span></span></span></span></span></span><span class="mbin mtight">∗</span><span class="mord mtight"><span class="mord mtight">4</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.931em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5916em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">2.1%</span></span></span></span></td></tr><tr><td style="text-align:center">TwoPair</td><td style="text-align:center"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><msubsup><mi>C</mi><mn>13</mn><mn>2</mn></msubsup><mo>∗</mo><msup><mn>6</mn><mn>2</mn></msup><mo>∗</mo><mn>44</mn></mrow><msubsup><mi>C</mi><mn>52</mn><mn>5</mn></msubsup></mfrac><mo>≈</mo><mn>4.75</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">\frac{C^2_{13}*6^2*44}{C^5_{52}} \approx 4.75\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.7258em;vertical-align:-0.5916em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1341em;"><span style="top:-2.6264em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8051em;"><span style="top:-2.1885em;margin-left:-0.0715em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">52</span></span></span></span><span style="top:-2.8448em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3115em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.5102em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.214em;margin-left:-0.0715em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">13</span></span></span></span><span style="top:-2.931em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286em;"><span></span></span></span></span></span></span><span class="mbin mtight">∗</span><span class="mord mtight"><span class="mord mtight">6</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.931em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mbin mtight">∗</span><span class="mord mtight">44</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5916em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">4.75%</span></span></span></span></td></tr><tr><td style="text-align:center">OnePair</td><td style="text-align:center"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mn>13</mn><mo>∗</mo><msubsup><mi>C</mi><mn>4</mn><mn>2</mn></msubsup><mo>∗</mo><msubsup><mi>C</mi><mn>12</mn><mn>3</mn></msubsup><mo>∗</mo><msup><mn>4</mn><mn>3</mn></msup></mrow><msubsup><mi>C</mi><mn>52</mn><mn>5</mn></msubsup></mfrac><mo>≈</mo><mn>42.3</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">\frac{13*C^2_{4}*C^3_{12}*4^3}{C^5_{52}} \approx 42.3\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.7258em;vertical-align:-0.5916em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1341em;"><span style="top:-2.6264em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8051em;"><span style="top:-2.1885em;margin-left:-0.0715em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">52</span></span></span></span><span style="top:-2.8448em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3115em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.5102em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">13</span><span class="mbin mtight">∗</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.214em;margin-left:-0.0715em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">4</span></span></span></span><span style="top:-2.931em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286em;"><span></span></span></span></span></span></span><span class="mbin mtight">∗</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.214em;margin-left:-0.0715em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">12</span></span></span></span><span style="top:-2.931em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286em;"><span></span></span></span></span></span></span><span class="mbin mtight">∗</span><span class="mord mtight"><span class="mord mtight">4</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.931em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5916em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">42.3%</span></span></span></span></td></tr><tr><td style="text-align:center">Single</td><td style="text-align:center"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><msubsup><mi>C</mi><mn>13</mn><mn>5</mn></msubsup><mo>∗</mo><msup><mn>4</mn><mn>5</mn></msup></mrow><msubsup><mi>C</mi><mn>52</mn><mn>5</mn></msubsup></mfrac><mo>≈</mo><mn>50.7</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">\frac{C^5_{13} * 4^5}{C^5_{52}} \approx 50.7\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.7258em;vertical-align:-0.5916em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1341em;"><span style="top:-2.6264em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8051em;"><span style="top:-2.1885em;margin-left:-0.0715em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">52</span></span></span></span><span style="top:-2.8448em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3115em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.5102em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.214em;margin-left:-0.0715em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">13</span></span></span></span><span style="top:-2.931em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286em;"><span></span></span></span></span></span></span><span class="mbin mtight">∗</span><span class="mord mtight"><span class="mord mtight">4</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.931em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">5</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5916em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">50.7%</span></span></span></span></td></tr></tbody></table><h3 id="四二法则">四二法则</h3><p>Flop后听N张牌，则最终成牌的概率约为4N%，Turn后听N张牌，则最终成牌的概率约为2N%</p><p>Flop后成牌概率为：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>−</mo><mo stretchy="false">(</mo><mfrac><mrow><mn>47</mn><mo>−</mo><mi>N</mi></mrow><mn>47</mn></mfrac><mo>×</mo><mfrac><mrow><mn>46</mn><mo>−</mo><mi>N</mi></mrow><mn>46</mn></mfrac><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mn>93</mn><mi>N</mi><mo>−</mo><msup><mi>N</mi><mn>2</mn></msup></mrow><mrow><mn>47</mn><mo>×</mo><mn>46</mn></mrow></mfrac></mrow><annotation encoding="application/x-tex">1 -(\frac{47-N }{47} \times \frac{46-N}{46} ) = \frac{93N-N^2}{47\times46}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.2173em;vertical-align:-0.345em;"></span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8723em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">47</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">47</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.2173em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8723em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">46</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">46</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.4213em;vertical-align:-0.4033em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0179em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">47</span><span class="mbin mtight">×</span><span class="mord mtight">46</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">93</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="mbin mtight">−</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.931em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4033em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><br>在Desmos中可以看出，当N在10以内时，四二法则的误差在 +1.6% 以内</p><p>Turn后成牌概率为：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mi>N</mi><mn>46</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{N}{46}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2173em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8723em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">46</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><br>当N在10以内时，误差在 -1.7% 以内</p><h3 id="翻前胜率">翻前胜率</h3><h3 id="翻后策略求解">翻后策略求解</h3><p><a href="https://github.com/bupticybee/TexasSolver">https://github.com/bupticybee/TexasSolver</a></p><h3 id="期望价值">期望价值</h3><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mi>V</mi><mo>=</mo><mtext>正向收益</mtext><mo>∗</mo><mtext>获胜概率</mtext><mo>+</mo><mtext>负向收益</mtext><mo>∗</mo><mtext>失败概率</mtext></mrow><annotation encoding="application/x-tex">EV = 正向收益 * 获胜概率 + 负向收益 * 失败概率</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord cjk_fallback">正向收益</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord cjk_fallback">获胜概率</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord cjk_fallback">负向收益</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord cjk_fallback">失败概率</span></span></span></span></p><p>即 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mi>V</mi><mo>=</mo><mi>P</mi><mi>o</mi><mi>t</mi><mo>×</mo><mi>W</mi><mi>i</mi><mi>n</mi><mi>R</mi><mi>a</mi><mi>t</mi><mi>e</mi><mo>−</mo><mi>B</mi><mi>e</mi><mi>t</mi><mo>×</mo><mi>L</mi><mi>o</mi><mi>s</mi><mi>e</mi><mi>R</mi><mi>a</mi><mi>t</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">EV = Pot \times WinRate - Bet \times LoseRate</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal">o</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">Win</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord mathnormal">e</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">L</span><span class="mord mathnormal">ose</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span></span></span></span></p><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mi>V</mi><mo>≥</mo><mn>0</mn><mo>⇔</mo><mi>B</mi><mi>e</mi><mi>t</mi><mo>≤</mo><mi>P</mi><mi>o</mi><mi>t</mi><mo>×</mo><mfrac><mrow><mi>W</mi><mi>i</mi><mi>n</mi><mi>R</mi><mi>a</mi><mi>t</mi><mi>e</mi></mrow><mrow><mn>1</mn><mo>−</mo><mi>W</mi><mi>i</mi><mi>n</mi><mi>R</mi><mi>a</mi><mi>t</mi><mi>e</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">EV \geq 0 \Leftrightarrow Bet \leq Pot \times \frac{WinRate}{1 - WinRate}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8193em;vertical-align:-0.136em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">⇔</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8193em;vertical-align:-0.136em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord mathnormal">e</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal">o</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.2757em;vertical-align:-0.4033em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8723em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight">Win</span><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">e</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">Win</span><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4033em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p><table><thead><tr><th style="text-align:center">胜率</th><th style="text-align:center">下注量(*Pot)</th></tr></thead><tbody><tr><td style="text-align:center">8%</td><td style="text-align:center">0.09</td></tr><tr><td style="text-align:center">16%</td><td style="text-align:center">0.19</td></tr><tr><td style="text-align:center">32%</td><td style="text-align:center">0.47</td></tr><tr><td style="text-align:center">50%</td><td style="text-align:center">1</td></tr><tr><td style="text-align:center">67%</td><td style="text-align:center">2</td></tr></tbody></table><h2 id="策略">策略</h2><p>参考</p><ul><li><a href="https://space.bilibili.com/2143447">https://space.bilibili.com/2143447</a></li><li><a href="https://www.youtube.com/@ronniepoker">https://www.youtube.com/@ronniepoker</a></li></ul><h2 id="GTO">GTO</h2>]]></content>
    
    
    <categories>
      
      <category>interest</category>
      
    </categories>
    
    
    <tags>
      
      <tag>德扑</tag>
      
      <tag>博弈论</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MLC学习</title>
    <link href="/2023/09/21/MLC%E5%AD%A6%E4%B9%A0/"/>
    <url>/2023/09/21/MLC%E5%AD%A6%E4%B9%A0/</url>
    
    <content type="html"><![CDATA[<p>陈天奇的MLC课程，参考<br><a href="https://github.com/BBuf/tvm_mlir_learn">https://github.com/BBuf/tvm_mlir_learn</a><br><a href="https://mlc.ai/zh/index.html">https://mlc.ai/zh/index.html</a><br><a href="https://space.bilibili.com/1663273796/channel/collectiondetail?sid=499979">https://space.bilibili.com/1663273796/channel/collectiondetail?sid=499979</a></p><span id="more"></span><h2 id="1-概述">1.概述</h2><p>定义：将机器学习的算法（模型）从开发形式（如pytorch、tf等通用框架编写的模型描述以及相关权重），通过变换和优化，转化为部署形式（如模型支撑代码、内存控制、接口等）<br>即，将神经网络模型转变成在特定硬件上运行的张量函数代码</p><p>机器学习编译目标：</p><ol><li>集成和最小化依赖</li><li>利用硬件加速：利用到每个部署环境的原生加速技术</li><li>通用优化</li></ol><h2 id="2-张量程序抽象">2. 张量程序抽象</h2><p>元张量函数：机器学习模型执行中的每一个步骤（或者说算子？），如linear、relu、softmax</p><p>许多不同的抽象可以表达同一种元张量函数，如torch.add和numpy.add，同时，有些机器学习框架也提供模型的编译过程优化，将元张量函数转变成更专门的、针对性的函数</p><p>张量程序抽象：一个典型的元张量函数实现包括：</p><ol><li>存储数据的多维数组</li><li>驱动张量计算的循环嵌套</li><li>计算语句</li></ol><p>根据抽象出来的共同特征，元张量函数因此可以被一系列有效的程序变换所改变，即优化。<br>一般情况下，我们感兴趣的大部分元张量函数都具有良好的可变换属性。</p><h3 id="TensorIR：TVM使用的张量程序抽象">TensorIR：TVM使用的张量程序抽象</h3><p>前提：大多数的机器学习编译可以视为张量函数之间的变换</p><h4 id="示例：一个经典的点积-relu-网络">示例：一个经典的点积 + relu 网络</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">dtype = <span class="hljs-string">&quot;float32&quot;</span><br>a_np = np.random.rand(<span class="hljs-number">128</span>, <span class="hljs-number">128</span>).astype(dtype)<br>b_np = np.random.rand(<span class="hljs-number">128</span>, <span class="hljs-number">128</span>).astype(dtype)<br>c_mm_relu = np.maximum(a_np @ b_np, <span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><p>在底层，numpy可能使用循环和算术运算实现上述操作：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">lnumpy_mm_relu</span>(<span class="hljs-params">A: np.ndarray, B: np.ndarray, C: np.ndarray</span>):<br>    <span class="hljs-comment"># 存储数据的多维数组</span><br>    Y = np.empty((<span class="hljs-number">128</span>, <span class="hljs-number">128</span>), dtype=<span class="hljs-string">&quot;float32&quot;</span>)<br>    <span class="hljs-comment"># 驱动张量计算的循环嵌套</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">128</span>):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">128</span>):<br>            <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">128</span>):<br>                <span class="hljs-keyword">if</span> k == <span class="hljs-number">0</span>:<br>                    Y[i, j] = <span class="hljs-number">0</span><br>                <span class="hljs-comment"># 计算语句</span><br>                Y[i, j] = Y[i, j] + A[i, k] * B[k, j]<br>    <span class="hljs-comment"># 驱动张量计算的循环嵌套</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">128</span>):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">128</span>):<br>            <span class="hljs-comment"># 计算语句</span><br>            C[i, j] = <span class="hljs-built_in">max</span>(Y[i, j], <span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><h4 id="TensorIR实现：">TensorIR实现：</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@tvm.script.ir_module</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyModule</span>:<br><span class="hljs-meta">    @T.prim_func</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">mm_relu</span>(<span class="hljs-params">A: T.Buffer(<span class="hljs-params">(<span class="hljs-params"><span class="hljs-number">128</span>, <span class="hljs-number">128</span></span>), <span class="hljs-string">&quot;float32&quot;</span></span>),</span><br><span class="hljs-params">                B: T.Buffer(<span class="hljs-params">(<span class="hljs-params"><span class="hljs-number">128</span>, <span class="hljs-number">128</span></span>), <span class="hljs-string">&quot;float32&quot;</span></span>),</span><br><span class="hljs-params">                C: T.Buffer(<span class="hljs-params">(<span class="hljs-params"><span class="hljs-number">128</span>, <span class="hljs-number">128</span></span>), <span class="hljs-string">&quot;float32&quot;</span></span>)</span>):<br>        T.func_attr(&#123;<span class="hljs-string">&quot;global_symbol&quot;</span>: <span class="hljs-string">&quot;mm_relu&quot;</span>, <span class="hljs-string">&quot;tir.noalias&quot;</span>: <span class="hljs-literal">True</span>&#125;)<br>        <span class="hljs-comment"># 存储数据的多维数组（缓冲区）</span><br>        Y = T.alloc_buffer((<span class="hljs-number">128</span>, <span class="hljs-number">128</span>), dtype=<span class="hljs-string">&quot;float32&quot;</span>)<br>        <span class="hljs-comment"># 驱动张量计算的循环嵌套</span><br>        <span class="hljs-keyword">for</span> i, j, k <span class="hljs-keyword">in</span> T.grid(<span class="hljs-number">128</span>, <span class="hljs-number">128</span>, <span class="hljs-number">128</span>):<br>            <span class="hljs-comment"># 计算语句</span><br>            <span class="hljs-keyword">with</span> T.block(<span class="hljs-string">&quot;Y&quot;</span>):<br>                vi = T.axis.spatial(<span class="hljs-number">128</span>, i)<br>                vj = T.axis.spatial(<span class="hljs-number">128</span>, j)<br>                vk = T.axis.reduce(<span class="hljs-number">128</span>, k)<br>                <span class="hljs-keyword">with</span> T.init():<br>                    Y[vi, vj] = T.float32(<span class="hljs-number">0</span>)<br>                Y[vi, vj] = Y[vi, vj] + A[vi, vk] * B[vk, vj]<br>        <span class="hljs-comment"># 驱动张量计算的循环嵌套</span><br>        <span class="hljs-keyword">for</span> i, j <span class="hljs-keyword">in</span> T.grid(<span class="hljs-number">128</span>, <span class="hljs-number">128</span>):<br>            <span class="hljs-comment"># 计算语句</span><br>            <span class="hljs-keyword">with</span> T.block(<span class="hljs-string">&quot;C&quot;</span>):<br>                vi = T.axis.spatial(<span class="hljs-number">128</span>, i)<br>                vj = T.axis.spatial(<span class="hljs-number">128</span>, j)<br>                C[vi, vj] = T.<span class="hljs-built_in">max</span>(Y[vi, vj], T.float32(<span class="hljs-number">0</span>))<br></code></pre></td></tr></table></figure><p>块是tensorIR的基本计算单位。定义如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">[block_axis] = T.axis.[axis_type]([axis_range], [mapped_value])<br></code></pre></td></tr></table></figure><p>如<code>vi = T.axis.spatial(128, i)</code> 即表示vi为i的映射，范围为(0,128)，且该块轴属性为spatial（空间轴），而vk的属性则为reduce规约轴。（可以理解为空间轴是原本就在的，规约轴是在上面做滑动的）</p><p>块轴加属性的好处是使得vi，vj，vk独立于外部的循环嵌套i，j，k，同时也对外部循环正确性做了二次验证。同时这些附加信息也有助于机器学习编译分析，比如说，我们总是可以在空间轴上做并行化，但在规约轴上做并行化则需要特定的策略</p><pre><code class="hljs">如果觉得自定义属性比较麻烦也可以一键绑定</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># SSR means the properties of each axes are &quot;spatial&quot;, &quot;spatial&quot;, &quot;reduce&quot;</span><br>vi, vj, vk = T.axis.remap(<span class="hljs-string">&quot;SSR&quot;</span>, [i, j, k])<br></code></pre></td></tr></table></figure><h4 id="tensorIR的元张量函数变换">tensorIR的元张量函数变换</h4><p>tensorIR引入了名为Schedule的辅助结构，允许我们进行方便的元张量函数变换</p><p>这是原来的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> IPython<br>IPython.display.Code(MyModule.script(), language=<span class="hljs-string">&quot;python&quot;</span>)<br><br><span class="hljs-comment"># from tvm.script import ir as I</span><br><span class="hljs-comment"># from tvm.script import tir as T</span><br><span class="hljs-meta">@I.ir_module</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Module</span>:<br><span class="hljs-meta">    @T.prim_func</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">mm_relu</span>(<span class="hljs-params">A: T.Buffer(<span class="hljs-params">(<span class="hljs-params"><span class="hljs-number">128</span>, <span class="hljs-number">128</span></span>), <span class="hljs-string">&quot;float32&quot;</span></span>), B: T.Buffer(<span class="hljs-params">(<span class="hljs-params"><span class="hljs-number">128</span>, <span class="hljs-number">128</span></span>), <span class="hljs-string">&quot;float32&quot;</span></span>), C: T.Buffer(<span class="hljs-params">(<span class="hljs-params"><span class="hljs-number">128</span>, <span class="hljs-number">128</span></span>), <span class="hljs-string">&quot;float32&quot;</span></span>)</span>):<br>        T.func_attr(&#123;<span class="hljs-string">&quot;global_symbol&quot;</span>: <span class="hljs-string">&quot;mm_relu&quot;</span>, <span class="hljs-string">&quot;tir.noalias&quot;</span>: <span class="hljs-literal">True</span>&#125;)<br>        <span class="hljs-comment"># with T.block(&quot;root&quot;):</span><br>        Y = T.alloc_buffer((<span class="hljs-number">128</span>, <span class="hljs-number">128</span>))<br>        <span class="hljs-keyword">for</span> i, j, k <span class="hljs-keyword">in</span> T.grid(<span class="hljs-number">128</span>, <span class="hljs-number">128</span>, <span class="hljs-number">128</span>):<br>            <span class="hljs-keyword">with</span> T.block(<span class="hljs-string">&quot;Y&quot;</span>):<br>                vi, vj, vk = T.axis.remap(<span class="hljs-string">&quot;SSR&quot;</span>, [i, j, k])<br>                T.reads(A[vi, vk], B[vk, vj])<br>                T.writes(Y[vi, vj])<br>                <span class="hljs-keyword">with</span> T.init():<br>                    Y[vi, vj] = T.float32(<span class="hljs-number">0</span>)<br>                Y[vi, vj] = Y[vi, vj] + A[vi, vk] * B[vk, vj]<br>        <span class="hljs-keyword">for</span> i, j <span class="hljs-keyword">in</span> T.grid(<span class="hljs-number">128</span>, <span class="hljs-number">128</span>):<br>            <span class="hljs-keyword">with</span> T.block(<span class="hljs-string">&quot;C&quot;</span>):<br>                vi, vj = T.axis.remap(<span class="hljs-string">&quot;SS&quot;</span>, [i, j])<br>                T.reads(Y[vi, vj])<br>                T.writes(C[vi, vj])<br>                C[vi, vj] = T.<span class="hljs-built_in">max</span>(Y[vi, vj], T.float32(<span class="hljs-number">0</span>))<br></code></pre></td></tr></table></figure><p>使用Schedule进行变换：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">## 以给定的module作为输入的辅助Schedule类</span><br>sch = tvm.tir.Schedule(MyModule)<br><span class="hljs-comment"># 获取对应的块及相应循环的引用</span><br>block_Y = sch.get_block(<span class="hljs-string">&quot;Y&quot;</span>, func_name=<span class="hljs-string">&quot;mm_relu&quot;</span>)<br>i, j, k = sch.get_loops(block_Y)<br><span class="hljs-comment"># 变换：将原有的j循环拆分成两个循环（4表示内部循环长度）</span><br>j0, j1 = sch.split(j, factors=[<span class="hljs-literal">None</span>, <span class="hljs-number">4</span>])<br><span class="hljs-comment"># 再次检查结果</span><br>IPython.display.Code(sch.mod.script(), language=<span class="hljs-string">&quot;python&quot;</span>)<br><br><span class="hljs-meta">@I.ir_module</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Module</span>:<br><span class="hljs-meta">    @T.prim_func</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">mm_relu</span>(<span class="hljs-params">A: T.Buffer(<span class="hljs-params">(<span class="hljs-params"><span class="hljs-number">128</span>, <span class="hljs-number">128</span></span>), <span class="hljs-string">&quot;float32&quot;</span></span>), B: T.Buffer(<span class="hljs-params">(<span class="hljs-params"><span class="hljs-number">128</span>, <span class="hljs-number">128</span></span>), <span class="hljs-string">&quot;float32&quot;</span></span>), C: T.Buffer(<span class="hljs-params">(<span class="hljs-params"><span class="hljs-number">128</span>, <span class="hljs-number">128</span></span>), <span class="hljs-string">&quot;float32&quot;</span></span>)</span>):<br>        T.func_attr(&#123;<span class="hljs-string">&quot;global_symbol&quot;</span>: <span class="hljs-string">&quot;mm_relu&quot;</span>, <span class="hljs-string">&quot;tir.noalias&quot;</span>: <span class="hljs-literal">True</span>&#125;)<br>        <span class="hljs-comment"># with T.block(&quot;root&quot;):</span><br>        Y = T.alloc_buffer((<span class="hljs-number">128</span>, <span class="hljs-number">128</span>))<br>        <span class="hljs-keyword">for</span> i, j_0, j_1, k <span class="hljs-keyword">in</span> T.grid(<span class="hljs-number">128</span>, <span class="hljs-number">32</span>, <span class="hljs-number">4</span>, <span class="hljs-number">128</span>):<br>            <span class="hljs-keyword">with</span> T.block(<span class="hljs-string">&quot;Y&quot;</span>):<br>                vi = T.axis.spatial(<span class="hljs-number">128</span>, i)<br>                vj = T.axis.spatial(<span class="hljs-number">128</span>, j_0 * <span class="hljs-number">4</span> + j_1)<br>                vk = T.axis.reduce(<span class="hljs-number">128</span>, k)<br>                T.reads(A[vi, vk], B[vk, vj])<br>                T.writes(Y[vi, vj])<br>                <span class="hljs-keyword">with</span> T.init():<br>                    Y[vi, vj] = T.float32(<span class="hljs-number">0</span>)<br>                Y[vi, vj] = Y[vi, vj] + A[vi, vk] * B[vk, vj]<br>        <span class="hljs-keyword">for</span> i, j <span class="hljs-keyword">in</span> T.grid(<span class="hljs-number">128</span>, <span class="hljs-number">128</span>):<br>            <span class="hljs-keyword">with</span> T.block(<span class="hljs-string">&quot;C&quot;</span>):<br>                vi, vj = T.axis.remap(<span class="hljs-string">&quot;SS&quot;</span>, [i, j])<br>                T.reads(Y[vi, vj])<br>                T.writes(C[vi, vj])<br>                C[vi, vj] = T.<span class="hljs-built_in">max</span>(Y[vi, vj], T.float32(<span class="hljs-number">0</span>))<br><br><span class="hljs-comment"># 还可以更换循环次序</span><br><span class="hljs-comment"># sch.reorder(j0, k, j1)</span><br></code></pre></td></tr></table></figure><p>此外，块之间也可以通过变换完成组合</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 将块C放到Y的内循环中</span><br>block_C = sch.get_block(<span class="hljs-string">&quot;C&quot;</span>, <span class="hljs-string">&quot;mm_relu&quot;</span>)<br><span class="hljs-comment"># 感觉意思是将块C与j0循环绑定，及j0这个空间轴变换时，原本只有Y有动作，现在C也有动作</span><br>sch.reverse_compute_at(block_C, j0)<br>IPython.display.Code(sch.mod.script(), language=<span class="hljs-string">&quot;python&quot;</span>)<br><br><span class="hljs-meta">@I.ir_module</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Module</span>:<br><span class="hljs-meta">    @T.prim_func</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">mm_relu</span>(<span class="hljs-params">A: T.Buffer(<span class="hljs-params">(<span class="hljs-params"><span class="hljs-number">128</span>, <span class="hljs-number">128</span></span>), <span class="hljs-string">&quot;float32&quot;</span></span>), B: T.Buffer(<span class="hljs-params">(<span class="hljs-params"><span class="hljs-number">128</span>, <span class="hljs-number">128</span></span>), <span class="hljs-string">&quot;float32&quot;</span></span>), C: T.Buffer(<span class="hljs-params">(<span class="hljs-params"><span class="hljs-number">128</span>, <span class="hljs-number">128</span></span>), <span class="hljs-string">&quot;float32&quot;</span></span>)</span>):<br>        T.func_attr(&#123;<span class="hljs-string">&quot;global_symbol&quot;</span>: <span class="hljs-string">&quot;mm_relu&quot;</span>, <span class="hljs-string">&quot;tir.noalias&quot;</span>: <span class="hljs-literal">True</span>&#125;)<br>        <span class="hljs-comment"># with T.block(&quot;root&quot;):</span><br>        Y = T.alloc_buffer((<span class="hljs-number">128</span>, <span class="hljs-number">128</span>))<br>        <span class="hljs-keyword">for</span> i, j_0 <span class="hljs-keyword">in</span> T.grid(<span class="hljs-number">128</span>, <span class="hljs-number">32</span>):<br>            <span class="hljs-keyword">for</span> k, j_1 <span class="hljs-keyword">in</span> T.grid(<span class="hljs-number">128</span>, <span class="hljs-number">4</span>):<br>                <span class="hljs-keyword">with</span> T.block(<span class="hljs-string">&quot;Y&quot;</span>):<br>                    vi = T.axis.spatial(<span class="hljs-number">128</span>, i)<br>                    vj = T.axis.spatial(<span class="hljs-number">128</span>, j_0 * <span class="hljs-number">4</span> + j_1)<br>                    vk = T.axis.reduce(<span class="hljs-number">128</span>, k)<br>                    T.reads(A[vi, vk], B[vk, vj])<br>                    T.writes(Y[vi, vj])<br>                    <span class="hljs-keyword">with</span> T.init():<br>                        Y[vi, vj] = T.float32(<span class="hljs-number">0</span>)<br>                    Y[vi, vj] = Y[vi, vj] + A[vi, vk] * B[vk, vj]<br>            <span class="hljs-keyword">for</span> ax0 <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>):<br>                <span class="hljs-keyword">with</span> T.block(<span class="hljs-string">&quot;C&quot;</span>):<br>                    vi = T.axis.spatial(<span class="hljs-number">128</span>, i)<br>                    <span class="hljs-comment"># 注意这里vj的变化，原本vj = j = j_0 * 4 + j_1，现在变成了j_0 * 4 + ax0</span><br>                    <span class="hljs-comment"># 感觉是因为上面 reverse_compute_at 只是将C与j0绑定，所以j_1这个循环还是在Y中，C里还需要单独循环ax0</span><br>                    vj = T.axis.spatial(<span class="hljs-number">128</span>, j_0 * <span class="hljs-number">4</span> + ax0)<br>                    T.reads(Y[vi, vj])<br>                    T.writes(C[vi, vj])<br>                    C[vi, vj] = T.<span class="hljs-built_in">max</span>(Y[vi, vj], T.float32(<span class="hljs-number">0</span>))<br><br></code></pre></td></tr></table></figure><p>此外还介绍了另一种原语decompose_reduction，用于将语块中元素的初始化与规约更新分开：<br>这也是 TVM 在以后编译的时候隐式做的，所以这一步的主要目的是让它显式，看看最终效果</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 将块Y中的初始化与循环k无关(k是规约轴)</span><br>sch.decompose_reduction(block_Y, k)<br>IPython.display.Code(sch.mod.script(), language=<span class="hljs-string">&quot;python&quot;</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">lnumpy_mm_relu_v3</span>(<span class="hljs-params">A: np.ndarray, B: np.ndarray, C: np.ndarray</span>):<br>    Y = np.empty((<span class="hljs-number">128</span>, <span class="hljs-number">128</span>), dtype=<span class="hljs-string">&quot;float32&quot;</span>)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">128</span>):<br>        <span class="hljs-keyword">for</span> j0 <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">32</span>):<br>            <span class="hljs-comment"># Y_init</span><br>            <span class="hljs-keyword">for</span> j1 <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>):<br>                j = j0 * <span class="hljs-number">4</span> + j1<br>                <span class="hljs-comment"># 此时初始化在k循环之前就已经做好</span><br>                Y[i, j] = <span class="hljs-number">0</span><br>            <span class="hljs-comment"># Y_update</span><br>            <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">128</span>):<br>                <span class="hljs-keyword">for</span> j1 <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>):<br>                    j = j0 * <span class="hljs-number">4</span> + j1<br>                    Y[i, j] = Y[i, j] + A[i, k] * B[k, j]<br>            <span class="hljs-comment"># C</span><br>            <span class="hljs-keyword">for</span> j1 <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>):<br>                j = j0 * <span class="hljs-number">4</span> + j1<br>                C[i, j] = <span class="hljs-built_in">max</span>(Y[i, j], <span class="hljs-number">0</span>)<br><br>c_np = np.empty((<span class="hljs-number">128</span>, <span class="hljs-number">128</span>), dtype=dtype)<br>lnumpy_mm_relu_v3(a_np, b_np, c_np)<br>np.testing.assert_allclose(c_mm_relu, c_np, rtol=<span class="hljs-number">1e-5</span>)<br></code></pre></td></tr></table></figure><h4 id="构建与运行">构建与运行</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 使用llvm将模型编译到本机平台</span><br>rt_lib = tvm.build(MyModule, target=<span class="hljs-string">&quot;llvm&quot;</span>)<br><br><span class="hljs-comment"># 用于存储输入和输出的TVM NDArray</span><br>a_nd = tvm.nd.array(a_np)<br>b_nd = tvm.nd.array(b_np)<br>c_nd = tvm.nd.empty((<span class="hljs-number">128</span>, <span class="hljs-number">128</span>), dtype=<span class="hljs-string">&quot;float32&quot;</span>)<br><br><span class="hljs-comment"># 调用编译好的函数</span><br>func_mm_relu = rt_lib[<span class="hljs-string">&quot;mm_relu&quot;</span>]<br>func_mm_relu(a_nd, b_nd, c_nd)<br><span class="hljs-comment"># 将TVM与numpy的结果进行比较</span><br>np.testing.assert_allclose(c_mm_relu, c_nd.numpy(), rtol=<span class="hljs-number">1e-5</span>)<br><br><span class="hljs-comment"># 调用TVM变换后的函数，继续比较</span><br>rt_lib_after = tvm.build(sch.mod, target=<span class="hljs-string">&quot;llvm&quot;</span>)<br>rt_lib_after[<span class="hljs-string">&quot;mm_relu&quot;</span>](a_nd, b_nd, c_nd)<br>np.testing.assert_allclose(c_mm_relu, c_nd.numpy(), rtol=<span class="hljs-number">1e-5</span>)<br></code></pre></td></tr></table></figure><p>在最后的结果中，TVM变换后的函数运行时间相比原先的TVM函数大幅缩短，为什么不同的循环变体会导致不同的时间性能呢？</p><p>关键在于CPU的访存策略，由于局部性原理，CPU在读取内存某元素时会尝试将该元素附近的元素一起获取到缓存中（cache块？特么OS快忘干净了😅）。因此具有连续内存访问的代码通常比随机访问内存不同部分的代码更快。</p><h2 id="3-端到端的模型执行">3. 端到端的模型执行</h2><p>现在考虑一个基础的两层神经网络，由2个MLP和1个relu组成（简化问题，删除最后的softmax）</p><p>numpy实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">numpy_mlp</span>(<span class="hljs-params">data, w0, b0, w1, b1</span>):<br>    lv0 = data @ w0.T + b0<br>    lv1 = np.maximum(lv0, <span class="hljs-number">0</span>)<br>    lv2 = lv1 @ w1.T + b1<br>    <span class="hljs-keyword">return</span> lv2<br><br>res = numpy_mlp(img.reshape(<span class="hljs-number">1</span>, <span class="hljs-number">784</span>),<br>                mlp_params[<span class="hljs-string">&quot;w0&quot;</span>],<br>                mlp_params[<span class="hljs-string">&quot;b0&quot;</span>],<br>                mlp_params[<span class="hljs-string">&quot;w1&quot;</span>],<br>                mlp_params[<span class="hljs-string">&quot;b1&quot;</span>])<br></code></pre></td></tr></table></figure><p>底层实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">lnumpy_linear0</span>(<span class="hljs-params">X: np.ndarray, W: np.ndarray, B: np.ndarray, Z: np.ndarray</span>):<br>    Y = np.empty((<span class="hljs-number">1</span>, <span class="hljs-number">128</span>), dtype=<span class="hljs-string">&quot;float32&quot;</span>)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">128</span>):<br>            <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">784</span>):<br>                <span class="hljs-keyword">if</span> k == <span class="hljs-number">0</span>:<br>                    Y[i, j] = <span class="hljs-number">0</span><br>                Y[i, j] = Y[i, j] + X[i, k] * W[j, k]<br><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">128</span>):<br>            Z[i, j] = Y[i, j] + B[j]<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">lnumpy_relu0</span>(<span class="hljs-params">X: np.ndarray, Y: np.ndarray</span>):<br>     <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">128</span>):<br>            Y[i, j] = np.maximum(X[i, j], <span class="hljs-number">0</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">lnumpy_linear1</span>(<span class="hljs-params">X: np.ndarray, W: np.ndarray, B: np.ndarray, Z: np.ndarray</span>):<br>    Y = np.empty((<span class="hljs-number">1</span>, <span class="hljs-number">10</span>), dtype=<span class="hljs-string">&quot;float32&quot;</span>)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>            <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">128</span>):<br>                <span class="hljs-keyword">if</span> k == <span class="hljs-number">0</span>:<br>                    Y[i, j] = <span class="hljs-number">0</span><br>                Y[i, j] = Y[i, j] + X[i, k] * W[j, k]<br><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>            Z[i, j] = Y[i, j] + B[j]<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">lnumpy_mlp</span>(<span class="hljs-params">data, w0, b0, w1, b1</span>):<br>    lv0 = np.empty((<span class="hljs-number">1</span>, <span class="hljs-number">128</span>), dtype=<span class="hljs-string">&quot;float32&quot;</span>)<br>    lnumpy_linear0(data, w0, b0, lv0)<br><br>    lv1 = np.empty((<span class="hljs-number">1</span>, <span class="hljs-number">128</span>), dtype=<span class="hljs-string">&quot;float32&quot;</span>)<br>    lnumpy_relu0(lv0, lv1)<br><br>    out = np.empty((<span class="hljs-number">1</span>, <span class="hljs-number">10</span>), dtype=<span class="hljs-string">&quot;float32&quot;</span>)<br>    lnumpy_linear1(lv1, w1, b1, out)<br>    <span class="hljs-keyword">return</span> out<br><br>result =lnumpy_mlp(<br>    img.reshape(<span class="hljs-number">1</span>, <span class="hljs-number">784</span>),<br>    mlp_params[<span class="hljs-string">&quot;w0&quot;</span>],<br>    mlp_params[<span class="hljs-string">&quot;b0&quot;</span>],<br>    mlp_params[<span class="hljs-string">&quot;w1&quot;</span>],<br>    mlp_params[<span class="hljs-string">&quot;b1&quot;</span>])<br><br>pred_kind = result.argmax(axis=<span class="hljs-number">1</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Low-level Numpy MLP Prediction:&quot;</span>, class_names[pred_kind[<span class="hljs-number">0</span>]])<br></code></pre></td></tr></table></figure><p>该模型的TVMScript实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@tvm.script.ir_module</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyModule</span>:<br><span class="hljs-meta">    @T.prim_func</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">relu0</span>(<span class="hljs-params">x: T.handle, y: T.handle</span>):<br>        n = T.int64()<br>        X = T.match_buffer(x, (<span class="hljs-number">1</span>, n), <span class="hljs-string">&quot;float32&quot;</span>)<br>        Y = T.match_buffer(y, (<span class="hljs-number">1</span>, n), <span class="hljs-string">&quot;float32&quot;</span>)<br>        <span class="hljs-keyword">for</span> i, j <span class="hljs-keyword">in</span> T.grid(<span class="hljs-number">1</span>, n):<br>            <span class="hljs-keyword">with</span> T.block(<span class="hljs-string">&quot;Y&quot;</span>):<br>                vi, vj = T.axis.remap(<span class="hljs-string">&quot;SS&quot;</span>, [i, j])<br>                Y[vi, vj] = T.<span class="hljs-built_in">max</span>(X[vi, vj], T.float32(<span class="hljs-number">0</span>))<br><br><span class="hljs-meta">    @T.prim_func</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">linear0</span>(<span class="hljs-params">x: T.handle,</span><br><span class="hljs-params">                w: T.handle,</span><br><span class="hljs-params">                b: T.handle,</span><br><span class="hljs-params">                z: T.handle</span>):<br>        m, n, k = T.int64(), T.int64(), T.int64()<br>        X = T.match_buffer(x, (<span class="hljs-number">1</span>, m), <span class="hljs-string">&quot;float32&quot;</span>)<br>        W = T.match_buffer(w, (n, m), <span class="hljs-string">&quot;float32&quot;</span>)<br>        B = T.match_buffer(b, (n, ), <span class="hljs-string">&quot;float32&quot;</span>)<br>        Z = T.match_buffer(z, (<span class="hljs-number">1</span>, n), <span class="hljs-string">&quot;float32&quot;</span>)<br>        Y = T.alloc_buffer((<span class="hljs-number">1</span>, n), <span class="hljs-string">&quot;float32&quot;</span>)<br>        <span class="hljs-keyword">for</span> i, j, k <span class="hljs-keyword">in</span> T.grid(<span class="hljs-number">1</span>, n, m):<br>            <span class="hljs-keyword">with</span> T.block(<span class="hljs-string">&quot;Y&quot;</span>):<br>                vi, vj, vk = T.axis.remap(<span class="hljs-string">&quot;SSR&quot;</span>, [i, j, k])<br>                <span class="hljs-keyword">with</span> T.init():<br>                    Y[vi, vj] = T.float32(<span class="hljs-number">0</span>)<br>                Y[vi, vj] = Y[vi, vj] + X[vi, vk] * W[vj, vk]<br>        <span class="hljs-keyword">for</span> i, j <span class="hljs-keyword">in</span> T.grid(<span class="hljs-number">1</span>, n):<br>            <span class="hljs-keyword">with</span> T.block(<span class="hljs-string">&quot;Z&quot;</span>):<br>                vi, vj = T.axis.remap(<span class="hljs-string">&quot;SS&quot;</span>, [i, j])<br>                Z[vi, vj] = Y[vi, vj] + B[vj]<br><br><span class="hljs-meta">    @R.function</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>(<span class="hljs-params">x: R.Tensor(<span class="hljs-params">(<span class="hljs-params"><span class="hljs-number">1</span>, <span class="hljs-string">&quot;m&quot;</span></span>), <span class="hljs-string">&quot;float32&quot;</span></span>),</span><br><span class="hljs-params">             w0: R.Tensor(<span class="hljs-params">(<span class="hljs-params"><span class="hljs-string">&quot;n&quot;</span>, <span class="hljs-string">&quot;m&quot;</span></span>), <span class="hljs-string">&quot;float32&quot;</span></span>),</span><br><span class="hljs-params">             b0: R.Tensor(<span class="hljs-params">(<span class="hljs-params"><span class="hljs-string">&quot;n&quot;</span>, </span>), <span class="hljs-string">&quot;float32&quot;</span></span>),</span><br><span class="hljs-params">             w1: R.Tensor(<span class="hljs-params">(<span class="hljs-params"><span class="hljs-string">&quot;k&quot;</span>, <span class="hljs-string">&quot;n&quot;</span></span>), <span class="hljs-string">&quot;float32&quot;</span></span>),</span><br><span class="hljs-params">             b1: R.Tensor(<span class="hljs-params">(<span class="hljs-params"><span class="hljs-string">&quot;k&quot;</span>, </span>), <span class="hljs-string">&quot;float32&quot;</span></span>)</span>):<br>        m, n, k = T.int64(), T.int64(), T.int64()<br>        <span class="hljs-keyword">with</span> R.dataflow():<br>            lv0 = R.call_dps_packed(<span class="hljs-string">&quot;linear0&quot;</span>, (x, w0, b0), R.Tensor((<span class="hljs-number">1</span>, n), <span class="hljs-string">&quot;float32&quot;</span>))<br>            lv1 = R.call_dps_packed(<span class="hljs-string">&quot;relu0&quot;</span>, (lv0, ), R.Tensor((<span class="hljs-number">1</span>, n), <span class="hljs-string">&quot;float32&quot;</span>))<br>            out = R.call_dps_packed(<span class="hljs-string">&quot;linear0&quot;</span>, (lv1, w1, b1), R.Tensor((<span class="hljs-number">1</span>, k), <span class="hljs-string">&quot;float32&quot;</span>))<br>            R.output(out)<br>        <span class="hljs-keyword">return</span> out<br></code></pre></td></tr></table></figure><p>引入了一个新的 <code>@R.function</code> 即Relex函数，是一种表示上层神经网络执行的全新抽象</p><p><img src="image.png" alt="Alt text"></p><p>注意到，其中<code>call_dps_packed</code>将我们的元函数嵌入到计算图中，其主要作用是满足<strong>目标传递</strong>的调用约定，即 pure 或 side-effect free ，函数只从其输入中读取数据并输出返回结果，而不改变程序的其他部分，这可以方便我们隐藏调用底层元函数的细节</p><p>如果只是像numpy实现中那样：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">lnumpy_linear0(data, w0, b0, lv0)<br>lnumpy_relu0(lv0, lv1)<br>lnumpy_linear1(lv1, w1, b1, out)<br></code></pre></td></tr></table></figure><p>计算图可能会变成这样：lv0既是<code>lnumpy_linear0</code>的入参，也是<code>lnumpy_relu0</code>的入参，其余同理<br><img src="image-1.png" alt="Alt text"></p><blockquote><p>计算图通常具有以下性质：</p><ul><li>框的每个输入边对应于操作的输入</li><li>每个出边对应于操作的输出</li><li>每个操作可以任意重新排序，直到边缘的拓扑顺序</li></ul></blockquote><p>当然，numpy的底层同样也使用了如<code>lnumpy_call_dps_packed</code>的类似调用</p><p>此外，注意<code>with R.dataflow():</code> 是一个帮助我们标注程序计算图范围的方式，后面的构建运行就不多说了</p><h2 id="4-自动程序优化">4. 自动程序优化</h2>]]></content>
    
    
    <categories>
      
      <category>work</category>
      
    </categories>
    
    
    <tags>
      
      <tag>课程笔记</tag>
      
      <tag>MLC</tag>
      
      <tag>TVM</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>网络状态检查</title>
    <link href="/2023/09/16/%E7%BD%91%E7%BB%9C%E7%8A%B6%E6%80%81%E6%A3%80%E6%9F%A5/"/>
    <url>/2023/09/16/%E7%BD%91%E7%BB%9C%E7%8A%B6%E6%80%81%E6%A3%80%E6%9F%A5/</url>
    
    <content type="html"><![CDATA[<p>最近fps老是延迟+掉包（把把被一枪头想必不是我的问题），加上网口接触不良一直不好确定源头在哪，在此记录一下问题定位的过程</p><span id="more"></span><h2 id="原因分析：">原因分析：</h2><ul><li>数据传输流程：<br>本地主机 — 本地路由（如果有） — 网关 — 外部网络中转 — 目标主机</li></ul><p>很显然突然的延迟和掉包几乎不可能是外部网络中转和目标主机的问题，加上目前是直连宽带，问题只可能出在主机 &lt;—&gt; 网关上</p><h2 id="问题排查：">问题排查：</h2><h3 id="1-查看自身网络配置：">1. 查看自身网络配置：</h3><p><img src="0.png" alt=""></p><p>本地主机有两条连接，网关分别为192.168.14.1（网口）和172.168.15.1(wifi)</p><h3 id="2-运行任一出现掉包的应用">2. 运行任一出现掉包的应用</h3><h3 id="3-任务管理器中的资源监视器，找到进程PID以及通信的外部IP">3. 任务管理器中的资源监视器，找到进程PID以及通信的外部IP</h3><p><img src="1.png" alt=""></p><p>我也不知道这么多IP哪一个是导致掉包和延迟的。。先找收发高的吧 180.102.211.22 121.229.89.178</p><h3 id="4-netstat查看该进程的网络相关信息">4. netstat查看该进程的网络相关信息</h3><p><img src="2.png" alt=""></p><p>很显然主机是用的192.1168.14.1上的某个端口向外部通信，并且问题大概率出现在与121.229与180.102的通信上</p><h3 id="5-tracert查看路由（pathping也行）">5. tracert查看路由（pathping也行）</h3><table><thead><tr><th style="text-align:center"><img src="4.png" alt=""></th><th style="text-align:center"><img src="5.png" alt=""></th></tr></thead></table><p>两次在走过网口后，都又经过了一个本地IP 100.69.0.1 ，估计是一整栋楼或者本层局域网统一之后的二级网关，经过这个才到外部网络</p><h3 id="6-ping">6. ping</h3><p>分别 ping -t 了一下网关和100.69两个ip，发现到网关基本上没问题，也就是主机到网口的全过程流畅</p><p>每次出现掉包时，到100.69也会出现请求超时，问题就在网口到100.69这段，分析有两种可能：</p><ol><li>网口到100.69线路导致丢包</li><li>100.69负载过高，收到数据后转发丢包</li></ol><h2 id="问题解决">问题解决</h2><p>不信邪，直接去楼上的两间空房和本层的另一间空房试了一下，楼上经网关后统一发向100.65.0.1，楼下统一发向100.69.0.1，且本层其他房间ping 100.69也会出现超时或延迟过高问题，服了，确实是层级网关负载过高的原因</p><h2 id="有线和wifi双网叠加">有线和wifi双网叠加</h2><p>参考：<a href="https://www.zhihu.com/question/294289602/answer/2912972037">https://www.zhihu.com/question/294289602/answer/2912972037</a></p><p>系统会优先选择跃点数小的网络进行传输， route print查看连接网络跃点数，之后将两个网络跃点数设置为相同即可</p><p>感觉很扯，实测下载速度不变，上传速度翻倍。。。牛皮</p>]]></content>
    
    
    <categories>
      
      <category>work</category>
      
    </categories>
    
    
    <tags>
      
      <tag>记录</tag>
      
      <tag>网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Dive into Deeplearning</title>
    <link href="/2023/09/14/Dive-into-Deeplearning/"/>
    <url>/2023/09/14/Dive-into-Deeplearning/</url>
    
    <content type="html"><![CDATA[<p>作为一切的开始，最近想要重新整理一份笔记，便于后期快速复习</p><span id="more"></span><p>参考：</p><ul><li><a href="https://zh.d2l.ai/index.html">https://zh.d2l.ai/index.html</a></li><li><a href="https://space.bilibili.com/1567748478/channel/seriesdetail?sid=358497&amp;ctype=0">https://space.bilibili.com/1567748478/channel/seriesdetail?sid=358497&amp;ctype=0</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>work</category>
      
    </categories>
    
    
    <tags>
      
      <tag>DL</tag>
      
      <tag>课程笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>GPGPA阅读</title>
    <link href="/2023/09/14/GPGPA%E9%98%85%E8%AF%BB/"/>
    <url>/2023/09/14/GPGPA%E9%98%85%E8%AF%BB/</url>
    
    <content type="html"><![CDATA[<h1>General-Purpose Graphics Processor Architectures</h1><h2 id="Abstract-Preface">Abstract &amp;&amp; Preface</h2><p>与CPU相比，GPU可以更加聚焦与计算，因此性能和效率更高。——通用可编程GPU</p><p>章节介绍：GPU基本结构与历史 —— GPU编程模型 —— GPU计算核心的体系结构 —— 计算核心与内存系统的交叉研究</p><h2 id="Chapter-1-Intro">Chapter 1: Intro</h2><h3 id="1-1-计算加速器的前景">1.1 计算加速器的前景</h3><p>过去，计算系统的性能提升大部分依赖于工艺的进步，使得晶体管尺寸缩小，从而提升集成度，使得运行速度更快。</p><p>Dennard Scaling：从05年开始晶体管缩放规则失效。因此为了提高性能，需要找到更高效的硬件架构。</p><p>hardware specialization：定制化硬件，可以使能效比大幅提高，两大方向：</p><ul><li>硬件向量化，消除指令处理的开销</li><li>优化计算过程，减少数据运输开销</li></ul><p>计算架构的关键：专业化硬件带来的收益与支持广泛程序所需的灵活性之间的平衡。相比于专用加速器（例如google的TPU），仍然需要GPU这种较为通用的计算硬件。</p><p>Turing-complete：图灵完备，只要给足够的时间与内存，GPU可以完成一切运算。</p><h3 id="1-2-GPU硬件基础">1.2 GPU硬件基础</h3><p>GPU不会完全取代CPU：GPU不是独立的计算设备，通常来说，CPU负责在GPU上启动计算并负责GPU上的数据传输。当前访问I/O设备或提供OS服务的软件主要还是运行在CPU上（这些软件缺乏大规模并行性），因此，需要首先考虑GPU与CPU的交互。</p><ul><li>独立GPU：两个U各有各的mem，同时核心通过PCIE总线进行数据传输。注意对于独显来说，两个U的mem的DRAM技术通常是不一样的，CPU的DRAM通常针对低延迟访问进行优化（DDR），而GPU的DRAM通常针对高吞吐进行优化（GDDR）。</li><li>集成GPU：两个U共享一个cache，cache与一个内存进行数据交互。由于共享内存所以只能采取单一技术，集成式GPU通常搭载在低功耗设备上，因此DRAM通常针对低功耗进行优化（LPDDR）。</li></ul><p>一个GPU计算应用会从CPU上开始，通常，该应用程序的CPU部分负责分配和初始化一些数据结构。在旧的N卡和A卡上，CPU需要为CPU和GPU内存中的数据结构分配空间，并协调数据从CPUmem到GPUmem的移动。在新的N卡（Pascal，10系）上的软硬件支持数据从Cmem到Gmem的自动传输，这项技术通过利用虚拟内存支持来实现，NV称之为unified memory。对于集显来说不存在数据mem传输的问题，但是由于两个U共享cache并且有些cache可能是私有的，因此也需要关注缓存一致性问题 (cache-coherence) 。</p><p>启动GPU运算一般需要驱动程序完成，在GPU启动运算前，CPU通过驱动程序指定GPU运行哪些代码，这些代码称为内核（kernel），同时，CPU还需要指定线程数、每个线程的数据位置等等。配置完毕后，CPU向GPU发出信号，GPU开始运算。</p><p>现代GPU由许多核心（SIMT Core）组成，NV称之为流式多处理器(Streaming Multiprocessor, SM)，AMD称之为计算单元(compute unit)，每个核心都执行一个与此时运行的内核相关的单指令多线程程序，一个核心可以运行上千个线程，这些线程通过暂存区mem进行通信，并使用快速屏障技术（fast barrier operations）进行同步。每个核心同时还有一级指令和一级缓存，这些缓存可以充当带宽过滤器，减少向低级别内存的流量，当拥有大量线程时，可以隐藏由于有时某线程的缓存未命中而访问内存带来的的性能下滑。</p><p>高计算吞吐需要高内存带宽的支持，这又对内存系统的并行性提出要求。这种并行性又多通道内存实现，每个通道与内存分区中的最后一级缓存（LLC）相连，GPU核心通过片上互连网络与内存分区相连。也有一些替代的方案，例如Intel的Xeon Phi，就是将LLC直接交由GPU核心分配</p><p>对于高并发任务来说，GPU相对超标量无序CPU拥有更高的单位面积性能，因为GPU可以将其芯片面积的大部分专用于算术逻辑单元，并相应的减小控制逻辑的面积。</p><p>09年出来一个性能随线程变化的分析模型。模型显示：</p><ol><li>当少量线程共享大缓存时（如多核CPU），性能会随着线程数量的增加而提高。</li><li>当线程数增加到缓存无法容纳整个工作集时，性能反而会随着线程数量增加而下降。</li><li>但是随着线程数量的进一步增加，性能会随着多线程隐藏片外延迟的能力而提高。<br>GPU就是通过采用多线程来容忍频繁的缓存未命中，提高运算性能。</li></ol><p>内存访问不仅降低性能，同时也会提高能耗。新的GPGPU架构的重点是改善内存访问。</p><h3 id="1-3-GPU简史">1.3 GPU简史</h3><h3 id="1-4-书籍大纲">1.4 书籍大纲</h3><ul><li>第二章：编程模型、代码开发过程、编译流程</li><li>第三章：单个GPU核心（SM）的体系结构</li><li>第四章：内存系统</li><li>第五章：其他研究</li></ul><h2 id="Chapter-2：编程模型">Chapter 2：编程模型</h2><p>现代GPU广泛采用SIMD硬件来利用数据级并行，但GPU的计算API（如NV的cuda和AMD的opencl）并不向程序员暴露SIMD的硬件，而是采取类似MIMD的编程模型，允许程序员在GPU上启动大量标量线程。其中的每一个标量线程都有自己独特的执行路径，并都可以访问内存。运行时，GPU上的的SIMD硬件利用线程的规律性和空间局部性，同步启动这些标量线程组，称为SIMT（单指令多线程）</p><ul><li>SIMD：例如两个向量，对两个向量的每一个分量进行相同的op操作，输出为一个向量（在一个线程里，受ALU宽度限制）</li><li>SIMT：与SIMD在一个线程公用一个ALU不同，SIMT有多个线程，每个线程各有各的ALU和自己的数据，但执行的指令相同（但是由于数据不同，执行指令时的控制分支可能会不一样）</li></ul><h3 id="2-1-运行模型">2.1 运行模型</h3><p>为GPU优化的代码很可能在CPU架构上表现不佳。假定一个 单精度标量A * 向量X + 向量Y 的函数实现：</p><p>CPU实现</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-type">void</span> <span class="hljs-title function_">saxpy_serial</span><span class="hljs-params">(<span class="hljs-type">int</span> n, <span class="hljs-type">float</span> a, <span class="hljs-type">float</span> *x, <span class="hljs-type">float</span> *y)</span><br>&#123;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; n; ++i)<br>        y[i] = a * x[i] + y[i];<br>&#125;<br>main()<br>&#123;<br>    <span class="hljs-type">float</span> *x, *y;<br>    <span class="hljs-type">int</span> n;<br>    <span class="hljs-comment">// 省略*x、*y的赋值操作</span><br>    saxpy_serial(n, <span class="hljs-number">2.0</span>, x, y);<br>    <span class="hljs-comment">// 省略内存释放操作</span><br>&#125;<br></code></pre></td></tr></table></figure><p>GPU-CUDA实现</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs C">__global__ <span class="hljs-type">void</span> <span class="hljs-title function_">saxpy</span><span class="hljs-params">(<span class="hljs-type">int</span> n, <span class="hljs-type">float</span> a, <span class="hljs-type">float</span> *x, <span class="hljs-type">float</span> *y)</span> <span class="hljs-comment">// __global__代表函数在GPU上运行</span><br>&#123;<br>   <span class="hljs-comment">// 每个线程都有各自的blockIdx.x、blockDim.x、threadIdx.x</span><br>   <span class="hljs-type">int</span> i = blockIdx.x * blockDim.x + threadIdx.x;<br>   <span class="hljs-comment">// threadIdx.x代表线程在线程块中的x坐标</span><br>   <span class="hljs-comment">// blockIdx.x代表线程所属的线程块在grid中的x坐标</span><br>   <span class="hljs-comment">// blockDim.x一个线程块在x维度的最大线程数</span><br>   <span class="hljs-comment">// 一般来说线程在线程块中有xyz三个坐标，线程块在网格中也有xyz三个坐标，这里省略y，z</span><br>   <span class="hljs-keyword">if</span> (i &lt; n)<br>      y[i] = a * x[i] + y[i];<br>&#125;<br><span class="hljs-type">int</span> <span class="hljs-title function_">main</span><span class="hljs-params">()</span><br>&#123;<br>   <span class="hljs-comment">// 一般h_表示cpu的内存指针，d_表示gpu的内存指针</span><br>   <span class="hljs-type">float</span> *h_x, *h_y;<br>   <span class="hljs-type">int</span> n;<br>   <span class="hljs-comment">// 省略*h_x、*h_y的赋值操作</span><br>   <span class="hljs-type">float</span> *d_x, *d_y;<br>   <span class="hljs-type">int</span> nblocks = (n + <span class="hljs-number">255</span>) / <span class="hljs-number">256</span>;<br>   <span class="hljs-comment">// 调用GPU驱动程序并要求分配gpu内存，并将这一片内存的地址赋给&amp;d_x</span><br>   cudaMalloc(&amp;d_x, n * <span class="hljs-keyword">sizeof</span>(<span class="hljs-type">float</span>));<br>   cudaMalloc(&amp;d_y, n * <span class="hljs-keyword">sizeof</span>(<span class="hljs-type">float</span>));<br>   <span class="hljs-comment">// 将h_x指向的内容赋值给d_x指向的区域</span><br>   cudaMemcpy(d_x, h_x, n * <span class="hljs-keyword">sizeof</span>(<span class="hljs-type">float</span>), cudaMemcpyHostToDevice);<br>   cudaMemcpy(d_y, h_y, n * <span class="hljs-keyword">sizeof</span>(<span class="hljs-type">float</span>), cudaMemcpyHostToDevice);<br>   <span class="hljs-comment">// 交由GPU，并启动nblocks个线程块（Thread Block，或CTA），每个线程块256个线程，所有的线程块组成一个grid，即本次内核的计算单元</span><br>   saxpy&lt;&lt;&lt;nblocks, <span class="hljs-number">256</span>&gt;&gt;&gt;(n, <span class="hljs-number">2.0</span>, d_x, d_y);<br>   <span class="hljs-comment">// 为了提高效率，每个线程块中，每32个线程以锁步形式组成一组warp，warp往上再组成线程块</span><br>   <span class="hljs-comment">// 一个warp包含多少线程是硬件概念，而一个线程块可以有多少线程则是软件概念（当然得是warp的整数倍）</span><br>   <span class="hljs-comment">// 将计算结果返回给CPU内存</span><br>   cudaMemcpy(h_x, d_x, n * <span class="hljs-keyword">sizeof</span>(<span class="hljs-type">float</span>), cudaMemcpyDeviceToHost);<br>   <span class="hljs-comment">// 省略内存释放操作</span><br>&#125;<br></code></pre></td></tr></table></figure><p>硬件：一个GPU有多个SM，每个SM包含多个SP（Stream Processor）</p><p>软件：一个GPU内核对应一个grid，一个grid包含多个CTA。CTA中有多个warp，每个warp包含固定数量的线程数（与SM中SP数量相同）。</p><p>GPU在运算时，可能是一个grid独占GPU，也可以多个grid并行跑GPU；SM对应的工作单元是CTA，其中的基本执行单元是warp（即每个SP对应一个warp中的线程），在某个warp受阻时SM可以切换同一个CTA中的其他warp，但只有该CTA执行完，才切换其他CTA</p><p>CTA中的线程之间可以通过暂存器内存互相通信（NV称之为共享内存），同步也轻松，同时每个SM中也有一个共享内存，可以分配给在该SM上运行的所有CTA</p><p>不同CTA中的线程也可以通过所有线程都能访问的全局地址空间通信，但代价较高</p><h3 id="2-2-指令模型">2.2 指令模型</h3><p>NV的并行线程执行ISA：Parallel Thread eXecution，简称PTX （虚拟指令，类似汇编指令）</p><p>GPU运行PTX代码前，需要编译（汇编）成实际的机器指令，NV称此为SASS（Streaming ASSembler），该过程有NV的工具包完成，并没有开放，这使得NV可以在硬件级别提供向后兼容性，每一代都可以重新设计ISA架构</p><h2 id="Chapter-3：SIMT核心：指令和寄存器数据流">Chapter 3：SIMT核心：指令和寄存器数据流</h2><p>对传统图形渲染来说，GPU通常需要访问详细的纹理图，这样的数据集因为太大不可能完全缓存在芯片上，因此有必要采用能够维持大片外带宽的GPU架构。所以如今的GPU都往高并发线程发展（大概意思是线程越多越能够隐藏访存损失）。并且，尽管每个线程的片上缓存很小，但因为局部性原理，仍然可以有效减少大量的片外存储访问。</p><p>SM的微体系结构，流水线分为SIMT前端和SIMD后端，共3个循环：</p><ol><li>取值（fetch）循环：fetch、I-Cache、Decode和I-Buffer模块</li><li>发指（issue）循环：I-Buffer、Scoreboard、issue和SIMT stack模块</li><li>寄存器访问调度循环：Operand Collector、ALU和Memory模块</li></ol><p><img src="image.png" alt=" "></p><h3 id="3-1-单循环近似">3.1 单循环近似</h3><p>线程的调度单位是warp（AMD称之为wavefronts）。每一个周期，SM选择一个warp进行调度。</p><p>单循环中，warp的程序计数器（PC）用于访问指令存储器时查找为warp执行的下一条指令。获得指令后，对指令解码，并找到源操作数寄存器。与此同时，SIMT的执行掩码值也被确定。</p><p>在执行掩码与源寄存器可用后，执行以SIMD的方式进行。如果设置了SIMT执行掩码，则每个线程都在与通路关联的功能单元上执行。与现代CPU一样，功能单元通常异构，即不同的单元支持不同的指令运行。</p><p>每个功能单元在名义上包含的通路数与warp的线程数相同，但也有一些GPU使用不同的实现，使其中的warp在多个时钟周期内执行。</p><h4 id="3-1-1-SIMT执行掩码">3.1.1 SIMT执行掩码</h4><p>现代GPU的关键特性是SIMT执行模型，为程序员提供了单个线程完全独立执行的抽象，这是通过传统谓词（prediction）与SIMT谓词掩码堆栈结合实现的。</p><p>SIMT堆栈有助于处理线程可以独立执行时出现的两个关键问题：</p><ol><li>嵌套控制流</li><li>完全跳过计算</li></ol><table><thead><tr><th style="text-align:center"><img src="image-1.png" alt=" "></th><th style="text-align:center"><img src="image-2.png" alt=" "></th><th style="text-align:center"><img src="image-3.png" alt=" "></th></tr></thead></table><p>假设每个warp有四个线程，所有线程都执行了A基本块，之后遵循不同的控制流，有3个线程进入B，1个线程进入F。如此流动，最后所有线程统一到达G。</p><table><thead><tr><th style="text-align:center"><img src="image-4.png" alt=" "></th><th style="text-align:center"><img src="image-5.png" alt=" "></th></tr></thead></table><p>堆栈包括三项：重新收敛程序计数器(Reconvergence program counter, RPC)、要执行的下一条指令的地址(Next PC)和活跃掩码(active mask)。warp每次都执行栈顶指针指向的条目的nextPC指向的代码块</p><ol><li>开始时堆栈中只有一个条目“-，A，1111”。代表所有线程都将进入A。</li><li>所有4个线程在走完A之后进行分支，此时需要有3处修改：<ul><li>将原先条目的nextPC值修改成分支后的重新汇聚点，对于这次分支B和F，将在G重新汇聚，因此将第一条的nextPC由A修改为G</li><li>这次分支有3个进入B，1个进入F，因此在堆栈中压入关于B和F的两个条目</li></ul></li><li>线程执行栈顶条目“G，B，1110”，掩码是1110代表这行条目对前三个线程active，走完B后进行分支，同理修改原来条目的nextPC，改成最近的重新收敛点E，同时添加两个分支条目。<ul><li>一般改成最近的重新收敛点，是为了从该位置将之前发散的线程以锁步的方式继续执行，便于同步</li><li>通常来说，在分支过后，最好是先将最多活跃线程的条目先入栈，少活跃线程的条目后入栈，例如d部分，而c部分的例子相反</li></ul></li></ol><h4 id="3-1-2-SIMT死锁与无堆栈SIMT结构">3.1.2 SIMT死锁与无堆栈SIMT结构</h4><p>SIMT基于堆栈的实现可能导致死锁：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-comment">// 将mutex置0代表资源空闲</span><br>*mutex = <span class="hljs-number">0</span>;<br><span class="hljs-comment">// atomicCAS读取mutex，若为0，则置1（即若空闲，则访问），返回mutex原始值</span><br><span class="hljs-comment">// 一个warp中的所有线程都执行，因此只有一个线程看到mutex=0，其他都看到=1</span><br><span class="hljs-keyword">while</span>(!atomicCAS(mutex,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>));<br><span class="hljs-comment">// 释放mutex</span><br>atomicExch(mutex,<span class="hljs-number">0</span>);<br></code></pre></td></tr></table></figure><p>简而言之，对于一个互斥资源，当一个warp的所有线程同时执行互斥锁式访问时，只有一个线程拿到资源，其他线程陷入原地等待。但是，拿到资源的线程在执行完毕后，达到了上文中的重新收敛点，会等待其他所有线程一起到这个点，才能继续执行第三句释放锁。</p><p>无堆栈分支的重新收敛机制：warp收敛屏障</p>]]></content>
    
    
    <categories>
      
      <category>work</category>
      
    </categories>
    
    
    <tags>
      
      <tag>论文笔记</tag>
      
      <tag>TBC</tag>
      
      <tag>GPGPA</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>DianNao系列论文阅读</title>
    <link href="/2023/09/14/DianNao%E7%B3%BB%E5%88%97%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    <url>/2023/09/14/DianNao%E7%B3%BB%E5%88%97%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/</url>
    
    <content type="html"><![CDATA[<h2 id="DianNao-A-Small-Footprint-High-Throughput-Accelerator-for-Ubiquitous-Machine-Learning">DianNao: A Small-Footprint High-Throughput Accelerator for Ubiquitous Machine-Learning</h2><h3 id="概述">概述</h3><p>DianNao：一个用于普遍机器学习的小规模高通量加速器。寒武纪开山之作</p><p>现阶段（2014）机器学习工作中（CNN、神经网络）CPU性能不够，GPU、FPGA等功耗过高。</p><p>当前的绝大多数acc的关注点都在于算法计算部分（efficiently implementing the computational part of the algorithms），然而CNN和DNN的特点是大尺寸、大计算量。在这种情况下，DMA的效果不太好。因此我们针对这一特性，设计了一个专门对访存做特别优化的加速器</p><p>对比常规SIMD处理器速度快117倍，能耗比提高21倍</p><h3 id="Intro">Intro</h3><p>加速器设计的权衡：灵活性和高性能。而由于当时机器学习的SOTA就是CNN和DNN，种类有限，所以可以这类计算设计出有针对性的加速器</p><p>当前针对CNN或MLP的加速器都专注于神经网络中计算原语如卷积的有效实现，如矩阵乘法、向量计算方面的优化。但是忽略了对性能影响同样巨大的访存部分</p><p>由于阿姆达尔定律，即使计算原件做大量优化，整体性能依旧会受制于内存传输部分，并且在机器学习领域，为了实现更高的精度和功能，有一个必然的趋势就是提高神经网络的规模，而这也证明了访存优化对于设计加速卡的重要性</p><p>主要贡献：高吞吐、高能耗比、侧重内存性能的加速卡设计</p><h3 id="最新机器学习技术入门">最新机器学习技术入门</h3><p>当前的市场来说，我们的加速器应该聚焦于网络的前馈而非反馈。这是由于在许多业务场景下离线学习都是主流，网路可以周期性的进行离线学习，而拿到客户手中只需要高效的前向推理。并且由于反向传播和正向路径原理类似，我们在之后也会针对反向传播做出优化工作</p><h3 id="基于处理器的（大型）神经网络实现">基于处理器的（大型）神经网络实现</h3><table><thead><tr><th style="text-align:center"><img src="image.png" alt=" "></th><th style="text-align:center"><img src="image-1.png" alt=" "></th><th style="text-align:center"><img src="image-2.png" alt=" "></th></tr></thead></table><ol><li><p>classifier层</p><ul><li>就是全连接层，在一般的理解中，每一个output相当于所有input的加权求和在Sigmoid出的概率值，如图所示，synapses矩阵对于每个output来说该input的权重</li><li>首先展示的是针对全连接层的优化，一般比较符合直观思维的模式是逐行运算，每次输出一个output。这种方式在遇到大规模神经网络（i/o神经元数量大）时有一个问题：对带宽要求高，内存运输总数= inputs loaded + synapses loaded + outputs written = Ni x Nn + Ni x Nn + Nn</li><li>改进方式：将输入神经元进行tile loop，在L1缓存不够大的情况下，平铺再分块，类似卷积层，这样做的好处是对input神经元的数据做了复用，大大降低了输入神经元的内存带宽需求，略微增加了输出带宽需求（因为不再是一次出结果，需要written多次）</li><li>同时如果将synapses矩阵存入L2缓存（对于当时的神经网络来说，权重总数在百万数量级，仍在L2的范围内），可以进一步减少所需带宽</li></ul></li><li><p>卷积层</p><ul><li>有两种数据复用可能：滑动窗口（就是卷积核权重，滑动过程中卷积核不变）以及跨通道的输出复用</li><li>简单来说就是每次不再都整个input feature map，而是在map上截取一片Tx*Ty，每次不同的卷积核在上面卷积运算之后送给output，再最后加权求和</li><li>无非是由于缓存空间限制而对feture maps、Input channel、output channel做出截取，让运算时数据都在缓存中，降低内存带宽</li><li>针对卷积核权值共享做了优化，文章倾向于共享卷积核</li></ul></li><li><p>池化层:</p><ul><li>重用机会少，对于增加Tx，Ty效果不显著</li></ul></li></ol><h3 id="小型神经网络加速器">小型神经网络加速器</h3><ul><li>对于小型网络，可假设所有神经元和突触都由硬件实现，内存仅用于I/O</li><li>对于小型神经网络可以大幅提高能耗，但随神经元数量增多面积、能量和延迟呈二次方增长</li></ul><h3 id="大型神经网络加速器">大型神经网络加速器</h3><p><img src="image-3.png" alt=" "></p><p>总共三大部件：</p><ul><li>运算部分：NFU</li><li>存储部分：输入缓存NBin、输出缓存NBout、突触权重SB</li><li>控制逻辑：CP</li></ul><p>NFU：</p><ul><li>按照第三节，将每一层分解为Ti和Tn的计算块</li><li>流水线：layer都可以分为若干个规范计算单元的组合，将整个计算规范化，流程化<ol><li>NFU-1：乘法单元</li><li>NFU-2：加法树</li><li>NFU-3：激活单元</li></ol></li></ul><p>全连接层：突出*输入；乘积求和；激活函数sigmoid；<br>卷积层：计算阶段相同，只是激活函数可能不同；<br>池化层：没有乘积的操作，可以是求最大池化和平均池化</p><h2 id="DaDianNao-A-Machine-Learning-Supercomputer">DaDianNao: A Machine-Learning Supercomputer</h2><h3 id="概述-2">概述</h3><p>在多核芯片中，由于CNNs和DNNs所需内存并未超过其片上存储空间，结合CNN/DNN算法自身特点，会导致高内部带宽和低外部通信这一情况，从而能在合理的区域成本下实现高并发。</p><h3 id="Intro-2">Intro</h3><p>前人工作缺陷：加速芯片要么有神经网络大小限制，要么对于大型网络，神经元和突触必须存储在内存中</p><p>神经网络性能瓶颈：内存访问</p><h3 id="The-GPU-Option-The-Accelerator-Option">The GPU Option/ The Accelerator Option</h3><p>CPU与GPU与DianNao的一些比较；DianNao的介绍，现有DianNao的不足</p><p>主要的限制来源于两种重要层的内存带宽需求：私有内核的卷积层(用于dnn)和全连接层</p><h3 id="A-Machine-Learning-Supercomputer">A Machine-Learning Supercomputer</h3><p>权重存储在将使用它们的神经元附近，最大限度地降低数据移动，节省时间和能量;架构是完全分布式的，没有主存</p><p>非对称的体系结构，其中每个节点占用的空间大量偏向于存储而不是计算</p><p>传递神经元值而不是权重，因为在两个典型层中，神经元值比权重数量级小，需要相对较少的外部(跨芯片)带宽</p><p>通过将本地存储分解成许多块来实现高的内部带宽</p><p>将SRAM更换为eDRAM，缩小面积，但需要周期性刷新、延迟高</p><p>NFU无法简单扩大规模：数据布线面积占用过多，可扩展性差</p><p>对NFU进行分片</p><h2 id="Cambricon-An-Instruction-Set-Architecture-for-Neural-Networks">Cambricon: An Instruction Set Architecture for Neural Networks</h2><h3 id="概述-3">概述</h3><p>传统神经网络往往在CPU、GPGPU这样的的通用平台执行，通常来说不够节能，因为这种平台主要是为了灵活支持各类型工作</p><p>最近的一些硬件加速器，这类加速器通常采用高级指令直接控制高级功能块。但是，当需要灵活支持各种不同的NN时，这种直接控制块的方式就不太行</p><p>思路 a. 分解大块的操作成一个个小的指令，获得更大的灵活性。用户可以用低层次的操作组合成高层次的功能。b. 简单的短指令可以大幅降低设计验证的复查度和解码器的功耗和面积。</p>]]></content>
    
    
    <categories>
      
      <category>work</category>
      
    </categories>
    
    
    <tags>
      
      <tag>DianNao</tag>
      
      <tag>论文笔记</tag>
      
      <tag>TBC</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>00：个人网站部署</title>
    <link href="/2023/09/13/00%EF%BC%9A%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99%E9%83%A8%E7%BD%B2/"/>
    <url>/2023/09/13/00%EF%BC%9A%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99%E9%83%A8%E7%BD%B2/</url>
    
    <content type="html"><![CDATA[<p>花了两三天时间搭了一个用于笔记的个人博客，部署在了 github 上，这里记录一下部署的过程。</p><span id="more"></span><h2 id="选型">选型</h2><p>网站的建立主要是为了搭一个在公司和家里都能访问的博客环境，对工作和学习做一些记录，所以直接放弃传统的带前端后端的动态页面，时间成本太高，整一个可以一键上传 markdown 的静态页面就挺ok。前端框架采用 hexo，UI选择 fluid，代码放在 github 上，并使用 github action 进行持续集成，部署到 github pages 后，后续写作只需要一次 git push 就可以自动将文章更新到目标网站上。</p><h2 id="框架搭建">框架搭建</h2><p><a href="https://hexo.io/zh-cn/docs/">https://hexo.io/zh-cn/docs/</a></p><h2 id="UI设置">UI设置</h2><p><a href="https://hexo.fluid-dev.com/docs/guide/">https://hexo.fluid-dev.com/docs/guide/</a></p><h2 id="部署">部署</h2><h3 id="快速部署">快速部署</h3><p><a href="https://hexo.io/zh-cn/docs/one-command-deployment">https://hexo.io/zh-cn/docs/one-command-deployment</a></p><p>适用于希望源代码保存在本地而不用上传的情况，相当于本地构建完再将构建好的网页直接推给gh page</p><p>需要在 _config.yml 中配置 gh page 的仓库地址和分支，推送后，hexo 会将 public 目录中的文件推送至_config.yml 中指定的分支中，并且完全覆盖该分支下的已有内容。</p><p>这就导致了一个问题，由于是只传 public 目录，域名映射需要的CNAME文件只能放到 public 下，这样每次 hexo clean 后会清空 public，还得再编辑一次CNAME，但是好处在于刨除了云端构建的不稳定性，每次可以本地看看网站效果，再直接放到 gh page 中</p><h3 id="gh-actions-持续集成">gh actions 持续集成</h3><p><a href="https://easyhexo.com/1-Hexo-install-and-config/1-5-continuous-integration.html">https://easyhexo.com/1-Hexo-install-and-config/1-5-continuous-integration.html</a></p><p>源代码放到 <a href="http://user.github.io">user.github.io</a> 仓库中后（仓库名只能设为这个，否则生成网页会变成 <a href="http://user.github.io">user.github.io</a> 的子页），CNAME 放在 source 中，然后在 .github/workflws 中定义 gh actions 的详细配置</p><p>采用的hexo官方文档中的配置，最后一步使用 peaceiris/actions-gh-pages@v3 咱也不太懂，参考知乎上的其他配置，大概相当于安装 hexo 完了在将 main 分支的源码 deploy 到 gh-pages 分支上，之后在设置时选择这个分支即可</p><p>主要问题在于每次 push 都要重新 build，推测后期内容增多后网站更新会十分不及时，可能需要看看别人的追加更新是咋弄的</p><h3 id="CDN加速、">CDN加速、</h3><p>更换 Cloudflare 的 DNS，注意 SSL/TLS 加密模式设为严格</p><h2 id="Summary">Summary</h2><p>属于我的第0篇博客，大概，能在网站上正常显示，证明基本功能已经ok</p><h2 id="TODO">TODO</h2>]]></content>
    
    
    <categories>
      
      <category>work</category>
      
    </categories>
    
    
    <tags>
      
      <tag>前端</tag>
      
      <tag>记录</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
