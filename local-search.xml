<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>C++ 杂记</title>
    <link href="/2024/03/11/C-%E6%9D%82%E8%AE%B0/"/>
    <url>/2024/03/11/C-%E6%9D%82%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<span id="more"></span><h2 id="基础">基础</h2><h3 id="内存分区">内存分区</h3><ol><li>代码区：函数体的二进制代码</li><li>全局区：全局变量、静态变量、常量</li><li>栈区：函数调用、局部变量</li><li>堆区：程序员动态分配内存，如new和delete</li></ol><h3 id="枚举">枚举</h3><p><code>enum enum_name&#123;a,b,c..&#125; var_name;</code><br>枚举标识符可赋值，默认从0开始+1</p><h3 id="const">const</h3><p>常类型的变量或对象的值无法被更新</p><h4 id="修饰变量">修饰变量</h4><p>必须赋初始值，且赋值之后无法修改</p><p>与#define相比，const定义的常量有数据类型，编译器可以进行类型安全检查，而#define只是单纯的字符串替换</p><p>可以防止修改，提高代码健壮性；同时节省空间</p><p>const变量默认为文件作用域，如果想在其他文件中使用，需要加extern</p><h4 id="修饰指针">修饰指针</h4><p><code>int const *p;</code> 或 <code>const int *p;</code>: const在*左边，无法通过指针修改这个变量的值<strong>指向常量的指针</strong></p><blockquote><p>无法通过这个指针修改，但仍然可以通过变量名、引用，或者其他指针修改</p></blockquote><p><code>int * const p</code>: const在*右边，指针指向的地址不能被修改 <strong>常指针</strong></p><blockquote><p>定义时必须初始化，常指针无法修改指向的地址，即使两个变量指向同一块地址</p></blockquote><h4 id="修饰引用">修饰引用</h4><p>同理，不能通过引用修改值，但仍可以通过变量名修改</p><h4 id="修饰函数返回类型">修饰函数返回类型</h4><p>函数返回值时，加const无意义，因为本身返回的值也会赋给其他变量，该值就可以通过其他变量修改</p><p>返回指针时同上</p><p><strong>修饰函数形参同上</strong></p><h4 id="修饰类、对象、成员函数">修饰类、对象、成员函数</h4><p>const对象只能访问const成员函数，const成员函数可以访问所有成员变量和其他const成员函数，但无法修改</p><h3 id="static">static</h3><p>为什么引入static：函数内部定义的变量，程序执行到时才分配内存到栈区，函数运行结束即释放。但有时候想要保存该变量的值到下一次调用，同时又不想改变该变量的访问范围</p><h4 id="修饰成员变量">修饰成员变量</h4><p>在程序启动时就被创建，不依赖类的对象，可以使用类名来直接调用</p><h4 id="修饰成员函数">修饰成员函数</h4><p>同样不依赖于类的对象，无法使用this指针，只能访问静态成员变量/函数</p><h3 id="struct和class">struct和class</h3><p>区别：struct的默认访问和继承权限是public，而class的默认访问和继承权限是private</p><h2 id="面向对象">面向对象</h2><h3 id="构造函数">构造函数</h3><p>编译器默认为每个对象提供空的构造函数和析构函数，以提供对象初始化和清理功能，也可以自定义</p><p><code>class_name()&#123;&#125;</code> 可以有参数，可以重载，程序调用对象前自动执行</p><p>编译器默认会给一个类添加三个函数：默认构造函数、拷贝构造函数、析构函数</p><p>如果定义了有参构造，编译器不再提供默认构造，需要手动定义；同理，如果要自定义拷贝构造函数，编译器也不会再自动生成其他构造函数</p><h3 id="析构函数">析构函数</h3><p><code>~class_name()&#123;&#125;</code> 不能有参数，无返回值，程序结束时自动调用</p><h3 id="深拷贝和浅拷贝">深拷贝和浅拷贝</h3><p>浅拷贝：只是简单的拷贝，指针指向的地址相同，两个对象指向同一块内存，释放一个对象的内存会导致另一个对象的内存无效</p><p>深拷贝：重新在堆区分配一块内存，将原对象的值拷贝到新的内存中，两个对象指向不同的内存</p><p>对于拷贝构造来说，如果类中有属性是在堆区开辟的（比如说被拷贝的对象中有指针，指针指向堆区new出来的一块内存），那么在拷贝时也需要重新在堆区开辟内存，并将原对象中的值拷贝到新的内存中</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Person</span> &#123;<br><span class="hljs-keyword">public</span>:<br><span class="hljs-built_in">Person</span>() &#123;&#125;<br><br>    <span class="hljs-built_in">Person</span>(<span class="hljs-type">int</span> age ,<span class="hljs-type">int</span> height) &#123;<br>m_age = age;<br>m_height = <span class="hljs-keyword">new</span> <span class="hljs-built_in">int</span>(height);<br>&#125;<br><br><span class="hljs-built_in">Person</span>(<span class="hljs-type">const</span> Person&amp; p) &#123;<br><span class="hljs-comment">//如果不利用深拷贝在堆区创建新内存，会导致浅拷贝带来的重复释放堆区问题</span><br>m_age = p.m_age;<br>m_height = <span class="hljs-keyword">new</span> <span class="hljs-built_in">int</span>(*p.m_height);<br>&#125;<br><br>~<span class="hljs-built_in">Person</span>() &#123;<br><span class="hljs-keyword">if</span> (m_height != <span class="hljs-literal">NULL</span>)&#123;<span class="hljs-keyword">delete</span> m_height;&#125;<br>&#125;<br><span class="hljs-keyword">public</span>:<br><span class="hljs-type">int</span> m_age;<br><span class="hljs-type">int</span>* m_height;<br>&#125;;<br></code></pre></td></tr></table></figure><p>如上，m_height本身是指针，构造时在堆区创建一块内存并指向该内存。如果在拷贝时仅仅做m_height = p.m_height，会导致两个对象指向同一块内存，释放一个对象的内存会导致另一个对象的内存无效</p><h3 id="构造与析构顺序">构造与析构顺序</h3><h4 id="继承">继承</h4><p>基类构造-&gt;派生类构造-&gt;派生类析构-&gt;基类析构</p><h4 id="成员对象">成员对象</h4><p>成员对象构造-&gt;外层对象构造-&gt;外层对象析构-&gt;成员对象析构</p><h3 id="this指针">this指针</h3><p>类的每个成员函数只会诞生一份函数实例放入代码区，多个同类型的对象会共用这份代码<br>在调用成员函数时，C++内置this指针，用于指向调用该函数的对象</p><h3 id="友元friend">友元friend</h3><h4 id="修饰全局函数">修饰全局函数</h4><p>将全局函数在类中声明为友元，就可以访问该类的私有成员</p><h4 id="修饰类">修饰类</h4><p>将类A在类B中声明为友元，A就可以访问B的私有成员</p><h4 id="修饰成员函数-2">修饰成员函数</h4><p>将类A的成员函数在类B中声明为友元，A的成员函数就可以访问B的私有成员</p><h3 id="继承-2">继承</h3><p>无论怎么继承，都无法访问从父类继承的私有成员。<br>私有成员还是会继承，但只是被隐藏了</p><h4 id="公共继承-class-A-public-B">公共继承 class A : public B</h4><p>父类中的公共和保护成员类型不变</p><h4 id="保护继承-class-A-protected-B">保护继承 class A : protected B</h4><p>父类中的公共和保护成员变为保护成员</p><h4 id="私有继承-class-A-private-B">私有继承 class A : private B</h4><p>父类中的公共和保护成员变为私有成员</p><h3 id="多态">多态</h3><p>如果有多个派生类且需要给他们分别实现一个同名的行为，比如说一个动物类，有狗、猫、猪等派生类，都有一个叫的行为，但是叫的实现不同，这时候就可以使用多态</p><p>多态的必须条件：父类指针指向子类对象，其实就是该指针将这个子类对象当作一个其父类，因此可以调用父类中的虚函数，同时由于指向的是子类对象，所以调用的是子类中重写的函数</p><h4 id="虚函数-virtual">虚函数 virtual</h4><p>在基类中，将需要多态的函数以virtual关键字声明，并在派生类中重写该函数。此后，若是<strong>父类指针指向子类对象</strong>时，并使用该指针调用多态函数，就会调用子类的函数</p><p>virtual的意思类似“这个函数可能会被子类重写”，告诉编译器先不急着确定函数地址，编译器会根据指针指向的对象来动态调用对应的函数</p><h4 id="纯虚函数">纯虚函数</h4><p>在需要使用多态的场景中，往往基类中的虚函数只是为了让派生类重写，并无实际意义，此时可将虚函数改为纯虚函数</p><p><code>virtual void func() = 0</code>，纯虚函数没有函数体，只是一个接口，派生类必须重写该函数</p><p>有纯虚函数以为着这个类仅仅用来声明派生类的接口，称为抽象类，无法被实例化</p><h4 id="虚析构">虚析构</h4><p>在父类指针指向子类对象时，如果释放该指针，只会调用父类的析构函数。这是因为在编译时，编译器只知道指针的<br>类型是父类，而不知道指针指向的是子类对象。</p><p>因此，如果想要调用子类的析构函数，需要将父类的析构函数声明为虚析构<code>virtual ~类名()&#123;&#125;</code></p><p>同理纯虚析构<code>virtual ~类名() = 0</code> 和纯虚函数一样，纯虚析构意味着该类是抽象类，除此之外和虚析构没啥区别</p><h3 id="模板-template-class-typename-T">模板 template&lt;class/typename T&gt;</h3><p>在下面的函数或者类中定义一种通用数据类型，在调用时可以指定具体的数据类型，提高代码复用</p><h3 id="STL：标准模板库">STL：标准模板库</h3><p>三大组件：容器、算法、迭代器<br>容器和算法之间通过迭代器无缝衔接</p>]]></content>
    
    
    <categories>
      
      <category>work</category>
      
    </categories>
    
    
    <tags>
      
      <tag>interview</tag>
      
      <tag>C++</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>linux &amp;&amp; docker杂记</title>
    <link href="/2024/02/29/linux-&amp;&amp;-docker%E6%9D%82%E8%AE%B0/"/>
    <url>/2024/02/29/linux-&amp;&amp;-docker%E6%9D%82%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[ <span id="more"></span><h2 id="Linux">Linux</h2><h3 id="系统启动过程">系统启动过程</h3><h4 id="内核引导">内核引导</h4><p>当计算机打开电源后，首先是BIOS开机自检，按照BIOS中设置的启动设备（通常是硬盘）来启动。操作系统接管硬件以后，首先读入 /boot 目录下的内核文件。</p><h4 id="init">init</h4><p>nit 进程是系统所有进程的起点，你可以把它比拟成系统所有进程的老祖宗，没有这个进程，系统中任何进程都不会启动。init 程序首先是需要读取配置文件 /etc/inittab</p><p><strong>运行级别</strong><br>许多程序需要开机启动。它们在Windows叫做&quot;服务&quot;（service），在Linux就叫做&quot;守护进程&quot;（daemon）。</p><p>init进程的一大任务，就是去运行这些开机启动的程序。</p><p>但是，不同的场合需要启动不同的程序，比如用作服务器时，需要启动Apache，用作桌面就不需要。</p><p>Linux允许为不同的场合，分配不同的开机启动程序，这就叫做&quot;运行级别&quot;（runlevel）。也就是说，启动时根据&quot;运行级别&quot;，确定要运行哪些程序。</p><p>Linux系统有7个运行级别(runlevel)：</p><ul><li>0：系统停机状态，系统默认运行级别不能设为0，否则不能正常启动</li><li>1：单用户工作状态，root权限，用于系统维护，禁止远程登录</li><li>2：多用户状态(没有NFS)</li><li>3：完全的多用户状态(有NFS)，登录后进入控制台命令行模式</li><li>4：系统未使用，保留</li><li>5：X11控制台，登录后进入图形GUI模式</li><li>6：系统正常关闭并重启，默认运行级别不能设为6，否则不能正常启动</li></ul><h4 id="系统初始化">系统初始化</h4><p>在init的配置文件中有这么一行： si::sysinit:/etc/rc.d/rc.sysinit　它调用执行了/etc/rc.d/rc.sysinit。</p><p>rc.sysinit是一个bash shell的脚本，它主要是完成一些系统初始化的工作，是每一个运行级别都要首先运行的重要脚本。</p><p>它主要完成的工作有：激活交换分区，检查磁盘，加载硬件模块以及其它一些需要优先执行任务。</p><p>如在/etc/inittab可能会看到某条目<code>l5:5:wait:/etc/rc.d/rc 5</code> 这个条目的格式是 id:runlevels:action:process，代表在运行级别 5 下，init 应该运行 /etc/rc.d/rc 5 脚本（该脚本意思是启动运行级别5下的所有守护进程），并等待它结束</p><h4 id="建立终端">建立终端</h4><p>在init执行完inittab中启动守护进程的条目后，接下来是打开终端以方便用户交互<br>如<code>1:2345:respawn:/sbin/mingetty tty1</code> 表示运行级别2、3、4、5下，init应该运行/sbin/mingetty tty1，而且当它结束时，init应该重新运行它</p><h3 id="目录结构">目录结构</h3><ul><li><p>/bin：<br>bin 是 Binaries (二进制文件) 的缩写, 这个目录存放着最经常使用的命令。</p></li><li><p>/boot：<br>这里存放的是启动 Linux 时使用的一些核心文件，包括一些连接文件以及镜像文件。</p></li><li><p>/dev ：<br>dev 是 Device(设备) 的缩写, 该目录下存放的是 Linux 的外部设备，在 Linux 中访问设备的方式和访问文件的方式是相同的。</p></li><li><p>/etc：<br>etc 是 Etcetera(等等) 的缩写,这个目录用来存放所有的系统管理所需要的配置文件和子目录。</p></li><li><p>/home：<br>用户的主目录，在 Linux 中，每个用户都有一个自己的目录，一般该目录名是以用户的账号命名的，如上图中的 alice、bob 和 eve。</p></li><li><p>/lib：<br>lib 是 Library(库) 的缩写这个目录里存放着系统最基本的动态连接共享库，其作用类似于 Windows 里的 DLL 文件。几乎所有的应用程序都需要用到这些共享库。</p></li><li><p>/lost+found：<br>这个目录一般情况下是空的，当系统非法关机后，这里就存放了一些文件。</p></li><li><p>/media：<br>linux 系统会自动识别一些设备，例如U盘、光驱等等，当识别后，Linux 会把识别的设备挂载到这个目录下。</p></li><li><p>/mnt：<br>系统提供该目录是为了让用户临时挂载别的文件系统的，我们可以将光驱挂载在 /mnt/ 上，然后进入该目录就可以查看光驱里的内容了。</p></li><li><p>/opt：<br>opt 是 optional(可选) 的缩写，这是给主机额外安装软件所摆放的目录。比如你安装一个ORACLE数据库则就可以放到这个目录下。默认是空的。</p></li><li><p>/proc：<br>proc 是 Processes(进程) 的缩写，/proc 是一种伪文件系统（也即虚拟文件系统），存储的是当前内核运行状态的一系列特殊文件，这个目录是一个虚拟的目录，它是系统内存的映射，我们可以通过直接访问这个目录来获取系统信息。<br>这个目录的内容不在硬盘上而是在内存里，我们也可以直接修改里面的某些文件，比如可以通过下面的命令来屏蔽主机的ping命令，使别人无法ping你的机器：<br>echo 1 &gt; /proc/sys/net/ipv4/icmp_echo_ignore_all</p></li><li><p>/root：<br>该目录为系统管理员，也称作超级权限者的用户主目录。</p></li><li><p>/sbin：<br>s 就是 Super User 的意思，是 Superuser Binaries (超级用户的二进制文件) 的缩写，这里存放的是系统管理员使用的系统管理程序。</p></li><li><p>/selinux：<br>这个目录是 Redhat/CentOS 所特有的目录，Selinux 是一个安全机制，类似于 windows 的防火墙，但是这套机制比较复杂，这个目录就是存放selinux相关的文件的。</p></li><li><p>/srv：<br>该目录存放一些服务启动之后需要提取的数据。</p></li><li><p>/sys：<br>这是 Linux2.6 内核的一个很大的变化。该目录下安装了 2.6 内核中新出现的一个文件系统 sysfs 。</p></li></ul><p>sysfs 文件系统集成了下面3种文件系统的信息：针对进程信息的 proc 文件系统、针对设备的 devfs 文件系统以及针对伪终端的 devpts 文件系统。</p><p>该文件系统是内核设备树的一个直观反映。</p><p>当一个内核对象被创建的时候，对应的文件和目录也在内核对象子系统中被创建。</p><ul><li><p>/tmp：<br>tmp 是 temporary(临时) 的缩写这个目录是用来存放一些临时文件的。</p></li><li><p>/usr：<br>usr 是 unix shared resources(共享资源) 的缩写，这是一个非常重要的目录，用户的很多应用程序和文件都放在这个目录下，类似于 windows 下的 program files 目录。</p></li><li><p>/usr/bin：<br>用户使用的应用程序。</p></li><li><p>/usr/sbin：<br>超级用户使用的比较高级的管理程序和系统守护程序。</p></li><li><p>/usr/src：<br>内核源代码默认的放置目录。</p></li><li><p>/var：<br>var 是 variable(变量) 的缩写，这个目录中存放着在不断扩充着的东西，我们习惯将那些经常被修改的目录放在这个目录下。包括各种日志文件。</p></li><li><p>/run：<br>是一个临时文件系统，存储系统启动以来的信息。当系统重启时，这个目录下的文件应该被删掉或清除。如果你的系统上有 /var/run 目录，应该让它指向 run。</p></li></ul><h3 id="文件基本属性">文件基本属性</h3><p>chown 修改所属用户及用户组 chmod修改文件权限<br><img src="image.png" alt="alt text"><br>把每一组rwx看作二进制计数，即chmod 777代表了文件所有者、文件所有者同组用户、其他用户都有rwx权限</p><h2 id="Docker">Docker</h2><p>Docker依赖于已存在并运行的Linux内核环境，因此windows上的Docker需要在虚拟机中运行</p><p>docker run：用于从一个 Docker 镜像创建并启动一个新的容器<br><code>docker run -it ubuntu:latest /bin/bash</code><br>-i代表容器的标准输入保持开启，即可以向容器发送输入<br>-t代表为容器分配一个伪终端，可以看到命令行</p><p>start：启动一个已经存在的容器</p><p>exec：对一个正在运行的容器执行一个命令<br><code>docker exec -it my_container /bin/bash</code><br>在exec之前容器就已经有一个或多个进程，因此exec的命令会在容器中启动一个新的进程，此时exit容器由于还有别的进程所以并不会直接停止</p><p>attach：为正在运行的容器启动一个shell，同样退出时不会停止容器</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Git cheat sheet</title>
    <link href="/2023/12/31/Git-cheat-sheet/"/>
    <url>/2023/12/31/Git-cheat-sheet/</url>
    
    <content type="html"><![CDATA[<p><a href="https://git-scm.com/book/zh/v2">Pro Git Book</a></p><span id="more"></span><h2 id="起步">起步</h2><h3 id="Git特色">Git特色</h3><p><strong>直接记录快照，而非差异比较</strong><br>与其他版本控制系统基于差异的版本控制不同，Git直接记录文件快照，每次提交或保存都会基于当前的全部文件创建一个快照并保存这个快照的索引。为了高效，如果文件没有变化，Git不会再次保存，而是只保留一个链接指向之前存储的文件。</p><p><strong>近乎所有操作都在本地执行</strong></p><p><strong>保证完整性</strong><br>Git中所有数据在存储前都会计算校验和（SHA-1），并以校验和的哈希值作为引用和索引。</p><p><strong>只添加数据</strong><br>几乎所有操作都只是添加，几乎没有导致文件不可恢复的操作。</p><p><strong>三种状态</strong></p><ul><li>modified：已修改，文件在工作区被修改，但还未保存到数据库中</li><li>staged：已暂存，修改的文件已经被做了标记，将被包含在下次提交中</li><li>commited：已提交，已经安全的保存在本地数据库中</li></ul><h3 id="运行前配置-git-config">运行前配置 git config</h3><p>配置文件优先级由低到高</p><ul><li>–system:针对该系统上所有用户的所有仓库的通用配置，一般在Git安装目录</li><li>–global:当前用户的所有仓库，一般在用户目录</li><li>–local:当前仓库，一般在当前仓库目录</li></ul><blockquote><p>git config --global <a href="http://user.name">user.name</a> “John Doe”<br>git config --global user.email <a href="mailto:johndoe@example.com">johndoe@example.com</a><br>git config --list  # 可能会有重复，因为Git会依次读取系统、全局、当前仓库的config，后面的会覆盖前面的同名配置</p></blockquote><h2 id="Cheat-Sheet">Cheat Sheet</h2><h3 id="Remote">Remote</h3><p>查看所有分支：<code>branch</code> -r远程，-a所有，-v附带详细信息</p><p>将本地的分支推送至远程仓库：<code>push &lt;remote&gt; &lt;local_branch&gt;:&lt;remote_branch&gt;</code></p><p>删除某远程分支：<code>push &lt;remote&gt; --delete &lt;branch_name&gt;</code></p><h3 id="Local">Local</h3><p>查看提交记录：<code>log</code> --pretty=oneline指定以一行的形式显示</p><p>比较差异：<code>diff &lt;hash1&gt; &lt;hash2&gt;</code></p><p>增删分支：<code>branch &lt;branch_name&gt;</code> -d删除 -t追踪远程分支</p><p>获取远程仓库数据：<code>fetch</code> 从远程仓库下载数据，但不会自动合并，后续需要merge或pull</p><p>撤销提交：<code>reset</code> --soft仅仅撤销提交，–mixed撤销提交并取消暂存区，–hard撤销提交并取消暂存区和工作区 HEAD~n表示前n个版本</p><h3 id="Index-Stage">Index/Stage</h3><p>提交到本地仓库：<code>commit</code> -a自动将所有已跟踪文件暂存起来并提交，相当于先执行add -u ，-m指定提交信息，–amend修改最后一次提交</p><p>比较当前index与某次提交的差异：<code>diff --cached &lt;hash&gt;</code></p><h3 id="Workspace">Workspace</h3><p>检查状态：<code>status</code> -s简洁</p><p>克隆远程仓库：<code>clone</code> 创建一个全新副本</p><p>从远程仓库拉取最新文件：<code>pull</code> 相当于fetch+merge</p><p>添加文件至Index：<code>add</code> -u更新已跟踪文件（即不包括新增文件），-A更新所有改动（包括新增文件），.当前目录所有文件</p><p>签出某个分支或提交或文件：<code>checkout</code> -b创建并签出新分支。如果签出的是一个特定提交，会处于&quot;detached HEAD&quot;状态，可以随意修改并提交，但这个提交不属于任何分支（但仍然存在，只要记得提交的哈希值），可以通过创建分支来保存</p><p>将某一分支的所有更改合并到当前分支：<code>merge &lt;branch_name&gt;</code>，Git默认使用Fast forward模式，即如果被合并分支是当前分支的直接后继，Git会将当前分支指向被合并分支的最新提交并不产生新提交；这时用–no-ff禁用Fast forward模式，仍然会产生一次新提交。如果并非直接前后继关系，Git会创建一个新的合并提交，该提交有两个父提交，即两个分支的最新提交。</p><p>变基：<code>rebase</code> 一般不用。</p><p>将其他分支的某个提交应用到当前分支：<code>cherry-pick &lt;hash&gt;</code>，会产生一个新的提交，提交内容（记得git是保存修改后文件的快照）与原提交相同。</p><p>回滚某提交：<code>revert &lt;hash&gt;</code>，会产生一个新的提交，提交内容与原提交相反。</p><p>清理未被跟踪的文件：<code>clean</code> -n列出将要被清理的文件，-f清理文件，-d清理文件夹，-x清理忽略的文件，-X清理忽略的文件夹</p><p>临时保存工作区和暂存区，将这些改动进栈：<code>stash</code> -u保存未被跟踪的文件，-a保存所有改动，-p交互式保存，-k不保存暂存区的改动</p><p>恢复工作区和暂存区：<code>stash pop</code> 恢复并删除栈顶的stash，<code>stash apply</code> 恢复但不删除栈顶的stash</p><h3 id="Stash">Stash</h3><p>显示栈：<code>stash list</code></p><p>入栈：<code>stash push</code> 默认入栈顶</p><p>显示栈的细节：<code>stash show</code> 默认栈顶</p><p>删除当个栈：<code>stash drop</code> 默认栈顶</p><p>清空整个stash：<code>stash clear</code></p>]]></content>
    
    
    <categories>
      
      <category>work</category>
      
    </categories>
    
    
    <tags>
      
      <tag>git</tag>
      
      <tag>cheat sheet</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>TVM源码-00</title>
    <link href="/2023/11/16/TVM%E6%BA%90%E7%A0%81-00/"/>
    <url>/2023/11/16/TVM%E6%BA%90%E7%A0%81-00/</url>
    
    <content type="html"><![CDATA[<p>TVM v0.8 源码学习</p><span id="more"></span><h2 id="代码拉取">代码拉取</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">git <span class="hljs-built_in">clone</span> --recursive https://github.com/apache/tvm.git<br>git checkout v0.8<br></code></pre></td></tr></table></figure><h2 id="编译安装">编译安装</h2><h3 id="编译常识">编译常识</h3><h4 id="GCC">GCC</h4><p>对于小项目来说，文件数量较少，使用GCC直接进行编译即可</p><ol><li>g++:将源文件编译成.out可执行文件</li><li>g++ -c:将源文件编译成中间文件 而不进行链接，即编译成.o文件</li><li>g++ -o:将源文件或者.o文件进行编译+链接或链接，生成.out文件</li><li>对于包含多个源文件的项目，可以将源文件分别gcc -c，再将产生的文件链接到一起，如<code>g++ -o myprogram file1.o file2.o</code></li></ol><h4 id="make-makefile">make &amp; makefile</h4><p>然而随着计算机的发展，一个软件工程包含的源文件越来越多，手动逐个编译完全不可行，于是有个make和makefile。</p><p>Make 是一个批处理工具，它根据 Makefile 文件中的规则来构建项目。Make 可以确定哪些文件需要重新编译，哪些文件已经是最新的，从而只编译需要编译的文件。</p><p>Makefile：Makefile 是 Make 的配置文件，它包含了一系列的规则，用于指定如何构建项目。Make 通过读取 Makefile 文件来构建项目。</p><p>在这一阶段，工程师可以手写项目的makefile文件，再使用make指令统一构建整个项目</p><h4 id="Cmake-CMakeLists">Cmake &amp; CMakeLists</h4><p>makefile在一些简单的工程下，完全可以人工手写，但是问题又来了，工程非常大的时候，连 makefile 的手写也非常麻烦，这时就需要一个工具可以自动生成 makefile ，这个工具就是cmake。</p><p>CMakeLists 是 Cmake 的配置文件。还是需要手写。</p><p>Cmake 会根据 CMakeLists 自动生成项目的 makefile 文件，然后再使用 make 构建项目。</p><p>Cmake 有不同的生成器，可以生成不同平台下的 makefile 文件，比如 Unix Makefile、Visual Studio、Ninja、Nmake等等，可以生成不同平台下的makefile，生成后再进行make就可以将项目构建在不同的平台下。</p><p>ninja是一种注重速度的生成器，使用ninja生成会产生一个build.ninja文件，然后使用ninja而非make进行构建</p><h3 id="编译TVM">编译TVM</h3><p>首先在 <a href="https://winlibs.com/">https://winlibs.com/</a> 拿到带 LLVM 库的 GCC 包，安装并加入环境变量，在cmd中可以使用 <code>llvm-config --libdir</code> 验证</p><p>创建build目录并<code>cp cmake/config.cmake build</code>并自定义配置，把USE LLVM打开</p><p>Conda创建tvm的虚拟环境，可以直接 <code>conda env create --file conda/build-environment.yaml</code> 但是使用该环境 git 会莫名奇妙出bug，不如手动创环境下载该文件中提到的依赖包</p><p>安装visual studio，把桌面C++开发组件勾上，安装完成后在cmd中使用<code>cl</code>验证（有没有可能除了装一个vs上述步骤全部不需要，但是不管了，官方文档安装部分相当混乱）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">mkdir</span> build<br><span class="hljs-built_in">cd</span> build<br>cmake -A x64 -Thost=x64 ..<br><span class="hljs-built_in">cd</span> ..<br>cmake --build build --config Release -- /m<br></code></pre></td></tr></table></figure><h3 id="安装python包">安装python包</h3><p>在import tvm时如果未找到包，vscode会自动在工作区下创建配置帮你把tvm的路径加到 <code>python.analysis.extraPaths</code> 但实测虽然变绿且鼠标可以左键跳转了，但解释器还是找不到，可能需要改全局的python路径啥的</p><p>不如直接安装，环境变量引入包的好处在于源码更改后，引入可以立即感知；而install的包在每次源码更改后要重新install才能生效。但是我使用的v0.8的源码，已经没有更新了，所以直接安装也ok</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> python<br>python setup.py install<br></code></pre></td></tr></table></figure><h2 id="用户手册">用户手册</h2><p>tvm/gallery</p><h3 id="introduction-py"><a href="http://introduction.py">introduction.py</a></h3><p><img src="image.png" alt="Alt text"></p><p>TVM编译步骤：</p><ol><li><p>从 TensorFlow、PyTorch 或 ONNX 等框架导入模型。在导入阶段中，TVM 可以从其他框架（如 TensorFlow、PyTorch 或 ONNX）中提取模型。 TVM 为前端提供的支持水平会随着我们不断改进这个开源项目而变化。如果在将模型导入 TVM 时遇到问题，可以将其转换为 ONNX。</p></li><li><p>翻译成 TVM 的高级模型语言 Relay。已导入 TVM 的模型在 Relay 中表示。Relay 是神经网络的功能语言和中间表示（IR）。Relay 应用图级优化 pass 来优化模型。</p></li><li><p>降级为张量表达式（TE）表示。降级是指将较高级的表示转换为较低级的表示。应用了高级优化之后，Relay 通过运行 FuseOps pass，把模型划分为许多小的子图，并将子图降级为 TE 表示。张量表达式（TE）是一种用于描述张量计算的领域特定语言。 TE 还提供了几个 schedule 原语来指定底层循环优化，例如循环切分、矢量化、并行化、循环展开和融合。为将 Relay 表示转换为 TE 表示，TVM 包含了一个张量算子清单（TOPI），其中包含常用张量算子的预定义模板（例如，conv2d、transpose）。</p></li><li><p>使用 auto-tuning 模块 AutoTVM 或 AutoScheduler 搜索最佳 schedule。schedule 为 TE 中定义的算子或子图指定底层循环优化。auto-tuning 模块搜索最佳 schedule，并将其与 cost model 和设备上的测量值进行比较。TVM 中有两个 auto-tuning 模块，AutoTVM（有模板）和Ansor（无模板）。</p></li><li><p>为模型编译选择最佳配置。调优后，auto-tuning 模块会生成 JSON 格式的调优记录。此步骤为每个子图选择最佳 schedule。</p></li><li><p>降级为张量中间表示（TIR，TVM 的底层中间表示）。基于调优步骤选择最佳配置后，所有 TE 子图降级为 TIR 并通过底层优化 pass 进行优化。接下来，优化的 TIR 降级为硬件平台的目标编译器。这是生成可部署到生产的优化模型的最终代码生成阶段。</p></li><li><p>编译成机器码。compiler-specific 的生成代码最终可降级为机器码。 TVM 可将模型编译为可链接对象模块，然后轻量级 TVM runtime 可以用 C 语言的 API 来动态加载模型，也可以为 Python 和 Rust 等其他语言提供入口点。或将 runtime 和模型放在同一个 package 里时，TVM 可以对其构建捆绑部署。</p></li></ol><h3 id="autotvm-relay-x86-py">autotvm_relay_x86.py</h3><p>使用TVM的Python API编译、训练和调优与训练的模型。</p><h4 id="导入依赖，并下载和加载ONNX模型">导入依赖，并下载和加载ONNX模型</h4><p>使用ResNet-50 v2，一个50层的用于图像分类的卷积神经网络，可以使用<a href="https://netron.app/">Netron</a>检查模型结构。输入图像为224×224，模型已经预训练好。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> onnx<br><span class="hljs-keyword">from</span> tvm.contrib.download <span class="hljs-keyword">import</span> download_testdata<br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> tvm.relay <span class="hljs-keyword">as</span> relay<br><span class="hljs-keyword">import</span> tvm<br><span class="hljs-keyword">from</span> tvm.contrib <span class="hljs-keyword">import</span> graph_executor<br><br>model_url = (<br>    <span class="hljs-string">&quot;https://github.com/onnx/models/raw/main/&quot;</span><br>    <span class="hljs-string">&quot;vision/classification/resnet/model/&quot;</span><br>    <span class="hljs-string">&quot;resnet50-v2-7.onnx&quot;</span><br>)<br><br>model_path = download_testdata(model_url, <span class="hljs-string">&quot;resnet50-v2-7.onnx&quot;</span>, module=<span class="hljs-string">&quot;onnx&quot;</span>)<br>onnx_model = onnx.load(model_path)<br><br><span class="hljs-comment"># 为 numpy 的 RNG 设置 seed，保证每次复现得到一致的结果</span><br>np.random.seed(<span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><h4 id="下载和预处理图像">下载和预处理图像</h4><p>将图像转为Numpy数组</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python">img_url = <span class="hljs-string">&quot;https://s3.amazonaws.com/model-server/inputs/kitten.jpg&quot;</span><br>img_path = download_testdata(img_url, <span class="hljs-string">&quot;imagenet_cat.png&quot;</span>, module=<span class="hljs-string">&quot;data&quot;</span>)<br><br><span class="hljs-comment"># 重设大小为 224x224</span><br>resized_image = Image.<span class="hljs-built_in">open</span>(img_path).resize((<span class="hljs-number">224</span>, <span class="hljs-number">224</span>))<br>img_data = np.asarray(resized_image).astype(<span class="hljs-string">&quot;float32&quot;</span>)<br><br><span class="hljs-comment"># 输入图像是 HWC 布局，而 ONNX 需要 CHW 输入，所以转换数组</span><br>img_data = np.transpose(img_data, (<span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>))<br><br><span class="hljs-comment"># 根据 ImageNet 输入规范进行归一化</span><br>imagenet_mean = np.array([<span class="hljs-number">0.485</span>, <span class="hljs-number">0.456</span>, <span class="hljs-number">0.406</span>]).reshape((<span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>imagenet_stddev = np.array([<span class="hljs-number">0.229</span>, <span class="hljs-number">0.224</span>, <span class="hljs-number">0.225</span>]).reshape((<span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>norm_img_data = (img_data / <span class="hljs-number">255</span> - imagenet_mean) / imagenet_stddev<br><br><span class="hljs-comment"># 添加 batch 维度，期望 4 维输入：NCHW。</span><br><span class="hljs-comment"># N:number of samples，即batch size C:channels H:height W:width</span><br>img_data = np.expand_dims(norm_img_data, axis=<span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><h4 id="使用Relay编译模型">使用Relay编译模型</h4><p>将模型转为Relay中间表示（IR）。首先用 from_onnx 导入器将模型导入到 Relay 中。然后，用标准优化，将模型构建到 TVM 库中，最后从库中创建一个 TVM 计算图 runtime 模块。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 输入名称可能因模型类型而异</span><br><span class="hljs-comment"># 可用 Netron 工具检查输入名称</span><br>input_name = <span class="hljs-string">&quot;data&quot;</span><br>target = <span class="hljs-string">&quot;llvm&quot;</span><br><br><span class="hljs-comment"># 定义输入的形状字典，键是模型固定的输入名称，值是输入形状，用于指定ONNX模型的输入形状</span><br>shape_dict = &#123;input_name: img_data.shape&#125;<br><br><span class="hljs-comment"># 将ONNX模型转换为Relay中间表示（IR）</span><br>mod, params = relay.frontend.from_onnx(onnx_model, shape_dict)<br><br><span class="hljs-comment"># 构建和编译模型</span><br><span class="hljs-keyword">with</span> tvm.transform.PassContext(opt_level=<span class="hljs-number">3</span>):<br>    <span class="hljs-comment"># 使用Relay构建模型并编译为目标为&quot;llvm&quot;的库</span><br>    lib = relay.build(mod, target=target, params=params)<br><br><span class="hljs-comment"># 创建&quot;llvm&quot;设备</span><br>dev = tvm.device(target, <span class="hljs-number">0</span>)<br><br><span class="hljs-comment"># 创建GraphModule并加载编译好的模块</span><br>module = graph_executor.GraphModule(lib[<span class="hljs-string">&quot;default&quot;</span>](dev))<br></code></pre></td></tr></table></figure><p><code>relay.frontend.from_onnx</code>接受一个ONNX模型和一个形状字典作为输入，返回一个Relay模块（mod）和一个参数字典（params）</p><p>mod是整个模型的计算图，params是模型的参数字典，包含了模型的权重和偏置等参数</p><p><code>tvm.transform.PassContext</code>是TVM控制优化过程的上下文，<code>opt_level=3</code>代表启用所有推荐优化<br>lib是编译后生成的模块库，包含模型计算图、参数和编译后的函数，它将可以被加载到一个GraphModule中，并在指定设备上执行</p><p><code>dev = tvm.device(target, 0)</code>和<code>module = graph_executor.GraphModule(lib[&quot;default&quot;](dev))</code> 分别创建了一个device对象和一个GraphModule对象（图执行模块）<br>可以在上面运行上面编译好的lib库</p><h4 id="使用模型进行推理">使用模型进行推理</h4><p>直接运行模型进行预测，并将输出转为可读形式。并收集此时还未优化过的模型基本性能数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 运行模型</span><br>dtype = <span class="hljs-string">&quot;float32&quot;</span><br>module.set_input(input_name, img_data)<br>module.run()<br>output_shape = (<span class="hljs-number">1</span>, <span class="hljs-number">1000</span>)<br>tvm_output = module.get_output(<span class="hljs-number">0</span>, tvm.nd.empty(output_shape)).numpy()<br><br><span class="hljs-keyword">from</span> scipy.special <span class="hljs-keyword">import</span> softmax<br><br><span class="hljs-comment"># 下载标签列表</span><br>labels_url = <span class="hljs-string">&quot;https://s3.amazonaws.com/onnx-model-zoo/synset.txt&quot;</span><br>labels_path = download_testdata(labels_url, <span class="hljs-string">&quot;synset.txt&quot;</span>, module=<span class="hljs-string">&quot;data&quot;</span>)<br><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(labels_path, <span class="hljs-string">&quot;r&quot;</span>) <span class="hljs-keyword">as</span> f:<br>    labels = [l.rstrip() <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> f]<br><br><span class="hljs-comment"># 打开输出文件并读取输出张量</span><br>scores = softmax(tvm_output)<br>scores = np.squeeze(scores)<br>ranks = np.argsort(scores)[::-<span class="hljs-number">1</span>]<br><span class="hljs-keyword">for</span> rank <span class="hljs-keyword">in</span> ranks[<span class="hljs-number">0</span>:<span class="hljs-number">5</span>]:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;class=&#x27;%s&#x27; with probability=%f&quot;</span> % (labels[rank], scores[rank]))<br><br><span class="hljs-comment"># 运行时间评估</span><br><span class="hljs-keyword">import</span> timeit<br>timing_number = <span class="hljs-number">10</span><br>timing_repeat = <span class="hljs-number">10</span><br>unoptimized = (<br>    np.array(timeit.Timer(<span class="hljs-keyword">lambda</span>: module.run()).repeat(repeat=timing_repeat, number=timing_number))<br>    * <span class="hljs-number">1000</span><br>    / timing_number<br>)<br>unoptimized = &#123;<br>    <span class="hljs-string">&quot;mean&quot;</span>: np.mean(unoptimized),<br>    <span class="hljs-string">&quot;median&quot;</span>: np.median(unoptimized),<br>    <span class="hljs-string">&quot;std&quot;</span>: np.std(unoptimized),<br>&#125;<br></code></pre></td></tr></table></figure><h4 id="输出后处理">输出后处理</h4><p>用专为该模型提供的查找表，运行一些后处理（post-processing），从而使得 ResNet-50 v2 的输出形式更具有可读性</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> scipy.special <span class="hljs-keyword">import</span> softmax<br><br><span class="hljs-comment"># 下载标签列表</span><br>labels_url = <span class="hljs-string">&quot;https://s3.amazonaws.com/onnx-model-zoo/synset.txt&quot;</span><br>labels_path = download_testdata(labels_url, <span class="hljs-string">&quot;synset.txt&quot;</span>, module=<span class="hljs-string">&quot;data&quot;</span>)<br><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(labels_path, <span class="hljs-string">&quot;r&quot;</span>) <span class="hljs-keyword">as</span> f:<br>    labels = [l.rstrip() <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> f]<br><br><span class="hljs-comment"># 打开输出文件并读取输出张量</span><br>scores = softmax(tvm_output)<br>scores = np.squeeze(scores)<br>ranks = np.argsort(scores)[::-<span class="hljs-number">1</span>]<br><span class="hljs-keyword">for</span> rank <span class="hljs-keyword">in</span> ranks[<span class="hljs-number">0</span>:<span class="hljs-number">5</span>]:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;class=&#x27;%s&#x27; with probability=%f&quot;</span> % (labels[rank], scores[rank]))<br></code></pre></td></tr></table></figure><h4 id="进行模型调优">进行模型调优</h4><p>用编译的模块推理，有时可能无法获得预期的性能。在这种情况下，可用自动调优器更好地配置模型，从而提高性能。 TVM 中的调优是指，在给定 target 上优化模型，使其运行得更快。与训练或微调不同，它不会影响模型的准确性，而只会影响 runtime 性能。作为调优过程的一部分，TVM 实现并运行许多不同算子的变体，以查看哪个性能最佳。这些运行的结果存储在调优记录文件中。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tvm.auto_scheduler <span class="hljs-keyword">as</span> auto_scheduler<br><span class="hljs-keyword">from</span> tvm.autotvm.tuner <span class="hljs-keyword">import</span> XGBTuner<br><span class="hljs-keyword">from</span> tvm <span class="hljs-keyword">import</span> autotvm<br><br>number = <span class="hljs-number">10</span><br>repeat = <span class="hljs-number">1</span><br>min_repeat_ms = <span class="hljs-number">0</span>  <span class="hljs-comment"># 调优 CPU 时设置为 0</span><br>timeout = <span class="hljs-number">10</span>  <span class="hljs-comment"># 秒</span><br><br><span class="hljs-comment"># 创建 TVM 运行器</span><br>runner = autotvm.LocalRunner(<br>    <span class="hljs-comment"># 将要测试的不同配置的数量</span><br>    number=number,<br>    <span class="hljs-comment"># 每个配置重复次数</span><br>    repeat=repeat,<br>    <span class="hljs-comment"># 每次测试运行时间上限</span><br>    timeout=timeout,<br>    <span class="hljs-comment"># 指定运行配置测试需要多长时间，如果重复次数低于此时间，则增加其值</span><br>    min_repeat_ms=min_repeat_ms,<br>    enable_cpu_cache_flush=<span class="hljs-literal">True</span>,<br>)<br><br>tuning_option = &#123;<br>    <span class="hljs-string">&quot;tuner&quot;</span>: <span class="hljs-string">&quot;xgb&quot;</span>,<br>    <span class="hljs-comment"># 试验次数，CPU上推荐1500，GPU推荐3000-4000，此处仅作展示用</span><br>    <span class="hljs-string">&quot;trials&quot;</span>: <span class="hljs-number">10</span>,<br>    <span class="hljs-comment"># 使搜索提前停止的实验最小值</span><br>    <span class="hljs-string">&quot;early_stopping&quot;</span>: <span class="hljs-number">100</span>,<br><br>    <span class="hljs-string">&quot;measure_option&quot;</span>: autotvm.measure_option(<br>        builder=autotvm.LocalBuilder(build_func=<span class="hljs-string">&quot;default&quot;</span>),<br>        runner=runner<br>    ),<br>    <span class="hljs-comment"># 调优数据保存的文件名</span><br>    <span class="hljs-string">&quot;tuning_records&quot;</span>: <span class="hljs-string">&quot;resnet-50-v2-autotuning.json&quot;</span>,<br>&#125;<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 首先从 onnx 模型中提取任务</span><br>tasks = autotvm.task.extract_from_program(mod[<span class="hljs-string">&quot;main&quot;</span>], target=target, params=params)<br><br><span class="hljs-keyword">for</span> i, task <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(tasks):<br>    prefix = <span class="hljs-string">&quot;[Task %2d/%2d] &quot;</span> % (i + <span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(tasks))<br>    tuner_obj = XGBTuner(task, loss_type=<span class="hljs-string">&quot;rank&quot;</span>)<br>    tuner_obj.tune(<br>        n_trial=<span class="hljs-built_in">min</span>(tuning_option[<span class="hljs-string">&quot;trials&quot;</span>], <span class="hljs-built_in">len</span>(task.config_space)),<br>        early_stopping=tuning_option[<span class="hljs-string">&quot;early_stopping&quot;</span>],<br>        measure_option=tuning_option[<span class="hljs-string">&quot;measure_option&quot;</span>],<br>        callbacks=[<br>            autotvm.callback.progress_bar(tuning_option[<span class="hljs-string">&quot;trials&quot;</span>], prefix=prefix),<br>            autotvm.callback.log_to_file(tuning_option[<span class="hljs-string">&quot;tuning_records&quot;</span>]),<br>        ],<br>    )<br></code></pre></td></tr></table></figure><h4 id="使用生成的调优数据优化编译模型">使用生成的调优数据优化编译模型</h4><p>获取上述存储在<code>resnet-50-v2-autotuning.json</code> 中的调优记录，并使用该结果为指定target上的模型生成高性能代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">with</span> autotvm.apply_history_best(tuning_option[<span class="hljs-string">&quot;tuning_records&quot;</span>]):<br>    <span class="hljs-keyword">with</span> tvm.transform.PassContext(opt_level=<span class="hljs-number">3</span>, config=&#123;&#125;):<br>        lib = relay.build(mod, target=target, params=params)<br><br>dev = tvm.device(<span class="hljs-built_in">str</span>(target), <span class="hljs-number">0</span>)<br>module = graph_executor.GraphModule(lib[<span class="hljs-string">&quot;default&quot;</span>](dev))<br><br><span class="hljs-comment"># 验证模型是否产生相同的结果</span><br>dtype = <span class="hljs-string">&quot;float32&quot;</span><br>module.set_input(input_name, img_data)<br>module.run()<br>output_shape = (<span class="hljs-number">1</span>, <span class="hljs-number">1000</span>)<br>tvm_output = module.get_output(<span class="hljs-number">0</span>, tvm.nd.empty(output_shape)).numpy()<br><br>scores = softmax(tvm_output)<br>scores = np.squeeze(scores)<br>ranks = np.argsort(scores)[::-<span class="hljs-number">1</span>]<br><span class="hljs-keyword">for</span> rank <span class="hljs-keyword">in</span> ranks[<span class="hljs-number">0</span>:<span class="hljs-number">5</span>]:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;class=&#x27;%s&#x27; with probability=%f&quot;</span> % (labels[rank], scores[rank]))<br></code></pre></td></tr></table></figure><h4 id="比较调优前后的模型性能">比较调优前后的模型性能</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> timeit<br><br>timing_number = <span class="hljs-number">10</span><br>timing_repeat = <span class="hljs-number">10</span><br>optimized = (<br>    np.array(timeit.Timer(<span class="hljs-keyword">lambda</span>: module.run()).repeat(repeat=timing_repeat, number=timing_number))<br>    * <span class="hljs-number">1000</span><br>    / timing_number<br>)<br>optimized = &#123;<span class="hljs-string">&quot;mean&quot;</span>: np.mean(optimized), <span class="hljs-string">&quot;median&quot;</span>: np.median(optimized), <span class="hljs-string">&quot;std&quot;</span>: np.std(optimized)&#125;<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;optimized: %s&quot;</span> % (optimized))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;unoptimized: %s&quot;</span> % (unoptimized))<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>work</category>
      
    </categories>
    
    
    <tags>
      
      <tag>TVM</tag>
      
      <tag>编译</tag>
      
      <tag>cmake</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>AI编译架构</title>
    <link href="/2023/10/16/AI%E7%BC%96%E8%AF%91%E6%9E%B6%E6%9E%84/"/>
    <url>/2023/10/16/AI%E7%BC%96%E8%AF%91%E6%9E%B6%E6%9E%84/</url>
    
    <content type="html"><![CDATA[<p>参考:</p><p><a href="https://github.com/BBuf/tvm_mlir_learn">TVM学习仓库</a></p><p><a href="https://space.bilibili.com/517221395/channel/collectiondetail?sid=857162">B站-zomi酱</a></p><p><a href="https://zhuanlan.zhihu.com/p/450022851">MLIR入门理解</a></p><span id="more"></span><h2 id="1-编译器相关">1. 编译器相关</h2><p>编译器（Compiler）和解释器（Interpreter）：</p><ul><li>编译器：将源代码整体编译为可执行文件（机器码），（可能经过预编译、编译、汇编、链接等环节，统一视作编译器的流程）最后由机器执行，会产生可以重复使用的中间文件和可执行文件</li><li>解释器：将源代码逐行解释成字节码并直接交由机器执行，不产生其他文件</li></ul><p>编译器编译方式：JIT 和 AOT</p><ul><li>AOT：AheadOfTime 即静态编译，源代码先统一编译成机器码，再执行</li><li>JIT：JustInTime 即动态编译，相比于传统 AOT，JIT 可以在程序运行过程中变运行边编译，具体流程可以参考 java。注意 JIT 与解释器的区别，解释器的粒度为一行源代码，而 JIT 的粒度为一个函数，JIT 编译的函数可以重复使用，而解释器每次都要重新解释一遍。</li></ul><p>一个 GCC 的标准编译流程：</p><ol><li>预处理：处理宏定义、文件包含、条件编译等信息，生成 .i 文件</li><li>编译：对 .i 文件进行语法分析，优化后生成 .s 汇编文件</li><li>汇编：将 .s 汇编文件汇编为机器码 .o 文件</li><li>链接：将程序运行所需要的目标文件、依赖库文件等统一打包链接成一个可执行文件</li></ol><p>LLVM 在 GCC 的基础上发展而来，早期苹果使用 GCC ，后来由于 GCC 证书以及苹果的商用需要，只能放弃 GCC 而单独发展出 LLVM，LLVM 本质算一个编译器的框架系统，使用模块化的方式，将编译器的前端、优化器、后端等模块分开，可以根据需要进行组合，比如目前主流的 Clang 就是 LLVM 的前端，而 LLVM 的后端可以生成多种平台的机器码，LLVM 的优化器也可以单独使用，这样就可以根据需要进行组合，而不是像 GCC 那样，前端、优化器、后端都是一体的，不可分割。</p><blockquote><p><em>LLVM is a sort of abstracted assembly language that compiler developers can target as a backend, and then LLVM itself comes packaged with a host of optimizations and “real” backend targets that can be compiled to. If you’re, say, the Rust programming language and you want to compile to x86, ARM, and WebAssembly without having to do all that work, you can just output LLVM code and then run LLVM’s compilation suite.</em></p></blockquote><p>PASS：编译器对源代码进行完整的扫描，进行优化和分析的步骤<br>IR：Intermediate Representation 中间表达</p><p>编译器基本结构（主要是 LLVM，GCC 分的没有这么明确）</p><ul><li>Front End：词法分析、语法分析，将源代码转换为抽象语法树（AST），LLVM 使用 Clang 作为前端</li><li>Optimizer：优化，将 IR 进行优化，使代码更高效（PASS 在这个地方）</li><li>Back End：代码生成，将 IR 转换为目标代码（机器码）</li></ul><p><img src="image.png" alt="Alt text"></p><blockquote><p>相关 <strong>Chris Lattner：The Golden Age of Compilers</strong></p></blockquote><p>AI 编译器是介于机器学习框架与硬件中间的一层，用于解决众多框架与多种硬件之间的适配问题，主要架构</p><ul><li>Front-end：计算图转换，将不同框架下的源代码输出为 Graph IR 等高阶 IR（HLIR），重点在于抽象出硬件无关的计算和控制流程，以及数据张量、算子的支持</li><li>Optimizer：对计算图进行一些算子融合、自动微分、并行切分、剪枝量化等优化，IR 间的相互转化，将高阶 IR 转换为低阶 IR（LLIR）</li><li>Back-end：针对特定的机器，将低级 IR 转换为 LLVM IR，再利用 LLVM 基础结构生成优化的机器码</li></ul><h2 id="2-TVM">2. TVM</h2><p>参考：</p><p><a href="https://tvm.hyper.ai/docs/arch/">TVM官方文档</a></p><p><a href="https://zhuanlan.zhihu.com/p/560210215">TVM学习指南</a></p><p>为什么使用 TVM：在模型部署时，众多的机器学习框架（Pytorch、TF、ONNX）与众多的平台（x86、arm、GPU）产生了众多不同的部署场景，而同一个模型在这些不同的场景之间是无法无缝切换的。TVM 的目标就是将这些不同的框架与平台进行统一，使得模型部署更加简单。</p><p>TVM 想要解决的问题：模型部署的可移植性问题、特定平台的硬件优化问题、软件栈的支持问题</p><h3 id="编译流程">编译流程</h3><p><img src="image0.png" alt="alt text"></p><p><img src="image1.png" alt="Alt text"></p><ol><li>TVM前端将如ONNX、Pytorch下的模型引入到IRModule中，将其翻译为relay（此时IRModule由一种高级表示relay.Function组成，一个relay.Function通常对应一个端到端的模型，可将其视为额外支持控制流、递归和复杂数据结构的计算图）</li><li>Relay经过第一次转换，即Relay Passes，主要是与硬件无关的转换（常量折叠、死码消除等）</li><li>在Relay优化的后期，TVM会运行一系列pass，以FuseOps（融合操作）开始，加上设备注解、布局重写、存储重写、图到函数转换等，将relay逐步转成te</li></ol><blockquote><p><em>重要的是，张量表达式te本身并不是一个可以存储到 IRModule 中的自包含函数（self-contained function）。相反，它是 IR 的一个片段，可以拼接起来构建一个 IRModule。</em></p></blockquote><ol start="4"><li>将te转为tir，使用autoTVM</li><li>tir经过一系列的tirPasses</li><li>IRMoudle转换成对应设备的runtime.Module由PackedFunc组成</li></ol><p>Relay IR：如 relay.Function，TVM 为了兼容上层的机器学习框架而引入的中间表达，一种高阶的图结构，包含了计算图和控制流的信息，这样的设计使得 TVM 可以对模型进行更加全面的优化。Relax 是下一代 Relay（Relay Next）</p><p>Tensor IR：如 tir.PrinFunc，TVM 为了兼容不同的硬件而引入的中间表达，一种低阶的图结构，包含了数据张量和算子的信息，这样的设计使得 TVM 可以对硬件进行更加全面的优化。</p><p>IRModule：是TVM堆栈中的主要数据结构，也是TVM编译的最小完整单元，在上层一般由一个或多个relay.Function组成。一个 RelayFunc 通常对应一个端到端的模型（可见MLC）。经过 TIR Pass 后一个 RelayFunc 可降级为多个 tir.PrimFunc 即元张量函数，这些函数可以被 TVM 优化器进行优化，最后转化为机器码。</p><h4 id="Pass-转换">Pass 转换</h4><p>TVM转换流程的目的：优化（如常量折叠、死码消除，针对特定张量的布局转换、scale因子折叠），以及降级（将代码逐渐转化成更接近硬件的低级表示。</p><p>在 relay/transform 流程的后期，FuseOps 将端到端的函数（即 relay.Function）转化为一个个的算子（即 tir.PrinFunc），这个过程帮助将原始的编译问题分为了两个子问题：</p><ol><li>算子的编译和优化</li><li>整体的执行流程：对生成的算子进行的调用</li></ol><p>tir/transform 流程主要处理 tir.PrimFunc 的降级，例如有些 pass 将多维访问展平为一维指针访问，将内联函数扩展至特定硬件的函数等。也有一些pass的目的仍是优化，如访问索引简化和死码消除。</p><h4 id="AutoTVM：搜索空间和基于学习的转换">AutoTVM：搜索空间和基于学习的转换</h4><p>上述的转换都是确定且基于某一规则的。TVM的目标之一是支持不同硬件平台的高性能代码优化，因此往往要研究尽可能多的优化选择，包括多维张量访问、循环分块策略、特殊加速器内存。</p><p>首先定义一组用来转换程序的操作，包括循环转换、内联、向量化等，称为调度原语，这种原语组成的集合定义了可用于程序优化的搜索空间。接下来，系统搜索不同的可能调度序列，找到最佳（极佳）的调度组合。</p><p>AutoTVM和AutoScheduler是TVM中的两个自动调度器，AutoTVM是基于遗传算法的调度器，AutoScheduler是基于机器学习的调度器。在官方文档中似乎统一为AutoTVM介绍了。</p><blockquote><p><em>使用基于搜索的优化来处理初始 tir 函数生成问题。</em></p></blockquote><p>AutoTVM是在tirPass之前进行的，经过AutoTVM后生成优化的PrinFunc，可以理解成到tirPass之后就不再进行高层优化了，只是针对硬件做一些特殊处理？</p><h4 id="Target-转换">Target 转换</h4><p>这一阶段将 tir 的 IRModule 转换为相应硬件的可执行形式。对于 x86 和 ARM 等后端，使用 LLVM IRBuilder 来构建内存中的 LLVM IR。还可以生成源代码级语言，例如 CUDA C 和 OpenCL。最后，还支持通过外部代码生成器将 Relay 函数（子图）直接转换为特定 target 。</p><p><strong>重要的是，这一阶段的转换要尽可能轻量级，因为绝大多数转换和降级都在之前的阶段完成</strong></p><h4 id="Runtime-执行">Runtime 执行</h4><blockquote><p><em>TVM runtime 的主要目标是提供一个最小的 API，从而能以选择的语言（包括 Python、C++、Rust、Go、Java 和 JavaScript）加载和执行编译好的工件</em></p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tvm<br><span class="hljs-comment"># Python 中 runtime 执行程序示例，带有类型注释</span><br>mod: tvm.runtime.Module = tvm.runtime.load_module(<span class="hljs-string">&quot;compiled_artifact.so&quot;</span>)<br>arr: tvm.runtime.NDArray = tvm.nd.array([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>], device=tvm.cuda(<span class="hljs-number">0</span>))<br>fun: tvm.runtime.PackedFunc = mod[<span class="hljs-string">&quot;addone&quot;</span>]<br>fun(a)<br><span class="hljs-built_in">print</span>(a.numpy())<br></code></pre></td></tr></table></figure><p>tvm.runtime.Module 封装了编译的结果。runtime.Module 包含一个 GetFunction 方法，用于按名称获取 PackedFuncs。</p><p>tvm.runtime.PackedFunc 是一种为各种构造函数消解类型的函数接口。runtime.PackedFunc 的参数和返回值的类型如下：POD 类型（int, float）、string、runtime.PackedFunc、runtime.Module、runtime.NDArray 和 runtime.Object 的其他子类。</p><p>tvm.runtime.Module 和 tvm.runtime.PackedFunc 是模块化 runtime 的强大机制。例如，要在 CUDA 上获取上述 addone 函数，可以用 LLVM 生成主机端代码来计算启动参数（例如线程组的大小），然后用 CUDA 驱动程序 API 支持的 CUDAModule 调用另一个 PackedFunc。OpenCL 内核也有相同的机制。</p><p>下面的代码片段给出了用相同接口执行端到端模型的示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tvm<br><span class="hljs-comment"># python 中 runtime 执行程序的示例，带有类型注释</span><br>factory: tvm.runtime.Module = tvm.runtime.load_module(<span class="hljs-string">&quot;resnet18.so&quot;</span>)<br><span class="hljs-comment"># 在 cuda(0) 上为 resnet18 创建一个有状态的图执行模块</span><br>gmod: tvm.runtime.Module = factory[<span class="hljs-string">&quot;resnet18&quot;</span>](tvm.cuda(<span class="hljs-number">0</span>))<br>data: tvm.runtime.NDArray = get_input_data()<br><span class="hljs-comment"># 设置输入</span><br>gmod[<span class="hljs-string">&quot;set_input&quot;</span>](<span class="hljs-number">0</span>, data)<br><span class="hljs-comment"># 执行模型</span><br>gmod[<span class="hljs-string">&quot;run&quot;</span>]()<br><span class="hljs-comment"># 得到输出</span><br>result = gmod[<span class="hljs-string">&quot;get_output&quot;</span>](<span class="hljs-number">0</span>).numpy()<br></code></pre></td></tr></table></figure><p>主要的结论是 runtime.Module 和 runtime.PackedFunc 可以封装算子级别的程序（例如 addone），以及端到端模型。</p><h3 id="逻辑架构组件">逻辑架构组件</h3><p><img src="image2.png" alt="Alt text"></p><h2 id="3-MLIR">3. MLIR</h2><p>参考<br><a href="https://www.lei.chat/zh/posts/compilers-and-irs-llvm-ir-spirv-and-mlir/">某大佬博客</a></p>]]></content>
    
    
    <categories>
      
      <category>work</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>LLVM</tag>
      
      <tag>MLIR</tag>
      
      <tag>TVM</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Texas Hold&#39;em</title>
    <link href="/2023/09/25/%E5%BE%B7%E5%B7%9E%E6%89%91%E5%85%8B%E5%AD%A6%E4%B9%A0/"/>
    <url>/2023/09/25/%E5%BE%B7%E5%B7%9E%E6%89%91%E5%85%8B%E5%AD%A6%E4%B9%A0/</url>
    
    <content type="html"><![CDATA[<blockquote><p><em>博弈论的基础建立在理性人假设之上：玩家是理性且自利的</em></p></blockquote><span id="more"></span><h2 id="概率">概率</h2><blockquote><p>VScode的Markdown preview enhanced（MPE）插件支持 Mathjax 和 Katex，可以实时预览Latex公式，完全没必要花两个小时装Texlive</p></blockquote><table><thead><tr><th style="text-align:center">牌型</th><th style="text-align:center">翻牌后</th></tr></thead><tbody><tr><td style="text-align:center">Royal Flush</td><td style="text-align:center"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>4</mn><msubsup><mi>C</mi><mn>52</mn><mn>5</mn></msubsup></mfrac><mo>=</mo><mfrac><mn>1</mn><mn>649740</mn></mfrac><mo>≈</mo><mn>0.00015</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">\frac{4}{C^5_{52}} = \frac{1}{649740} \approx 0.00015\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.4367em;vertical-align:-0.5916em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.6264em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8051em;"><span style="top:-2.1885em;margin-left:-0.0715em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">52</span></span></span></span><span style="top:-2.8448em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3115em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">4</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5916em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">649740</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">0.00015%</span></span></span></span></td></tr><tr><td style="text-align:center">Straight Flush</td><td style="text-align:center"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mn>649740</mn></mfrac><mo>×</mo><mn>10</mn><mo>≈</mo><mn>0.0015</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">\frac{1}{649740} \times 10 \approx  0.0015\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">649740</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">10</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">0.0015%</span></span></span></span></td></tr><tr><td style="text-align:center">Four-of-a-Kind</td><td style="text-align:center"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mn>13</mn><mo>∗</mo><mn>48</mn></mrow><msubsup><mi>C</mi><mn>52</mn><mn>5</mn></msubsup></mfrac><mo>=</mo><mfrac><mn>1</mn><mn>4165</mn></mfrac><mo>≈</mo><mn>0.024</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">\frac{13*48}{C^5_{52}} = \frac{1}{4165} \approx 0.024\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.4367em;vertical-align:-0.5916em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.6264em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8051em;"><span style="top:-2.1885em;margin-left:-0.0715em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">52</span></span></span></span><span style="top:-2.8448em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3115em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">13</span><span class="mbin mtight">∗</span><span class="mord mtight">48</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5916em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">4165</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">0.024%</span></span></span></span></td></tr><tr><td style="text-align:center">Full House</td><td style="text-align:center"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mn>13</mn><mo>∗</mo><mn>4</mn><mo>∗</mo><mn>12</mn><mo>∗</mo><mn>6</mn></mrow><msubsup><mi>C</mi><mn>52</mn><mn>5</mn></msubsup></mfrac><mo>=</mo><mfrac><mn>1</mn><mn>694</mn></mfrac><mo>≈</mo><mn>0.144</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">\frac{13*4*12*6}{C^5_{52}} = \frac{1}{694} \approx 0.144\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.4367em;vertical-align:-0.5916em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.6264em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8051em;"><span style="top:-2.1885em;margin-left:-0.0715em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">52</span></span></span></span><span style="top:-2.8448em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3115em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">13</span><span class="mbin mtight">∗</span><span class="mord mtight">4</span><span class="mbin mtight">∗</span><span class="mord mtight">12</span><span class="mbin mtight">∗</span><span class="mord mtight">6</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5916em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">694</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">0.144%</span></span></span></span></td></tr><tr><td style="text-align:center">Flush</td><td style="text-align:center"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mn>4</mn><mo>∗</mo><msubsup><mi>C</mi><mn>13</mn><mn>5</mn></msubsup></mrow><msubsup><mi>C</mi><mn>52</mn><mn>5</mn></msubsup></mfrac><mo>≈</mo><mn>0.2</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">\frac{4*C^5_{13}}{C^5_{52}} \approx 0.2\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.7258em;vertical-align:-0.5916em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1341em;"><span style="top:-2.6264em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8051em;"><span style="top:-2.1885em;margin-left:-0.0715em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">52</span></span></span></span><span style="top:-2.8448em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3115em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.5102em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">4</span><span class="mbin mtight">∗</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.214em;margin-left:-0.0715em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">13</span></span></span></span><span style="top:-2.931em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5916em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">0.2%</span></span></span></span></td></tr><tr><td style="text-align:center">Straight</td><td style="text-align:center"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mn>10</mn><mo>∗</mo><msup><mn>4</mn><mn>5</mn></msup></mrow><msubsup><mi>C</mi><mn>52</mn><mn>5</mn></msubsup></mfrac><mo>≈</mo><mn>0.39</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">\frac{10*4^5}{C^5_{52}} \approx 0.39\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.6096em;vertical-align:-0.5916em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0179em;"><span style="top:-2.6264em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8051em;"><span style="top:-2.1885em;margin-left:-0.0715em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">52</span></span></span></span><span style="top:-2.8448em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3115em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">10</span><span class="mbin mtight">∗</span><span class="mord mtight"><span class="mord mtight">4</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.931em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">5</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5916em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">0.39%</span></span></span></span></td></tr><tr><td style="text-align:center">Three-of-a-Kind</td><td style="text-align:center"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mn>13</mn><mo>∗</mo><mn>4</mn><mo>∗</mo><msubsup><mi>C</mi><mn>12</mn><mn>2</mn></msubsup><mo>∗</mo><msup><mn>4</mn><mn>2</mn></msup></mrow><msubsup><mi>C</mi><mn>52</mn><mn>5</mn></msubsup></mfrac><mo>≈</mo><mn>2.1</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">\frac{13*4*C^2_{12}*4^2}{C^5_{52}} \approx 2.1\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.7258em;vertical-align:-0.5916em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1341em;"><span style="top:-2.6264em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8051em;"><span style="top:-2.1885em;margin-left:-0.0715em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">52</span></span></span></span><span style="top:-2.8448em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3115em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.5102em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">13</span><span class="mbin mtight">∗</span><span class="mord mtight">4</span><span class="mbin mtight">∗</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.214em;margin-left:-0.0715em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">12</span></span></span></span><span style="top:-2.931em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286em;"><span></span></span></span></span></span></span><span class="mbin mtight">∗</span><span class="mord mtight"><span class="mord mtight">4</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.931em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5916em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">2.1%</span></span></span></span></td></tr><tr><td style="text-align:center">TwoPair</td><td style="text-align:center"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><msubsup><mi>C</mi><mn>13</mn><mn>2</mn></msubsup><mo>∗</mo><msup><mn>6</mn><mn>2</mn></msup><mo>∗</mo><mn>44</mn></mrow><msubsup><mi>C</mi><mn>52</mn><mn>5</mn></msubsup></mfrac><mo>≈</mo><mn>4.75</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">\frac{C^2_{13}*6^2*44}{C^5_{52}} \approx 4.75\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.7258em;vertical-align:-0.5916em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1341em;"><span style="top:-2.6264em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8051em;"><span style="top:-2.1885em;margin-left:-0.0715em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">52</span></span></span></span><span style="top:-2.8448em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3115em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.5102em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.214em;margin-left:-0.0715em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">13</span></span></span></span><span style="top:-2.931em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286em;"><span></span></span></span></span></span></span><span class="mbin mtight">∗</span><span class="mord mtight"><span class="mord mtight">6</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.931em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mbin mtight">∗</span><span class="mord mtight">44</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5916em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">4.75%</span></span></span></span></td></tr><tr><td style="text-align:center">OnePair</td><td style="text-align:center"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mn>13</mn><mo>∗</mo><msubsup><mi>C</mi><mn>4</mn><mn>2</mn></msubsup><mo>∗</mo><msubsup><mi>C</mi><mn>12</mn><mn>3</mn></msubsup><mo>∗</mo><msup><mn>4</mn><mn>3</mn></msup></mrow><msubsup><mi>C</mi><mn>52</mn><mn>5</mn></msubsup></mfrac><mo>≈</mo><mn>42.3</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">\frac{13*C^2_{4}*C^3_{12}*4^3}{C^5_{52}} \approx 42.3\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.7258em;vertical-align:-0.5916em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1341em;"><span style="top:-2.6264em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8051em;"><span style="top:-2.1885em;margin-left:-0.0715em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">52</span></span></span></span><span style="top:-2.8448em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3115em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.5102em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">13</span><span class="mbin mtight">∗</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.214em;margin-left:-0.0715em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">4</span></span></span></span><span style="top:-2.931em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286em;"><span></span></span></span></span></span></span><span class="mbin mtight">∗</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.214em;margin-left:-0.0715em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">12</span></span></span></span><span style="top:-2.931em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286em;"><span></span></span></span></span></span></span><span class="mbin mtight">∗</span><span class="mord mtight"><span class="mord mtight">4</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.931em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5916em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">42.3%</span></span></span></span></td></tr><tr><td style="text-align:center">Single</td><td style="text-align:center"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><msubsup><mi>C</mi><mn>13</mn><mn>5</mn></msubsup><mo>∗</mo><msup><mn>4</mn><mn>5</mn></msup></mrow><msubsup><mi>C</mi><mn>52</mn><mn>5</mn></msubsup></mfrac><mo>≈</mo><mn>50.7</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">\frac{C^5_{13} * 4^5}{C^5_{52}} \approx 50.7\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.7258em;vertical-align:-0.5916em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1341em;"><span style="top:-2.6264em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8051em;"><span style="top:-2.1885em;margin-left:-0.0715em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">52</span></span></span></span><span style="top:-2.8448em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3115em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.5102em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.214em;margin-left:-0.0715em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">13</span></span></span></span><span style="top:-2.931em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286em;"><span></span></span></span></span></span></span><span class="mbin mtight">∗</span><span class="mord mtight"><span class="mord mtight">4</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.931em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">5</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5916em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">50.7%</span></span></span></span></td></tr></tbody></table><h3 id="四二法则">四二法则</h3><p>Flop后听N张牌，则最终成牌的概率约为4N%，Turn后听N张牌，则最终成牌的概率约为2N%</p><p>Flop后成牌概率为：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>−</mo><mo stretchy="false">(</mo><mfrac><mrow><mn>47</mn><mo>−</mo><mi>N</mi></mrow><mn>47</mn></mfrac><mo>×</mo><mfrac><mrow><mn>46</mn><mo>−</mo><mi>N</mi></mrow><mn>46</mn></mfrac><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mn>93</mn><mi>N</mi><mo>−</mo><msup><mi>N</mi><mn>2</mn></msup></mrow><mrow><mn>47</mn><mo>×</mo><mn>46</mn></mrow></mfrac></mrow><annotation encoding="application/x-tex">1 -(\frac{47-N }{47} \times \frac{46-N}{46} ) = \frac{93N-N^2}{47\times46}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.2173em;vertical-align:-0.345em;"></span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8723em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">47</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">47</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.2173em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8723em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">46</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">46</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.4213em;vertical-align:-0.4033em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0179em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">47</span><span class="mbin mtight">×</span><span class="mord mtight">46</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">93</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="mbin mtight">−</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-2.931em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4033em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><br>在Desmos中可以看出，当N在10以内时，四二法则的误差在 +1.6% 以内</p><p>Turn后成牌概率为：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mi>N</mi><mn>46</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{N}{46}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2173em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8723em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">46</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><br>当N在10以内时，误差在 -1.7% 以内</p><h3 id="翻前胜率">翻前胜率</h3><h3 id="翻后策略求解">翻后策略求解</h3><p><a href="https://github.com/bupticybee/TexasSolver">TexasSolver</a></p><h3 id="期望价值">期望价值</h3><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mi>V</mi><mo>=</mo><mtext>正向收益</mtext><mo>∗</mo><mtext>获胜概率</mtext><mo>+</mo><mtext>负向收益</mtext><mo>∗</mo><mtext>失败概率</mtext></mrow><annotation encoding="application/x-tex">EV = 正向收益 * 获胜概率 + 负向收益 * 失败概率</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord cjk_fallback">正向收益</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord cjk_fallback">获胜概率</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord cjk_fallback">负向收益</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord cjk_fallback">失败概率</span></span></span></span></p><p>即 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mi>V</mi><mo>=</mo><mi>P</mi><mi>o</mi><mi>t</mi><mo>×</mo><mi>W</mi><mi>i</mi><mi>n</mi><mi>R</mi><mi>a</mi><mi>t</mi><mi>e</mi><mo>−</mo><mi>B</mi><mi>e</mi><mi>t</mi><mo>×</mo><mi>L</mi><mi>o</mi><mi>s</mi><mi>e</mi><mi>R</mi><mi>a</mi><mi>t</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">EV = Pot \times WinRate - Bet \times LoseRate</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal">o</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">Win</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord mathnormal">e</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">L</span><span class="mord mathnormal">ose</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span></span></span></span></p><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mi>V</mi><mo>≥</mo><mn>0</mn><mo>⇔</mo><mi>B</mi><mi>e</mi><mi>t</mi><mo>≤</mo><mi>P</mi><mi>o</mi><mi>t</mi><mo>×</mo><mfrac><mrow><mi>W</mi><mi>i</mi><mi>n</mi><mi>R</mi><mi>a</mi><mi>t</mi><mi>e</mi></mrow><mrow><mn>1</mn><mo>−</mo><mi>W</mi><mi>i</mi><mi>n</mi><mi>R</mi><mi>a</mi><mi>t</mi><mi>e</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">EV \geq 0 \Leftrightarrow Bet \leq Pot \times \frac{WinRate}{1 - WinRate}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8193em;vertical-align:-0.136em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">⇔</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8193em;vertical-align:-0.136em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord mathnormal">e</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal">o</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.2757em;vertical-align:-0.4033em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8723em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight">Win</span><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">e</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">Win</span><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4033em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p><table><thead><tr><th style="text-align:center">胜率</th><th style="text-align:center">下注量(*Pot)</th></tr></thead><tbody><tr><td style="text-align:center">8%</td><td style="text-align:center">0.09</td></tr><tr><td style="text-align:center">16%</td><td style="text-align:center">0.19</td></tr><tr><td style="text-align:center">32%</td><td style="text-align:center">0.47</td></tr><tr><td style="text-align:center">50%</td><td style="text-align:center">1</td></tr><tr><td style="text-align:center">67%</td><td style="text-align:center">2</td></tr></tbody></table><h2 id="策略">策略</h2><p>参考</p><ul><li><a href="https://space.bilibili.com/2143447">https://space.bilibili.com/2143447</a></li><li><a href="https://www.youtube.com/@ronniepoker">https://www.youtube.com/@ronniepoker</a></li></ul><h2 id="GTO">GTO</h2>]]></content>
    
    
    <categories>
      
      <category>interest</category>
      
    </categories>
    
    
    <tags>
      
      <tag>德扑</tag>
      
      <tag>博弈论</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Machine Learning Compilation</title>
    <link href="/2023/09/21/Machine-Learning-Compilation/"/>
    <url>/2023/09/21/Machine-Learning-Compilation/</url>
    
    <content type="html"><![CDATA[<p>陈天奇的MLC课程，参考</p><p><a href="https://github.com/BBuf/tvm_mlir_learn">TVM学习仓库</a></p><p><a href="https://mlc.ai/zh/index.html">MLC官方课程文档</a></p><p><a href="https://space.bilibili.com/1663273796/channel/collectiondetail?sid=499979">MLC课程视频</a></p><span id="more"></span><h2 id="1-概述">1.概述</h2><p>定义：将机器学习的算法（模型）从开发形式（如pytorch、tf等通用框架编写的模型描述以及相关权重），通过变换和优化，转化为部署形式（如模型支撑代码、内存控制、接口等）<br>即，将神经网络模型转变成在特定硬件上运行的张量函数代码</p><p>机器学习编译目标：</p><ol><li>集成和最小化依赖</li><li>利用硬件加速：利用到每个部署环境的原生加速技术</li><li>通用优化</li></ol><h2 id="2-张量程序抽象">2. 张量程序抽象</h2><p>元张量函数：机器学习模型执行中的每一个步骤（或者说算子？），如linear、relu、softmax</p><p>许多不同的抽象可以表达同一种元张量函数，如torch.add和numpy.add，同时，有些机器学习框架也提供模型的编译过程优化，将元张量函数转变成更专门的、针对性的函数</p><p>张量程序抽象：一个典型的元张量函数实现包括：</p><ol><li>存储数据的多维数组</li><li>驱动张量计算的循环嵌套</li><li>计算语句</li></ol><p>根据抽象出来的共同特征，元张量函数因此可以被一系列有效的程序变换所改变，即优化。<br>一般情况下，我们感兴趣的大部分元张量函数都具有良好的可变换属性。</p><h3 id="TensorIR：TVM使用的张量程序抽象">TensorIR：TVM使用的张量程序抽象</h3><p>前提：大多数的机器学习编译可以视为张量函数之间的变换</p><h4 id="示例：一个经典的点积-relu-网络">示例：一个经典的点积 + relu 网络</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">dtype = <span class="hljs-string">&quot;float32&quot;</span><br>a_np = np.random.rand(<span class="hljs-number">128</span>, <span class="hljs-number">128</span>).astype(dtype)<br>b_np = np.random.rand(<span class="hljs-number">128</span>, <span class="hljs-number">128</span>).astype(dtype)<br>c_mm_relu = np.maximum(a_np @ b_np, <span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><p>在底层，numpy可能使用循环和算术运算实现上述操作：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">lnumpy_mm_relu</span>(<span class="hljs-params">A: np.ndarray, B: np.ndarray, C: np.ndarray</span>):<br>    <span class="hljs-comment"># 存储数据的多维数组</span><br>    Y = np.empty((<span class="hljs-number">128</span>, <span class="hljs-number">128</span>), dtype=<span class="hljs-string">&quot;float32&quot;</span>)<br>    <span class="hljs-comment"># 驱动张量计算的循环嵌套</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">128</span>):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">128</span>):<br>            <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">128</span>):<br>                <span class="hljs-keyword">if</span> k == <span class="hljs-number">0</span>:<br>                    Y[i, j] = <span class="hljs-number">0</span><br>                <span class="hljs-comment"># 计算语句</span><br>                Y[i, j] = Y[i, j] + A[i, k] * B[k, j]<br>    <span class="hljs-comment"># 驱动张量计算的循环嵌套</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">128</span>):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">128</span>):<br>            <span class="hljs-comment"># 计算语句</span><br>            C[i, j] = <span class="hljs-built_in">max</span>(Y[i, j], <span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><h4 id="TensorIR实现：">TensorIR实现：</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@tvm.script.ir_module</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyModule</span>:<br><span class="hljs-meta">    @T.prim_func</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">mm_relu</span>(<span class="hljs-params">A: T.Buffer(<span class="hljs-params">(<span class="hljs-params"><span class="hljs-number">128</span>, <span class="hljs-number">128</span></span>), <span class="hljs-string">&quot;float32&quot;</span></span>),</span><br><span class="hljs-params">                B: T.Buffer(<span class="hljs-params">(<span class="hljs-params"><span class="hljs-number">128</span>, <span class="hljs-number">128</span></span>), <span class="hljs-string">&quot;float32&quot;</span></span>),</span><br><span class="hljs-params">                C: T.Buffer(<span class="hljs-params">(<span class="hljs-params"><span class="hljs-number">128</span>, <span class="hljs-number">128</span></span>), <span class="hljs-string">&quot;float32&quot;</span></span>)</span>):<br>        T.func_attr(&#123;<span class="hljs-string">&quot;global_symbol&quot;</span>: <span class="hljs-string">&quot;mm_relu&quot;</span>, <span class="hljs-string">&quot;tir.noalias&quot;</span>: <span class="hljs-literal">True</span>&#125;)<br>        <span class="hljs-comment"># 存储数据的多维数组（缓冲区）</span><br>        Y = T.alloc_buffer((<span class="hljs-number">128</span>, <span class="hljs-number">128</span>), dtype=<span class="hljs-string">&quot;float32&quot;</span>)<br>        <span class="hljs-comment"># 驱动张量计算的循环嵌套</span><br>        <span class="hljs-keyword">for</span> i, j, k <span class="hljs-keyword">in</span> T.grid(<span class="hljs-number">128</span>, <span class="hljs-number">128</span>, <span class="hljs-number">128</span>):<br>            <span class="hljs-comment"># 计算语句</span><br>            <span class="hljs-keyword">with</span> T.block(<span class="hljs-string">&quot;Y&quot;</span>):<br>                vi = T.axis.spatial(<span class="hljs-number">128</span>, i)<br>                vj = T.axis.spatial(<span class="hljs-number">128</span>, j)<br>                vk = T.axis.reduce(<span class="hljs-number">128</span>, k)<br>                <span class="hljs-keyword">with</span> T.init():<br>                    Y[vi, vj] = T.float32(<span class="hljs-number">0</span>)<br>                Y[vi, vj] = Y[vi, vj] + A[vi, vk] * B[vk, vj]<br>        <span class="hljs-comment"># 驱动张量计算的循环嵌套</span><br>        <span class="hljs-keyword">for</span> i, j <span class="hljs-keyword">in</span> T.grid(<span class="hljs-number">128</span>, <span class="hljs-number">128</span>):<br>            <span class="hljs-comment"># 计算语句</span><br>            <span class="hljs-keyword">with</span> T.block(<span class="hljs-string">&quot;C&quot;</span>):<br>                vi = T.axis.spatial(<span class="hljs-number">128</span>, i)<br>                vj = T.axis.spatial(<span class="hljs-number">128</span>, j)<br>                C[vi, vj] = T.<span class="hljs-built_in">max</span>(Y[vi, vj], T.float32(<span class="hljs-number">0</span>))<br></code></pre></td></tr></table></figure><p>ir_module是TVM编译的最小完整单元，在TVM前端，其通常包括一个或多个relay（一个relay通常对应一个端到端模型），在经过如autoTVM、tirPasses之后relay被分解成一个或多个primFunc</p><p>块是tensorIR的基本计算单位。定义如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">[block_axis] = T.axis.[axis_type]([axis_range], [mapped_value])<br></code></pre></td></tr></table></figure><p>如<code>vi = T.axis.spatial(128, i)</code> 即表示vi为i的映射，范围为(0,128)，且该块轴属性为spatial（空间轴），而vk的属性则为reduce规约轴。（可以理解为空间轴是原本就在的，规约轴是在上面做滑动的）</p><p>块轴加属性的好处是使得vi，vj，vk独立于外部的循环嵌套i，j，k，同时也对外部循环正确性做了二次验证。同时这些附加信息也有助于机器学习编译分析，比如说，我们总是可以在空间轴上做并行化，但在规约轴上做并行化则需要特定的策略</p><pre><code class="hljs">如果觉得自定义属性比较麻烦也可以一键绑定</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># SSR means the properties of each axes are &quot;spatial&quot;, &quot;spatial&quot;, &quot;reduce&quot;</span><br>vi, vj, vk = T.axis.remap(<span class="hljs-string">&quot;SSR&quot;</span>, [i, j, k])<br></code></pre></td></tr></table></figure><h4 id="tensorIR的元张量函数变换">tensorIR的元张量函数变换</h4><p>tensorIR引入了名为Schedule的辅助结构，允许我们进行方便的元张量函数变换</p><p>这是原来的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> IPython<br>IPython.display.Code(MyModule.script(), language=<span class="hljs-string">&quot;python&quot;</span>)<br><br><span class="hljs-comment"># from tvm.script import ir as I</span><br><span class="hljs-comment"># from tvm.script import tir as T</span><br><span class="hljs-meta">@I.ir_module</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Module</span>:<br><span class="hljs-meta">    @T.prim_func</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">mm_relu</span>(<span class="hljs-params">A: T.Buffer(<span class="hljs-params">(<span class="hljs-params"><span class="hljs-number">128</span>, <span class="hljs-number">128</span></span>), <span class="hljs-string">&quot;float32&quot;</span></span>), B: T.Buffer(<span class="hljs-params">(<span class="hljs-params"><span class="hljs-number">128</span>, <span class="hljs-number">128</span></span>), <span class="hljs-string">&quot;float32&quot;</span></span>), C: T.Buffer(<span class="hljs-params">(<span class="hljs-params"><span class="hljs-number">128</span>, <span class="hljs-number">128</span></span>), <span class="hljs-string">&quot;float32&quot;</span></span>)</span>):<br>        T.func_attr(&#123;<span class="hljs-string">&quot;global_symbol&quot;</span>: <span class="hljs-string">&quot;mm_relu&quot;</span>, <span class="hljs-string">&quot;tir.noalias&quot;</span>: <span class="hljs-literal">True</span>&#125;)<br>        <span class="hljs-comment"># with T.block(&quot;root&quot;):</span><br>        Y = T.alloc_buffer((<span class="hljs-number">128</span>, <span class="hljs-number">128</span>))<br>        <span class="hljs-keyword">for</span> i, j, k <span class="hljs-keyword">in</span> T.grid(<span class="hljs-number">128</span>, <span class="hljs-number">128</span>, <span class="hljs-number">128</span>):<br>            <span class="hljs-keyword">with</span> T.block(<span class="hljs-string">&quot;Y&quot;</span>):<br>                vi, vj, vk = T.axis.remap(<span class="hljs-string">&quot;SSR&quot;</span>, [i, j, k])<br>                T.reads(A[vi, vk], B[vk, vj])<br>                T.writes(Y[vi, vj])<br>                <span class="hljs-keyword">with</span> T.init():<br>                    Y[vi, vj] = T.float32(<span class="hljs-number">0</span>)<br>                Y[vi, vj] = Y[vi, vj] + A[vi, vk] * B[vk, vj]<br>        <span class="hljs-keyword">for</span> i, j <span class="hljs-keyword">in</span> T.grid(<span class="hljs-number">128</span>, <span class="hljs-number">128</span>):<br>            <span class="hljs-keyword">with</span> T.block(<span class="hljs-string">&quot;C&quot;</span>):<br>                vi, vj = T.axis.remap(<span class="hljs-string">&quot;SS&quot;</span>, [i, j])<br>                T.reads(Y[vi, vj])<br>                T.writes(C[vi, vj])<br>                C[vi, vj] = T.<span class="hljs-built_in">max</span>(Y[vi, vj], T.float32(<span class="hljs-number">0</span>))<br></code></pre></td></tr></table></figure><p>使用Schedule进行变换：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">## 以给定的module作为输入的辅助Schedule类</span><br>sch = tvm.tir.Schedule(MyModule)<br><span class="hljs-comment"># 获取对应的块及相应循环的引用</span><br>block_Y = sch.get_block(<span class="hljs-string">&quot;Y&quot;</span>, func_name=<span class="hljs-string">&quot;mm_relu&quot;</span>)<br>i, j, k = sch.get_loops(block_Y)<br><span class="hljs-comment"># 变换：将原有的j循环拆分成两个循环（4表示内部循环长度）</span><br>j0, j1 = sch.split(j, factors=[<span class="hljs-literal">None</span>, <span class="hljs-number">4</span>])<br><span class="hljs-comment"># 再次检查结果</span><br>IPython.display.Code(sch.mod.script(), language=<span class="hljs-string">&quot;python&quot;</span>)<br><br><span class="hljs-meta">@I.ir_module</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Module</span>:<br><span class="hljs-meta">    @T.prim_func</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">mm_relu</span>(<span class="hljs-params">A: T.Buffer(<span class="hljs-params">(<span class="hljs-params"><span class="hljs-number">128</span>, <span class="hljs-number">128</span></span>), <span class="hljs-string">&quot;float32&quot;</span></span>), B: T.Buffer(<span class="hljs-params">(<span class="hljs-params"><span class="hljs-number">128</span>, <span class="hljs-number">128</span></span>), <span class="hljs-string">&quot;float32&quot;</span></span>), C: T.Buffer(<span class="hljs-params">(<span class="hljs-params"><span class="hljs-number">128</span>, <span class="hljs-number">128</span></span>), <span class="hljs-string">&quot;float32&quot;</span></span>)</span>):<br>        T.func_attr(&#123;<span class="hljs-string">&quot;global_symbol&quot;</span>: <span class="hljs-string">&quot;mm_relu&quot;</span>, <span class="hljs-string">&quot;tir.noalias&quot;</span>: <span class="hljs-literal">True</span>&#125;)<br>        <span class="hljs-comment"># with T.block(&quot;root&quot;):</span><br>        Y = T.alloc_buffer((<span class="hljs-number">128</span>, <span class="hljs-number">128</span>))<br>        <span class="hljs-keyword">for</span> i, j_0, j_1, k <span class="hljs-keyword">in</span> T.grid(<span class="hljs-number">128</span>, <span class="hljs-number">32</span>, <span class="hljs-number">4</span>, <span class="hljs-number">128</span>):<br>            <span class="hljs-keyword">with</span> T.block(<span class="hljs-string">&quot;Y&quot;</span>):<br>                vi = T.axis.spatial(<span class="hljs-number">128</span>, i)<br>                vj = T.axis.spatial(<span class="hljs-number">128</span>, j_0 * <span class="hljs-number">4</span> + j_1)<br>                vk = T.axis.reduce(<span class="hljs-number">128</span>, k)<br>                T.reads(A[vi, vk], B[vk, vj])<br>                T.writes(Y[vi, vj])<br>                <span class="hljs-keyword">with</span> T.init():<br>                    Y[vi, vj] = T.float32(<span class="hljs-number">0</span>)<br>                Y[vi, vj] = Y[vi, vj] + A[vi, vk] * B[vk, vj]<br>        <span class="hljs-keyword">for</span> i, j <span class="hljs-keyword">in</span> T.grid(<span class="hljs-number">128</span>, <span class="hljs-number">128</span>):<br>            <span class="hljs-keyword">with</span> T.block(<span class="hljs-string">&quot;C&quot;</span>):<br>                vi, vj = T.axis.remap(<span class="hljs-string">&quot;SS&quot;</span>, [i, j])<br>                T.reads(Y[vi, vj])<br>                T.writes(C[vi, vj])<br>                C[vi, vj] = T.<span class="hljs-built_in">max</span>(Y[vi, vj], T.float32(<span class="hljs-number">0</span>))<br><br><span class="hljs-comment"># 还可以更换循环次序</span><br><span class="hljs-comment"># sch.reorder(j0, k, j1)</span><br></code></pre></td></tr></table></figure><p>此外，块之间也可以通过变换完成组合</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 将块C放到Y的内循环中</span><br>block_C = sch.get_block(<span class="hljs-string">&quot;C&quot;</span>, <span class="hljs-string">&quot;mm_relu&quot;</span>)<br><span class="hljs-comment"># 感觉意思是将块C与j0循环绑定，及j0这个空间轴变换时，原本只有Y有动作，现在C也有动作</span><br>sch.reverse_compute_at(block_C, j0)<br>IPython.display.Code(sch.mod.script(), language=<span class="hljs-string">&quot;python&quot;</span>)<br><br><span class="hljs-meta">@I.ir_module</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Module</span>:<br><span class="hljs-meta">    @T.prim_func</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">mm_relu</span>(<span class="hljs-params">A: T.Buffer(<span class="hljs-params">(<span class="hljs-params"><span class="hljs-number">128</span>, <span class="hljs-number">128</span></span>), <span class="hljs-string">&quot;float32&quot;</span></span>), B: T.Buffer(<span class="hljs-params">(<span class="hljs-params"><span class="hljs-number">128</span>, <span class="hljs-number">128</span></span>), <span class="hljs-string">&quot;float32&quot;</span></span>), C: T.Buffer(<span class="hljs-params">(<span class="hljs-params"><span class="hljs-number">128</span>, <span class="hljs-number">128</span></span>), <span class="hljs-string">&quot;float32&quot;</span></span>)</span>):<br>        T.func_attr(&#123;<span class="hljs-string">&quot;global_symbol&quot;</span>: <span class="hljs-string">&quot;mm_relu&quot;</span>, <span class="hljs-string">&quot;tir.noalias&quot;</span>: <span class="hljs-literal">True</span>&#125;)<br>        <span class="hljs-comment"># with T.block(&quot;root&quot;):</span><br>        Y = T.alloc_buffer((<span class="hljs-number">128</span>, <span class="hljs-number">128</span>))<br>        <span class="hljs-keyword">for</span> i, j_0 <span class="hljs-keyword">in</span> T.grid(<span class="hljs-number">128</span>, <span class="hljs-number">32</span>):<br>            <span class="hljs-keyword">for</span> k, j_1 <span class="hljs-keyword">in</span> T.grid(<span class="hljs-number">128</span>, <span class="hljs-number">4</span>):<br>                <span class="hljs-keyword">with</span> T.block(<span class="hljs-string">&quot;Y&quot;</span>):<br>                    vi = T.axis.spatial(<span class="hljs-number">128</span>, i)<br>                    vj = T.axis.spatial(<span class="hljs-number">128</span>, j_0 * <span class="hljs-number">4</span> + j_1)<br>                    vk = T.axis.reduce(<span class="hljs-number">128</span>, k)<br>                    T.reads(A[vi, vk], B[vk, vj])<br>                    T.writes(Y[vi, vj])<br>                    <span class="hljs-keyword">with</span> T.init():<br>                        Y[vi, vj] = T.float32(<span class="hljs-number">0</span>)<br>                    Y[vi, vj] = Y[vi, vj] + A[vi, vk] * B[vk, vj]<br>            <span class="hljs-keyword">for</span> ax0 <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>):<br>                <span class="hljs-keyword">with</span> T.block(<span class="hljs-string">&quot;C&quot;</span>):<br>                    vi = T.axis.spatial(<span class="hljs-number">128</span>, i)<br>                    <span class="hljs-comment"># 注意这里vj的变化，原本vj = j = j_0 * 4 + j_1，现在变成了j_0 * 4 + ax0</span><br>                    <span class="hljs-comment"># 感觉是因为上面 reverse_compute_at 只是将C与j0绑定，所以j_1这个循环还是在Y中，C里还需要单独循环ax0</span><br>                    vj = T.axis.spatial(<span class="hljs-number">128</span>, j_0 * <span class="hljs-number">4</span> + ax0)<br>                    T.reads(Y[vi, vj])<br>                    T.writes(C[vi, vj])<br>                    C[vi, vj] = T.<span class="hljs-built_in">max</span>(Y[vi, vj], T.float32(<span class="hljs-number">0</span>))<br><br></code></pre></td></tr></table></figure><p>此外还介绍了另一种原语decompose_reduction，用于将语块中元素的初始化与规约更新分开：<br>这也是 TVM 在以后编译的时候隐式做的，所以这一步的主要目的是让它显式，看看最终效果</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 将块Y中的初始化与循环k无关(k是规约轴)</span><br>sch.decompose_reduction(block_Y, k)<br>IPython.display.Code(sch.mod.script(), language=<span class="hljs-string">&quot;python&quot;</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">lnumpy_mm_relu_v3</span>(<span class="hljs-params">A: np.ndarray, B: np.ndarray, C: np.ndarray</span>):<br>    Y = np.empty((<span class="hljs-number">128</span>, <span class="hljs-number">128</span>), dtype=<span class="hljs-string">&quot;float32&quot;</span>)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">128</span>):<br>        <span class="hljs-keyword">for</span> j0 <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">32</span>):<br>            <span class="hljs-comment"># Y_init</span><br>            <span class="hljs-keyword">for</span> j1 <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>):<br>                j = j0 * <span class="hljs-number">4</span> + j1<br>                <span class="hljs-comment"># 此时初始化在k循环之前就已经做好</span><br>                Y[i, j] = <span class="hljs-number">0</span><br>            <span class="hljs-comment"># Y_update</span><br>            <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">128</span>):<br>                <span class="hljs-keyword">for</span> j1 <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>):<br>                    j = j0 * <span class="hljs-number">4</span> + j1<br>                    Y[i, j] = Y[i, j] + A[i, k] * B[k, j]<br>            <span class="hljs-comment"># C</span><br>            <span class="hljs-keyword">for</span> j1 <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>):<br>                j = j0 * <span class="hljs-number">4</span> + j1<br>                C[i, j] = <span class="hljs-built_in">max</span>(Y[i, j], <span class="hljs-number">0</span>)<br><br>c_np = np.empty((<span class="hljs-number">128</span>, <span class="hljs-number">128</span>), dtype=dtype)<br>lnumpy_mm_relu_v3(a_np, b_np, c_np)<br>np.testing.assert_allclose(c_mm_relu, c_np, rtol=<span class="hljs-number">1e-5</span>)<br></code></pre></td></tr></table></figure><h4 id="构建与运行">构建与运行</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 使用llvm将模型编译到本机平台</span><br>rt_lib = tvm.build(MyModule, target=<span class="hljs-string">&quot;llvm&quot;</span>)<br><br><span class="hljs-comment"># 用于存储输入和输出的TVM NDArray</span><br>a_nd = tvm.nd.array(a_np)<br>b_nd = tvm.nd.array(b_np)<br>c_nd = tvm.nd.empty((<span class="hljs-number">128</span>, <span class="hljs-number">128</span>), dtype=<span class="hljs-string">&quot;float32&quot;</span>)<br><br><span class="hljs-comment"># 调用编译好的函数</span><br>func_mm_relu = rt_lib[<span class="hljs-string">&quot;mm_relu&quot;</span>]<br>func_mm_relu(a_nd, b_nd, c_nd)<br><span class="hljs-comment"># 将TVM与numpy的结果进行比较</span><br>np.testing.assert_allclose(c_mm_relu, c_nd.numpy(), rtol=<span class="hljs-number">1e-5</span>)<br><br><span class="hljs-comment"># 调用TVM变换后的函数，继续比较</span><br>rt_lib_after = tvm.build(sch.mod, target=<span class="hljs-string">&quot;llvm&quot;</span>)<br>rt_lib_after[<span class="hljs-string">&quot;mm_relu&quot;</span>](a_nd, b_nd, c_nd)<br>np.testing.assert_allclose(c_mm_relu, c_nd.numpy(), rtol=<span class="hljs-number">1e-5</span>)<br></code></pre></td></tr></table></figure><p>在最后的结果中，TVM变换后的函数运行时间相比原先的TVM函数大幅缩短，为什么不同的循环变体会导致不同的时间性能呢？</p><p>关键在于CPU的访存策略，由于局部性原理，CPU在读取内存某元素时会尝试将该元素附近的元素一起获取到缓存中（cache块？特么OS快忘干净了😅）。因此具有连续内存访问的代码通常比随机访问内存不同部分的代码更快。</p><h2 id="3-端到端的模型执行">3. 端到端的模型执行</h2><p>现在考虑一个基础的两层神经网络，由2个MLP和1个relu组成（简化问题，删除最后的softmax）</p><p>numpy实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">numpy_mlp</span>(<span class="hljs-params">data, w0, b0, w1, b1</span>):<br>    lv0 = data @ w0.T + b0<br>    lv1 = np.maximum(lv0, <span class="hljs-number">0</span>)<br>    lv2 = lv1 @ w1.T + b1<br>    <span class="hljs-keyword">return</span> lv2<br><br>res = numpy_mlp(img.reshape(<span class="hljs-number">1</span>, <span class="hljs-number">784</span>),<br>                mlp_params[<span class="hljs-string">&quot;w0&quot;</span>],<br>                mlp_params[<span class="hljs-string">&quot;b0&quot;</span>],<br>                mlp_params[<span class="hljs-string">&quot;w1&quot;</span>],<br>                mlp_params[<span class="hljs-string">&quot;b1&quot;</span>])<br></code></pre></td></tr></table></figure><p>底层实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">lnumpy_linear0</span>(<span class="hljs-params">X: np.ndarray, W: np.ndarray, B: np.ndarray, Z: np.ndarray</span>):<br>    Y = np.empty((<span class="hljs-number">1</span>, <span class="hljs-number">128</span>), dtype=<span class="hljs-string">&quot;float32&quot;</span>)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">128</span>):<br>            <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">784</span>):<br>                <span class="hljs-keyword">if</span> k == <span class="hljs-number">0</span>:<br>                    Y[i, j] = <span class="hljs-number">0</span><br>                Y[i, j] = Y[i, j] + X[i, k] * W[j, k]<br><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">128</span>):<br>            Z[i, j] = Y[i, j] + B[j]<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">lnumpy_relu0</span>(<span class="hljs-params">X: np.ndarray, Y: np.ndarray</span>):<br>     <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">128</span>):<br>            Y[i, j] = np.maximum(X[i, j], <span class="hljs-number">0</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">lnumpy_linear1</span>(<span class="hljs-params">X: np.ndarray, W: np.ndarray, B: np.ndarray, Z: np.ndarray</span>):<br>    Y = np.empty((<span class="hljs-number">1</span>, <span class="hljs-number">10</span>), dtype=<span class="hljs-string">&quot;float32&quot;</span>)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>            <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">128</span>):<br>                <span class="hljs-keyword">if</span> k == <span class="hljs-number">0</span>:<br>                    Y[i, j] = <span class="hljs-number">0</span><br>                Y[i, j] = Y[i, j] + X[i, k] * W[j, k]<br><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>            Z[i, j] = Y[i, j] + B[j]<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">lnumpy_mlp</span>(<span class="hljs-params">data, w0, b0, w1, b1</span>):<br>    lv0 = np.empty((<span class="hljs-number">1</span>, <span class="hljs-number">128</span>), dtype=<span class="hljs-string">&quot;float32&quot;</span>)<br>    lnumpy_linear0(data, w0, b0, lv0)<br><br>    lv1 = np.empty((<span class="hljs-number">1</span>, <span class="hljs-number">128</span>), dtype=<span class="hljs-string">&quot;float32&quot;</span>)<br>    lnumpy_relu0(lv0, lv1)<br><br>    out = np.empty((<span class="hljs-number">1</span>, <span class="hljs-number">10</span>), dtype=<span class="hljs-string">&quot;float32&quot;</span>)<br>    lnumpy_linear1(lv1, w1, b1, out)<br>    <span class="hljs-keyword">return</span> out<br><br>result =lnumpy_mlp(<br>    img.reshape(<span class="hljs-number">1</span>, <span class="hljs-number">784</span>),<br>    mlp_params[<span class="hljs-string">&quot;w0&quot;</span>],<br>    mlp_params[<span class="hljs-string">&quot;b0&quot;</span>],<br>    mlp_params[<span class="hljs-string">&quot;w1&quot;</span>],<br>    mlp_params[<span class="hljs-string">&quot;b1&quot;</span>])<br><br>pred_kind = result.argmax(axis=<span class="hljs-number">1</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Low-level Numpy MLP Prediction:&quot;</span>, class_names[pred_kind[<span class="hljs-number">0</span>]])<br></code></pre></td></tr></table></figure><p>该模型的TVMScript实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@tvm.script.ir_module</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyModule</span>:<br><span class="hljs-meta">    @T.prim_func</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">relu0</span>(<span class="hljs-params">x: T.handle, y: T.handle</span>):<br>        n = T.int64()<br>        X = T.match_buffer(x, (<span class="hljs-number">1</span>, n), <span class="hljs-string">&quot;float32&quot;</span>)<br>        Y = T.match_buffer(y, (<span class="hljs-number">1</span>, n), <span class="hljs-string">&quot;float32&quot;</span>)<br>        <span class="hljs-keyword">for</span> i, j <span class="hljs-keyword">in</span> T.grid(<span class="hljs-number">1</span>, n):<br>            <span class="hljs-keyword">with</span> T.block(<span class="hljs-string">&quot;Y&quot;</span>):<br>                vi, vj = T.axis.remap(<span class="hljs-string">&quot;SS&quot;</span>, [i, j])<br>                Y[vi, vj] = T.<span class="hljs-built_in">max</span>(X[vi, vj], T.float32(<span class="hljs-number">0</span>))<br><br><span class="hljs-meta">    @T.prim_func</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">linear0</span>(<span class="hljs-params">x: T.handle,</span><br><span class="hljs-params">                w: T.handle,</span><br><span class="hljs-params">                b: T.handle,</span><br><span class="hljs-params">                z: T.handle</span>):<br>        m, n, k = T.int64(), T.int64(), T.int64()<br>        X = T.match_buffer(x, (<span class="hljs-number">1</span>, m), <span class="hljs-string">&quot;float32&quot;</span>)<br>        W = T.match_buffer(w, (n, m), <span class="hljs-string">&quot;float32&quot;</span>)<br>        B = T.match_buffer(b, (n, ), <span class="hljs-string">&quot;float32&quot;</span>)<br>        Z = T.match_buffer(z, (<span class="hljs-number">1</span>, n), <span class="hljs-string">&quot;float32&quot;</span>)<br>        Y = T.alloc_buffer((<span class="hljs-number">1</span>, n), <span class="hljs-string">&quot;float32&quot;</span>)<br>        <span class="hljs-keyword">for</span> i, j, k <span class="hljs-keyword">in</span> T.grid(<span class="hljs-number">1</span>, n, m):<br>            <span class="hljs-keyword">with</span> T.block(<span class="hljs-string">&quot;Y&quot;</span>):<br>                vi, vj, vk = T.axis.remap(<span class="hljs-string">&quot;SSR&quot;</span>, [i, j, k])<br>                <span class="hljs-keyword">with</span> T.init():<br>                    Y[vi, vj] = T.float32(<span class="hljs-number">0</span>)<br>                Y[vi, vj] = Y[vi, vj] + X[vi, vk] * W[vj, vk]<br>        <span class="hljs-keyword">for</span> i, j <span class="hljs-keyword">in</span> T.grid(<span class="hljs-number">1</span>, n):<br>            <span class="hljs-keyword">with</span> T.block(<span class="hljs-string">&quot;Z&quot;</span>):<br>                vi, vj = T.axis.remap(<span class="hljs-string">&quot;SS&quot;</span>, [i, j])<br>                Z[vi, vj] = Y[vi, vj] + B[vj]<br><br><span class="hljs-meta">    @R.function</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>(<span class="hljs-params">x: R.Tensor(<span class="hljs-params">(<span class="hljs-params"><span class="hljs-number">1</span>, <span class="hljs-string">&quot;m&quot;</span></span>), <span class="hljs-string">&quot;float32&quot;</span></span>),</span><br><span class="hljs-params">             w0: R.Tensor(<span class="hljs-params">(<span class="hljs-params"><span class="hljs-string">&quot;n&quot;</span>, <span class="hljs-string">&quot;m&quot;</span></span>), <span class="hljs-string">&quot;float32&quot;</span></span>),</span><br><span class="hljs-params">             b0: R.Tensor(<span class="hljs-params">(<span class="hljs-params"><span class="hljs-string">&quot;n&quot;</span>, </span>), <span class="hljs-string">&quot;float32&quot;</span></span>),</span><br><span class="hljs-params">             w1: R.Tensor(<span class="hljs-params">(<span class="hljs-params"><span class="hljs-string">&quot;k&quot;</span>, <span class="hljs-string">&quot;n&quot;</span></span>), <span class="hljs-string">&quot;float32&quot;</span></span>),</span><br><span class="hljs-params">             b1: R.Tensor(<span class="hljs-params">(<span class="hljs-params"><span class="hljs-string">&quot;k&quot;</span>, </span>), <span class="hljs-string">&quot;float32&quot;</span></span>)</span>):<br>        m, n, k = T.int64(), T.int64(), T.int64()<br>        <span class="hljs-keyword">with</span> R.dataflow():<br>            lv0 = R.call_dps_packed(<span class="hljs-string">&quot;linear0&quot;</span>, (x, w0, b0), R.Tensor((<span class="hljs-number">1</span>, n), <span class="hljs-string">&quot;float32&quot;</span>))<br>            lv1 = R.call_dps_packed(<span class="hljs-string">&quot;relu0&quot;</span>, (lv0, ), R.Tensor((<span class="hljs-number">1</span>, n), <span class="hljs-string">&quot;float32&quot;</span>))<br>            out = R.call_dps_packed(<span class="hljs-string">&quot;linear0&quot;</span>, (lv1, w1, b1), R.Tensor((<span class="hljs-number">1</span>, k), <span class="hljs-string">&quot;float32&quot;</span>))<br>            R.output(out)<br>        <span class="hljs-keyword">return</span> out<br></code></pre></td></tr></table></figure><p>引入了一个新的 <code>@R.function</code> 即Relex函数，是一种表示上层神经网络执行的全新抽象</p><p><img src="image.png" alt="Alt text"></p><p>注意到，其中<code>call_dps_packed</code>将我们的元函数嵌入到计算图中，其主要作用是满足<strong>目标传递</strong>的调用约定，即 pure 或 side-effect free ，函数只从其输入中读取数据并输出返回结果，而不改变程序的其他部分，这可以方便我们隐藏调用底层元函数的细节</p><p>如果只是像numpy实现中那样：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">lnumpy_linear0(data, w0, b0, lv0)<br>lnumpy_relu0(lv0, lv1)<br>lnumpy_linear1(lv1, w1, b1, out)<br></code></pre></td></tr></table></figure><p>计算图可能会变成这样：lv0既是<code>lnumpy_linear0</code>的入参，也是<code>lnumpy_relu0</code>的入参，其余同理<br><img src="image-1.png" alt="Alt text"></p><blockquote><p>计算图通常具有以下性质：</p><ul><li>框的每个输入边对应于操作的输入</li><li>每个出边对应于操作的输出</li><li>每个操作可以任意重新排序，直到边缘的拓扑顺序</li></ul></blockquote><p>当然，numpy的底层同样也使用了如<code>lnumpy_call_dps_packed</code>的类似调用</p><p>此外，注意<code>with R.dataflow():</code> 是一个帮助我们标注程序计算图范围的方式，后面的构建运行就不多说了</p><h2 id="4-自动程序优化">4. 自动程序优化</h2><p>这一章主要讲随机调度变换，当我们无法决定原张量函数优化的每一个细节时，可以使用机器的一些<strong>随机变换</strong>做法</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">stochastic_schedule_mm</span>(<span class="hljs-params">sch: tvm.tir.Schedule</span>):<br>    block_C = sch.get_block(<span class="hljs-string">&quot;C&quot;</span>, <span class="hljs-string">&quot;main&quot;</span>)<br>    i, j, k = sch.get_loops(block=block_C)<br>    <span class="hljs-comment"># 注意 j_factors 没有使用固定的[none,4]，而是采用随机值</span><br>    j_factors = sch.sample_perfect_tile(loop=j, n=<span class="hljs-number">2</span>)<br>    j_0, j_1 = sch.split(loop=j, factors=j_factors)<br>    sch.reorder(i, j_0, k, j_1)<br>    sch.decompose_reduction(block_C, k)<br>    <span class="hljs-keyword">return</span> sch<br></code></pre></td></tr></table></figure><p>上述代码中，用到了 sch.sample_perfect_tile 来随机拆分循环。它会将输入的循环的长度进行随机分割，例如原始j =128 时，就可以分割为 [8,16]、[32,4]、[2,64] 等等，可以发现，每次运行时该函数的采样都不一样</p><p>此外还讲了一些随机搜索的东西，大概类似超参数的网格搜索之类的，在TVM里叫<code>meta_schedule</code>，主要还做了以下事情：</p><ol><li>跨多个进程的并行基准测试</li><li>使用代价模型<code>cost model</code>进行代价评估，这样可以避免每组都进行基准测试</li><li>根据历史轨迹来进行遗传搜索，而不是每次都随机采样</li></ol><p>关键思想就是使用随机变换来指定好的程序的搜索空间，使用 <code>tune_tir</code> API 帮助在搜索空间内搜索并找到最优的调度变换</p><blockquote><p><strong>前面几章内容总结，就是为什么通过编译可以使模型运行更快（cache空间局部性），以及怎么样编译可以更快（元张量函数变换），同时也介绍了一些随机变换的方法（网格搜索），感觉随机变换的算法才是MLC性能的核心，也就是自动调优，TVM后面似乎用到了一些 autoTVM、autoSchedule 之类的方法进行 auto tune，这也是我需要重点关注的部分</strong></p></blockquote><h2 id="5-与机器学习框架的整合">5. 与机器学习框架的整合</h2><p>如何将机器学习模型从现有框架引入MLC，一些API的基础教程，参考 <a href="https://mlc.ai/zh/chapter_integration/index.html">https://mlc.ai/zh/chapter_integration/index.html</a></p><h2 id="6-GPU硬件加速">6. GPU硬件加速</h2><p>在GPU环境下的MLC流程，第一部分主要讨论CUDA，第二部分讨论专门的GPU环境，后面再看吧</p><h2 id="7-计算图优化">7. 计算图优化</h2><p>提供了一些算子融合的基础代码，也不太想看</p>]]></content>
    
    
    <categories>
      
      <category>work</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>TVM</tag>
      
      <tag>课程笔记</tag>
      
      <tag>MLC</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>网络状态检查</title>
    <link href="/2023/09/16/%E7%BD%91%E7%BB%9C%E7%8A%B6%E6%80%81%E6%A3%80%E6%9F%A5/"/>
    <url>/2023/09/16/%E7%BD%91%E7%BB%9C%E7%8A%B6%E6%80%81%E6%A3%80%E6%9F%A5/</url>
    
    <content type="html"><![CDATA[<p>最近fps老是延迟+掉包（把把被一枪头想必不是我的问题），加上网口接触不良一直不好确定源头在哪，在此记录一下问题定位的过程</p><span id="more"></span><h2 id="原因分析：">原因分析：</h2><ul><li>数据传输流程：<br>本地主机 — 本地路由（如果有） — 网关 — 外部网络中转 — 目标主机</li></ul><p>很显然突然的延迟和掉包几乎不可能是外部网络中转和目标主机的问题，加上目前是直连宽带，问题只可能出在主机 &lt;—&gt; 网关上</p><h2 id="问题排查：">问题排查：</h2><h3 id="1-查看自身网络配置：">1. 查看自身网络配置：</h3><p><img src="0.png" alt=""></p><p>本地主机有两条连接，网关分别为192.168.14.1（网口）和172.168.15.1(wifi)</p><h3 id="2-运行任一出现掉包的应用">2. 运行任一出现掉包的应用</h3><h3 id="3-任务管理器中的资源监视器，找到进程PID以及通信的外部IP">3. 任务管理器中的资源监视器，找到进程PID以及通信的外部IP</h3><p><img src="1.png" alt=""></p><p>我也不知道这么多IP哪一个是导致掉包和延迟的。。先找收发高的吧 180.102.211.22 121.229.89.178</p><h3 id="4-netstat查看该进程的网络相关信息">4. netstat查看该进程的网络相关信息</h3><p><img src="2.png" alt=""></p><p>很显然主机是用的192.1168.14.1上的某个端口向外部通信，并且问题大概率出现在与121.229与180.102的通信上</p><h3 id="5-tracert查看路由（pathping也行）">5. tracert查看路由（pathping也行）</h3><table><thead><tr><th style="text-align:center"><img src="4.png" alt=""></th><th style="text-align:center"><img src="5.png" alt=""></th></tr></thead></table><p>两次在走过网口后，都又经过了一个本地IP 100.69.0.1 ，估计是一整栋楼或者本层局域网统一之后的二级网关，经过这个才到外部网络</p><h3 id="6-ping">6. ping</h3><p>分别 ping -t 了一下网关和100.69两个ip，发现到网关基本上没问题，也就是主机到网口的全过程流畅</p><p>每次出现掉包时，到100.69也会出现请求超时，问题就在网口到100.69这段，分析有两种可能：</p><ol><li>网口到100.69线路导致丢包</li><li>100.69负载过高，收到数据后转发丢包</li></ol><h2 id="问题解决">问题解决</h2><p><s>不信邪，直接去楼上的两间空房和本层的另一间空房试了一下，楼上经网关后统一发向100.65.0.1，楼下统一发向100.69.0.1，且本层其他房间ping 100.69也会出现超时或延迟过高问题，服了，确实是层级网关负载过高的原因</s></p><p>并不是，过几天发现有时网络也会走100.65，而且同样会有丢包现象。</p><p>于是偷偷溜进弱点机房观察了一下，一层大概二十个房间，使用两组交换机，每个交换机的24号口连接主路由，主路由的WAN口再连接光猫。主路由还有一个口用来给wifi的路由器。</p><p>这个路由器应该就是100.65.0.1，但是为什么之前测试走的100.69，可能有负载均衡吧。</p><p>实测不管换线还是换接口，延迟和丢包依旧在。看到主路由还有一个闲置LAN口，索性把自己房间直接跳过交换机接到主路由上，发现延迟还是有些不稳定，但丢包彻底解决。公寓该换交换机了。</p><p>本来之后还想着直接接到光猫的闲置口上，但无法识别，可能端口没开启或者是手动分配ip的吧。</p><p>1Gbps速率测速能跑到七八十M/s，应该没啥问题，但wifi延迟和带宽还是很拉跨，应该也是wifi路由器的问题。</p><h2 id="有线和wifi双网叠加">有线和wifi双网叠加</h2><p>参考：<a href="https://www.zhihu.com/question/294289602/answer/2912972037">https://www.zhihu.com/question/294289602/answer/2912972037</a></p><p>系统会优先选择跃点数小的网络进行传输， route print查看连接网络跃点数，之后将两个网络跃点数设置为相同即可</p><p>感觉很扯，实测下载速度不变，上传速度翻倍。。。牛皮</p>]]></content>
    
    
    <categories>
      
      <category>work</category>
      
    </categories>
    
    
    <tags>
      
      <tag>记录</tag>
      
      <tag>网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Dive into Deeplearning</title>
    <link href="/2023/09/14/Dive-into-Deeplearning/"/>
    <url>/2023/09/14/Dive-into-Deeplearning/</url>
    
    <content type="html"><![CDATA[<span id="more"></span><p>参考：</p><ul><li><a href="https://zh.d2l.ai/index.html">《动手学深度学习》</a></li><li><a href="https://space.bilibili.com/1567748478/channel/seriesdetail?sid=358497&amp;ctype=0">跟李沐学AI</a></li></ul><p><img src="image.png" alt="全书结构"></p><h2 id="Intro">Intro</h2><h3 id="机器学习的关键组件：">机器学习的关键组件：</h3><ol><li>用来学习的数据：data</li><li>转换数据的模型：model</li><li>用来量化模型有效性的目标函数：objective function（lose function）</li><li>调整模型参数以优化目标函数得到的值的算法：algorithm</li></ol><h4 id="数据">数据</h4><p>用于机器学习的数据一般可分为训练集（train）、测试集（validate）和验证集（test）</p><ol><li>训练集用于训练即反向传播调整模型参数</li><li>测试集用于调整模型超参数</li><li>验证集用于评估模型最终性能</li></ol><p>每个数据集由一个个样本（sample，也称数据点或数据实例）组成，大多时候这些样本都遵循独立同分布，每个样本由一组称为特征（features）的属性组成，特征数量称为该样本数据的维数（dimensionality）。机器学习模型会根据这些属性进行预测，在监督学习中，预测结果是一个特殊属性，称为标签（label）</p><h4 id="模型">模型</h4><p>这是深度学习与经典机器学习的主要区别点：深度学习的模型更复杂，数据转换层数更多</p><h4 id="目标函数">目标函数</h4><p>即误差函数，一般用来度量预测值与真实值之间的误差</p><h4 id="优化算法">优化算法</h4><p>用于搜索模型的最佳参数，从而最小化目标函数。一般采用梯度下降</p><h3 id="机器学习问题分类">机器学习问题分类</h3><p>监督学习：回归、分类、标记（不排斥的图片多物体标记）、搜索、推荐系统、序列学习（RNN）等</p><p>无监督学习：聚类、主成分分析、GAN等</p><p>在线学习：以上监督/无监督都属于预先获取大量数据，然后启动模型开始学习的离线学习类。离线学习将算法与环境断开，可以孤立的进行模式识别而不必被影响。而在线学习强调与环境的互动</p><p>强化学习：一个典型的与环境交互的学习方式</p><h2 id="线性神经网络">线性神经网络</h2><p>。。。</p>]]></content>
    
    
    <categories>
      
      <category>work</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>Deeplearning</tag>
      
      <tag>课程笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>General-Purpose Graphics Processor Architectures</title>
    <link href="/2023/09/14/General-Purpose-Graphics-Processor-Architectures/"/>
    <url>/2023/09/14/General-Purpose-Graphics-Processor-Architectures/</url>
    
    <content type="html"><![CDATA[<h1>General-Purpose Graphics Processor Architectures</h1><h2 id="Abstract-Preface">Abstract &amp;&amp; Preface</h2><p>与CPU相比，GPU可以更加聚焦与计算，因此性能和效率更高。——通用可编程GPU</p><p>章节介绍：GPU基本结构与历史 —— GPU编程模型 —— GPU计算核心的体系结构 —— 计算核心与内存系统的交叉研究</p><h2 id="Chapter-1-Intro">Chapter 1: Intro</h2><h3 id="1-1-计算加速器的前景">1.1 计算加速器的前景</h3><p>过去，计算系统的性能提升大部分依赖于工艺的进步，使得晶体管尺寸缩小，从而提升集成度，使得运行速度更快。</p><p>Dennard Scaling：从05年开始晶体管缩放规则失效。因此为了提高性能，需要找到更高效的硬件架构。</p><p>hardware specialization：定制化硬件，可以使能效比大幅提高，两大方向：</p><ul><li>硬件向量化，消除指令处理的开销</li><li>优化计算过程，减少数据运输开销</li></ul><p>计算架构的关键：专业化硬件带来的收益与支持广泛程序所需的灵活性之间的平衡。相比于专用加速器（例如google的TPU），仍然需要GPU这种较为通用的计算硬件。</p><p>Turing-complete：图灵完备，只要给足够的时间与内存，GPU可以完成一切运算。</p><h3 id="1-2-GPU硬件基础">1.2 GPU硬件基础</h3><p>GPU不会完全取代CPU：GPU不是独立的计算设备，通常来说，CPU负责在GPU上启动计算并负责GPU上的数据传输。当前访问I/O设备或提供OS服务的软件主要还是运行在CPU上（这些软件缺乏大规模并行性），因此，需要首先考虑GPU与CPU的交互。</p><ul><li>独立GPU：两个U各有各的mem，同时核心通过PCIE总线进行数据传输。注意对于独显来说，两个U的mem的DRAM技术通常是不一样的，CPU的DRAM通常针对低延迟访问进行优化（DDR），而GPU的DRAM通常针对高吞吐进行优化（GDDR）。</li><li>集成GPU：两个U共享一个cache，cache与一个内存进行数据交互。由于共享内存所以只能采取单一技术，集成式GPU通常搭载在低功耗设备上，因此DRAM通常针对低功耗进行优化（LPDDR）。</li></ul><p>一个GPU计算应用会从CPU上开始，通常，该应用程序的CPU部分负责分配和初始化一些数据结构。在旧的N卡和A卡上，CPU需要为CPU和GPU内存中的数据结构分配空间，并协调数据从CPUmem到GPUmem的移动。在新的N卡（Pascal，10系）上的软硬件支持数据从Cmem到Gmem的自动传输，这项技术通过利用虚拟内存支持来实现，NV称之为unified memory。对于集显来说不存在数据mem传输的问题，但是由于两个U共享cache并且有些cache可能是私有的，因此也需要关注缓存一致性问题 (cache-coherence) 。</p><p>启动GPU运算一般需要驱动程序完成，在GPU启动运算前，CPU通过驱动程序指定GPU运行哪些代码，这些代码称为内核（kernel），同时，CPU还需要指定线程数、每个线程的数据位置等等。配置完毕后，CPU向GPU发出信号，GPU开始运算。</p><p>现代GPU由许多核心（SIMT Core）组成，NV称之为流式多处理器(Streaming Multiprocessor, SM)，AMD称之为计算单元(compute unit)，每个核心都执行一个与此时运行的内核相关的单指令多线程程序，一个核心可以运行上千个线程，这些线程通过暂存区mem进行通信，并使用快速屏障技术（fast barrier operations）进行同步。每个核心同时还有一级指令和一级缓存，这些缓存可以充当带宽过滤器，减少向低级别内存的流量，当拥有大量线程时，可以隐藏由于有时某线程的缓存未命中而访问内存带来的的性能下滑。</p><p>高计算吞吐需要高内存带宽的支持，这又对内存系统的并行性提出要求。这种并行性又多通道内存实现，每个通道与内存分区中的最后一级缓存（LLC）相连，GPU核心通过片上互连网络与内存分区相连。也有一些替代的方案，例如Intel的Xeon Phi，就是将LLC直接交由GPU核心分配</p><p>对于高并发任务来说，GPU相对超标量无序CPU拥有更高的单位面积性能，因为GPU可以将其芯片面积的大部分专用于算术逻辑单元，并相应的减小控制逻辑的面积。</p><p>09年出来一个性能随线程变化的分析模型。模型显示：</p><ol><li>当少量线程共享大缓存时（如多核CPU），性能会随着线程数量的增加而提高。</li><li>当线程数增加到缓存无法容纳整个工作集时，性能反而会随着线程数量增加而下降。</li><li>但是随着线程数量的进一步增加，性能会随着多线程隐藏片外延迟的能力而提高。<br>GPU就是通过采用多线程来容忍频繁的缓存未命中，提高运算性能。</li></ol><p>内存访问不仅降低性能，同时也会提高能耗。新的GPGPU架构的重点是改善内存访问。</p><h3 id="1-3-GPU简史">1.3 GPU简史</h3><h3 id="1-4-书籍大纲">1.4 书籍大纲</h3><ul><li>第二章：编程模型、代码开发过程、编译流程</li><li>第三章：单个GPU核心（SM）的体系结构</li><li>第四章：内存系统</li><li>第五章：其他研究</li></ul><h2 id="Chapter-2：编程模型">Chapter 2：编程模型</h2><p>现代GPU广泛采用SIMD硬件来利用数据级并行，但GPU的计算API（如NV的cuda和AMD的opencl）并不向程序员暴露SIMD的硬件，而是采取类似MIMD的编程模型，允许程序员在GPU上启动大量标量线程。其中的每一个标量线程都有自己独特的执行路径，并都可以访问内存。运行时，GPU上的的SIMD硬件利用线程的规律性和空间局部性，同步启动这些标量线程组，称为SIMT（单指令多线程）</p><ul><li>SIMD：例如两个向量，对两个向量的每一个分量进行相同的op操作，输出为一个向量（在一个线程里，受ALU宽度限制）</li><li>SIMT：与SIMD在一个线程公用一个ALU不同，SIMT有多个线程，每个线程各有各的ALU和自己的数据，但执行的指令相同（但是由于数据不同，执行指令时的控制分支可能会不一样）</li></ul><h3 id="2-1-运行模型">2.1 运行模型</h3><p>为GPU优化的代码很可能在CPU架构上表现不佳。假定一个 单精度标量A * 向量X + 向量Y 的函数实现：</p><p>CPU实现</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-type">void</span> <span class="hljs-title function_">saxpy_serial</span><span class="hljs-params">(<span class="hljs-type">int</span> n, <span class="hljs-type">float</span> a, <span class="hljs-type">float</span> *x, <span class="hljs-type">float</span> *y)</span><br>&#123;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; n; ++i)<br>        y[i] = a * x[i] + y[i];<br>&#125;<br>main()<br>&#123;<br>    <span class="hljs-type">float</span> *x, *y;<br>    <span class="hljs-type">int</span> n;<br>    <span class="hljs-comment">// 省略*x、*y的赋值操作</span><br>    saxpy_serial(n, <span class="hljs-number">2.0</span>, x, y);<br>    <span class="hljs-comment">// 省略内存释放操作</span><br>&#125;<br></code></pre></td></tr></table></figure><p>GPU-CUDA实现</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs C">__global__ <span class="hljs-type">void</span> <span class="hljs-title function_">saxpy</span><span class="hljs-params">(<span class="hljs-type">int</span> n, <span class="hljs-type">float</span> a, <span class="hljs-type">float</span> *x, <span class="hljs-type">float</span> *y)</span> <span class="hljs-comment">// __global__代表函数在GPU上运行</span><br>&#123;<br>   <span class="hljs-comment">// 每个线程都有各自的blockIdx.x、blockDim.x、threadIdx.x</span><br>   <span class="hljs-type">int</span> i = blockIdx.x * blockDim.x + threadIdx.x;<br>   <span class="hljs-comment">// threadIdx.x代表线程在线程块中的x坐标</span><br>   <span class="hljs-comment">// blockIdx.x代表线程所属的线程块在grid中的x坐标</span><br>   <span class="hljs-comment">// blockDim.x一个线程块在x维度的最大线程数</span><br>   <span class="hljs-comment">// 一般来说线程在线程块中有xyz三个坐标，线程块在网格中也有xyz三个坐标，这里省略y，z</span><br>   <span class="hljs-keyword">if</span> (i &lt; n)<br>      y[i] = a * x[i] + y[i];<br>&#125;<br><span class="hljs-type">int</span> <span class="hljs-title function_">main</span><span class="hljs-params">()</span><br>&#123;<br>   <span class="hljs-comment">// 一般h_表示cpu的内存指针，d_表示gpu的内存指针</span><br>   <span class="hljs-type">float</span> *h_x, *h_y;<br>   <span class="hljs-type">int</span> n;<br>   <span class="hljs-comment">// 省略*h_x、*h_y的赋值操作</span><br>   <span class="hljs-type">float</span> *d_x, *d_y;<br>   <span class="hljs-type">int</span> nblocks = (n + <span class="hljs-number">255</span>) / <span class="hljs-number">256</span>;<br>   <span class="hljs-comment">// 调用GPU驱动程序并要求分配gpu内存，并将这一片内存的地址赋给&amp;d_x</span><br>   cudaMalloc(&amp;d_x, n * <span class="hljs-keyword">sizeof</span>(<span class="hljs-type">float</span>));<br>   cudaMalloc(&amp;d_y, n * <span class="hljs-keyword">sizeof</span>(<span class="hljs-type">float</span>));<br>   <span class="hljs-comment">// 将h_x指向的内容赋值给d_x指向的区域</span><br>   cudaMemcpy(d_x, h_x, n * <span class="hljs-keyword">sizeof</span>(<span class="hljs-type">float</span>), cudaMemcpyHostToDevice);<br>   cudaMemcpy(d_y, h_y, n * <span class="hljs-keyword">sizeof</span>(<span class="hljs-type">float</span>), cudaMemcpyHostToDevice);<br>   <span class="hljs-comment">// 交由GPU，并启动nblocks个线程块（Thread Block，或CTA），每个线程块256个线程，所有的线程块组成一个grid，即本次内核的计算单元</span><br>   saxpy&lt;&lt;&lt;nblocks, <span class="hljs-number">256</span>&gt;&gt;&gt;(n, <span class="hljs-number">2.0</span>, d_x, d_y);<br>   <span class="hljs-comment">// 为了提高效率，每个线程块中，每32个线程以锁步形式组成一组warp，warp往上再组成线程块</span><br>   <span class="hljs-comment">// 一个warp包含多少线程是硬件概念，而一个线程块可以有多少线程则是软件概念（当然得是warp的整数倍）</span><br>   <span class="hljs-comment">// 将计算结果返回给CPU内存</span><br>   cudaMemcpy(h_x, d_x, n * <span class="hljs-keyword">sizeof</span>(<span class="hljs-type">float</span>), cudaMemcpyDeviceToHost);<br>   <span class="hljs-comment">// 省略内存释放操作</span><br>&#125;<br></code></pre></td></tr></table></figure><p>硬件：一个GPU有多个SM，每个SM包含多个SP（Stream Processor）</p><p>软件：一个GPU内核对应一个grid，一个grid包含多个CTA。CTA中有多个warp，每个warp包含固定数量的线程数（与SM中SP数量相同）。</p><p>GPU在运算时，可能是一个grid独占GPU，也可以多个grid并行跑GPU；SM对应的工作单元是CTA，其中的基本执行单元是warp（即每个SP对应一个warp中的线程），在某个warp受阻时SM可以切换同一个CTA中的其他warp，但只有该CTA执行完，才切换其他CTA</p><p>CTA中的线程之间可以通过暂存器内存互相通信（NV称之为共享内存），同步也轻松，同时每个SM中也有一个共享内存，可以分配给在该SM上运行的所有CTA</p><p>不同CTA中的线程也可以通过所有线程都能访问的全局地址空间通信，但代价较高</p><h3 id="2-2-指令模型">2.2 指令模型</h3><p>NV的并行线程执行ISA：Parallel Thread eXecution，简称PTX （虚拟指令，类似汇编指令）</p><p>GPU运行PTX代码前，需要编译（汇编）成实际的机器指令，NV称此为SASS（Streaming ASSembler），该过程有NV的工具包完成，并没有开放，这使得NV可以在硬件级别提供向后兼容性，每一代都可以重新设计ISA架构</p><h2 id="Chapter-3：SIMT核心：指令和寄存器数据流">Chapter 3：SIMT核心：指令和寄存器数据流</h2><p>对传统图形渲染来说，GPU通常需要访问详细的纹理图，这样的数据集因为太大不可能完全缓存在芯片上，因此有必要采用能够维持大片外带宽的GPU架构。所以如今的GPU都往高并发线程发展（大概意思是线程越多越能够隐藏访存损失）。并且，尽管每个线程的片上缓存很小，但因为局部性原理，仍然可以有效减少大量的片外存储访问。</p><p>SM的微体系结构，流水线分为SIMT前端和SIMD后端，共3个循环：</p><ol><li>取值（fetch）循环：fetch、I-Cache、Decode和I-Buffer模块</li><li>发指（issue）循环：I-Buffer、Scoreboard、issue和SIMT stack模块</li><li>寄存器访问调度循环：Operand Collector、ALU和Memory模块</li></ol><p><img src="image.png" alt=" "></p><h3 id="3-1-单循环近似">3.1 单循环近似</h3><p>线程的调度单位是warp（AMD称之为wavefronts）。每一个周期，SM选择一个warp进行调度。</p><p>单循环中，warp的程序计数器（PC）用于访问指令存储器时查找为warp执行的下一条指令。获得指令后，对指令解码，并找到源操作数寄存器。与此同时，SIMT的执行掩码值也被确定。</p><p>在执行掩码与源寄存器可用后，执行以SIMD的方式进行。如果设置了SIMT执行掩码，则每个线程都在与通路关联的功能单元上执行。与现代CPU一样，功能单元通常异构，即不同的单元支持不同的指令运行。</p><p>每个功能单元在名义上包含的通路数与warp的线程数相同，但也有一些GPU使用不同的实现，使其中的warp在多个时钟周期内执行。</p><h4 id="3-1-1-SIMT执行掩码">3.1.1 SIMT执行掩码</h4><p>现代GPU的关键特性是SIMT执行模型，为程序员提供了单个线程完全独立执行的抽象，这是通过传统谓词（prediction）与SIMT谓词掩码堆栈结合实现的。</p><p>SIMT堆栈有助于处理线程可以独立执行时出现的两个关键问题：</p><ol><li>嵌套控制流</li><li>完全跳过计算</li></ol><table><thead><tr><th style="text-align:center"><img src="image-1.png" alt=" "></th><th style="text-align:center"><img src="image-2.png" alt=" "></th><th style="text-align:center"><img src="image-3.png" alt=" "></th></tr></thead></table><p>假设每个warp有四个线程，所有线程都执行了A基本块，之后遵循不同的控制流，有3个线程进入B，1个线程进入F。如此流动，最后所有线程统一到达G。</p><table><thead><tr><th style="text-align:center"><img src="image-4.png" alt=" "></th><th style="text-align:center"><img src="image-5.png" alt=" "></th></tr></thead></table><p>堆栈包括三项：重新收敛程序计数器(Reconvergence program counter, RPC)、要执行的下一条指令的地址(Next PC)和活跃掩码(active mask)。warp每次都执行栈顶指针指向的条目的nextPC指向的代码块</p><ol><li>开始时堆栈中只有一个条目“-，A，1111”。代表所有线程都将进入A。</li><li>所有4个线程在走完A之后进行分支，此时需要有3处修改：<ul><li>将原先条目的nextPC值修改成分支后的重新汇聚点，对于这次分支B和F，将在G重新汇聚，因此将第一条的nextPC由A修改为G</li><li>这次分支有3个进入B，1个进入F，因此在堆栈中压入关于B和F的两个条目</li></ul></li><li>线程执行栈顶条目“G，B，1110”，掩码是1110代表这行条目对前三个线程active，走完B后进行分支，同理修改原来条目的nextPC，改成最近的重新收敛点E，同时添加两个分支条目。<ul><li>一般改成最近的重新收敛点，是为了从该位置将之前发散的线程以锁步的方式继续执行，便于同步</li><li>通常来说，在分支过后，最好是先将最多活跃线程的条目先入栈，少活跃线程的条目后入栈，例如d部分，而c部分的例子相反</li></ul></li></ol><h4 id="3-1-2-SIMT死锁与无堆栈SIMT结构">3.1.2 SIMT死锁与无堆栈SIMT结构</h4><p>SIMT基于堆栈的实现可能导致死锁：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-comment">// 将mutex置0代表资源空闲</span><br>*mutex = <span class="hljs-number">0</span>;<br><span class="hljs-comment">// atomicCAS读取mutex，若为0，则置1（即若空闲，则访问），返回mutex原始值</span><br><span class="hljs-comment">// 一个warp中的所有线程都执行，因此只有一个线程看到mutex=0，其他都看到=1</span><br><span class="hljs-keyword">while</span>(!atomicCAS(mutex,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>));<br><span class="hljs-comment">// 释放mutex</span><br>atomicExch(mutex,<span class="hljs-number">0</span>);<br></code></pre></td></tr></table></figure><p>简而言之，对于一个互斥资源，当一个warp的所有线程同时执行互斥锁式访问时，只有一个线程拿到资源，其他线程陷入原地等待。但是，拿到资源的线程在执行完毕后，达到了上文中的重新收敛点，会等待其他所有线程一起到这个点，才能继续执行第三句释放锁。</p><p>无堆栈分支的重新收敛机制：warp收敛屏障</p>]]></content>
    
    
    <categories>
      
      <category>work</category>
      
    </categories>
    
    
    <tags>
      
      <tag>论文阅读</tag>
      
      <tag>GPGPA</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>00：个人网站部署</title>
    <link href="/2023/09/13/00%EF%BC%9A%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99%E9%83%A8%E7%BD%B2/"/>
    <url>/2023/09/13/00%EF%BC%9A%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99%E9%83%A8%E7%BD%B2/</url>
    
    <content type="html"><![CDATA[<p>花了两三天时间搭了一个用于笔记的个人博客，部署在了 github 上，这里记录一下部署的过程。</p><span id="more"></span><h2 id="选型">选型</h2><p>网站的建立主要是为了搭一个在公司和家里都能访问的博客环境，对工作和学习做一些记录，所以直接放弃传统的带前端后端的动态页面，时间成本太高，整一个可以一键上传 markdown 的静态页面就挺ok。前端框架采用 hexo，UI选择 fluid，代码放在 github 上，并使用 github action 进行持续集成，部署到 github pages 后，后续写作只需要一次 git push 就可以自动将文章更新到目标网站上。</p><h2 id="框架搭建">框架搭建</h2><p><a href="https://hexo.io/zh-cn/docs/">https://hexo.io/zh-cn/docs/</a></p><h2 id="UI设置">UI设置</h2><p><a href="https://hexo.fluid-dev.com/docs/guide/">https://hexo.fluid-dev.com/docs/guide/</a></p><h2 id="部署">部署</h2><h3 id="快速部署">快速部署</h3><p><a href="https://hexo.io/zh-cn/docs/one-command-deployment">https://hexo.io/zh-cn/docs/one-command-deployment</a></p><p>适用于希望源代码保存在本地而不用上传的情况，相当于本地构建完再将构建好的网页直接推给gh page</p><p>需要在 _config.yml 中配置 gh page 的仓库地址和分支，推送后，hexo 会将 public 目录中的文件推送至_config.yml 中指定的分支中，并且完全覆盖该分支下的已有内容。</p><p>这就导致了一个问题，由于是只传 public 目录，域名映射需要的CNAME文件只能放到 public 下，这样每次 hexo clean 后会清空 public，还得再编辑一次CNAME，但是好处在于刨除了云端构建的不稳定性，每次可以本地看看网站效果，再直接放到 gh page 中</p><h3 id="gh-actions-持续集成">gh actions 持续集成</h3><p><a href="https://easyhexo.com/1-Hexo-install-and-config/1-5-continuous-integration.html">https://easyhexo.com/1-Hexo-install-and-config/1-5-continuous-integration.html</a></p><p>源代码放到 <a href="http://user.github.io">user.github.io</a> 仓库中后（仓库名只能设为这个，否则生成网页会变成 <a href="http://user.github.io">user.github.io</a> 的子页），CNAME 放在 source 中，然后在 .github/workflws 中定义 gh actions 的详细配置</p><p>采用的hexo官方文档中的配置，最后一步使用 peaceiris/actions-gh-pages@v3 咱也不太懂，参考知乎上的其他配置，大概相当于安装 hexo 完了在将 main 分支的源码 deploy 到 gh-pages 分支上，之后在设置时选择这个分支即可</p><p>主要问题在于每次 push 都要重新 build，推测后期内容增多后网站更新会十分不及时，可能需要看看别人的追加更新是咋弄的</p><h3 id="CDN加速、">CDN加速、</h3><p>更换 Cloudflare 的 DNS，注意 SSL/TLS 加密模式设为严格</p><h2 id="Summary">Summary</h2><p>属于我的第0篇博客，大概，能在网站上正常显示，证明基本功能已经ok</p><h2 id="TODO">TODO</h2>]]></content>
    
    
    <categories>
      
      <category>work</category>
      
    </categories>
    
    
    <tags>
      
      <tag>前端</tag>
      
      <tag>记录</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
