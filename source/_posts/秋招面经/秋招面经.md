---
title: 秋招面经
date: 2024-07-08 14:34:57
categories:
- work
tags:
- interview
---


<!--more-->

## 简历描述
面试官您好，我叫XXX，来自湖北省荆州市。本科毕业于武汉大学计算机系，研究生就读于中国科学技术大学软件学院，预计将于明年六月份毕业。

在校期间，我获得过一次二等学业奖学金。研一期间，我独立完成了MIT的6.S081课程项目，设计并实现了一个精简的类Unix操作系统中的部分核心功能，包括内存管理、进程管理和文件系统等。

在研二开始，也就是去年七八月份，我来到燧原科技进行日常实习，主要负责公司推理加速卡的性能优化，至今已有将近一年的时间。这段时间里，我主要做了以下几方面的工作：

第一，组内的日常性能优化。在收到针对某网络或算子的性能优化需求后，我们会使用组内的autotuner框架处理网络或算子，获得算子级别的切分数据，并进行上卡实跑。通过性能对比，得到网络上各类算子的最佳切分，完成一次调优工作。

第二，autotuner的重构工作，称为tuner2.0。原先的autotuner流程比较繁琐，展示了过多的末端细节，只适合开发人员调试和使用。我们希望这一系统可以交给用户，甚至直接融入加速卡推理运行的生命周期中。因此，我的工作是对tuner的核心runner模块进行重写，利用多线程的思路提高系统健壮性，并完善异常处理等功能。

第三，为autotuner引入基于深度学习的启发式搜索模型，这也是我毕业论文的研究方向。原先基于单一网络的自动调优虽然能提供极致的性能优化，但本质上是根据加速卡的各项硬件参数，对算子的每一种可能切分进行实跑，进而找到最佳结果，运行时间较长且应用场景有限。当前的想法是设计一个在线学习模型，在得到足够量级的实跑数据后，对后续进入的算子数据直接推理出性能结果，以节省调优时间。

以上是我目前的一些工作经历和成果。谢谢！


### autotuner
我们知道张量运算由于大量的数据并行和数据吞吐，怎么高效地组织张量中各个元素的访存和调度，是机器学习编译器性能提高的重点。
TVM这种深度学习编译器的工作流程就是IR进行流转的过程。从Pytorch、Tensorflow、ONNX这类框架中导入模型后，TVM首先会将模型翻译成他自己的一种模型语言RelayIR，经过图级别的优化以及模型切分、降级之后转化成一个个小的张量表达式，也就是TE。对应到我们的autotuning系统中，我们首先会提取出经过多层pass流转处理过后的最后一级IR，我们叫做lastIR，这一层包含了经过图级别优化、降级之后得到的模型全部计算节点信息，然后从里面提取出目前支持tune的算子种类，例如conv、dot等等，对于每个算子，经过我们的cost model计算出性能最佳的调度参数，对应到我们的系统里，目前还是使用的基于实际硬件的黑盒模型，也就是将调度参数上机实跑得到运行时间这种性能数据


## 招聘情况

### 科大讯飞-提前批（飞星计划）-AI研究算法工程师-深度学习框架和平台方向
![alt text](image1.png)

#### 0628投递

#### 0708技术一面 40min

虚函数，静态多态和动态多态，内存分页机制，LRU

怎么排查内存泄漏

快排复杂度，为什么最坏是n^2

一条绳子切m段，怎么切使得每段长度之积最大（动态规划）

项目创新点，autoTVM算法

表达的太垃圾了。。。表述要清晰

有点kpi，最后“如果没什么问题我们就结束了”。。。反问环节也没有

0718通知一面过。。。约0725晚上八点二面，应该比一面容易

### 科大讯飞-提前批（飞凡计划）-研发方向
![alt text](image2.png)

#### 0706投递

