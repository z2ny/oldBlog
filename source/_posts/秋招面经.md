---
title: 秋招面经
date: 2024-07-08 14:34:57
categories:
- work
tags:
- interview
---

<!--more-->

## 招聘情况

### ❌科大讯飞 飞星计划 AI研究 深度学习框架和平台方向

#### 技术一面 0708 40min

虚函数，静态多态和动态多态，内存分页机制，LRU

怎么排查内存泄漏

快排复杂度，为什么最坏是n^2

一条绳子切m段，怎么切使得每段长度之积最大（动态规划）

项目创新点，autoTVM算法

表达的太垃圾了。。。表述要清晰

有点kpi，最后“如果没什么问题我们就结束了”。。。反问环节也没有

0718通知一面过。。。约0725晚上八点二面

#### 技术二面 0725 40min

全是大模型优化之类，岗位明显不太符合，25分钟提前结束，寄

面评：综合评估下来，大模型的了解不足，推理优化知识较为不清晰。

### ❌科大讯飞 飞凡计划 研发

#### 笔试 0803

#### 技术一面 0809
问到java和golang，不是很匹配

智能指针 静态/动态多态 内存泄漏的预防 操作系统锁 golang的协程与C++线程区别 无锁编程 malloc/new/free/delete

继承/构造/析构 基类指针指向子类对象 空类/结构体的大小 带虚函数的类大小 带const的类大小

### ❌OPPO 底层软件

#### 技术一面 0821
主要问项目，但不很涉及细节，可能一面在于考察简历是否真实

进程调度中的时间片轮转算法，如何加入优先级，怎么保证进程不会饿死

虚拟内存怎么映射到物理内存，为什么需要虚拟内存，怎么实现内存分页，内存分页的意义，是怎么提高访问效率的

多线程怎么实现数据共享

面试官在平台与内核开发部，问的问题很快，20分钟就结束，但是回答我的问题也还比较仔细，不确定是否KPI

#### 综合面 0901
他吗牛客上别人都开奖快一个月了，不会又是kpi面吧

ok，被狠狠kpi了，面试官也不耐烦。15分钟面完光速被挂，以后约面一定不能拖，hc都没了还面什么

### ❌寒武纪 高性能算法

#### 笔试 0826
BFS/DFS 动态规划

#### 技术一面 0910
偏聊天，讲讲项目，后面一道让设计一个FP28精度的数据结构，一道动态规划

#### 技术二面 0923
牛客可以识别面试网页是否在最前端，慌了，看面经被逮到直接慌不择路，寄

### 中兴 领军计划 算法（智算）-> 软开

#### 技术一面 0903
纯聊天半小时，技术方向，刷题情况，工作中的困难以及如何解决，比较随意

问到base说主要长沙，问流程说这就是技术面，后面还有综合面

0909感谢信，看来自己表现不太行

#### 技术二面 0913 流程转软开正式批
噢牛皮，领军被KPI了接着流程面软开

base也换了，长沙/深圳

常规综合面问题，为什么选择中兴，预计薪资，职业规划，加班看法，出差看法，是得整理一下了

#### 终面 1016
聊家庭情况 base选择 说武汉没hc了只有深圳，要了35+

### 华为 AI软件开发 终端软件部

#### 笔试 0828
“主要考察字符串，差分，二分法，bfs/dfs，贪心。不考动态规划”

#### 复活赛 1016
A了两道 应该过了

### ✅经纬恒润 C++

#### 技术一面 0906
聊了二十分钟，讲讲项目互相介绍，体验很好

#### 技术二面 0919
要求准备15minPPT

<!-- 面试官您好，我叫张亦行，来自湖北省荆州市，本科毕业于武汉大学，研究生就读于中国科学技术大学，预计是明年毕业

因为我研二期间有过一年的实习经历，自己的大部分工作成果都是在其中取得的，我选了实习过程中的一段和自己论文方向比较近的工作来进行展示

首先介绍一下我目前的实习公司，燧原科技是一家专注于人工智能领域的创新型公司，致力与为通用人工智能打造基础算力底座，提供原始创新，具备自主知识产权的AI加速卡、系统集群，以及周边的软硬件解决方案，简而言之公司主要是做国产推理加速芯片的，右边就是公司成立以来推出的所有主要产品，推理芯片上包括第一代的i10，第二代的i20，目前公司的第三代推理芯片产品S60也正在研发中。我在performence部门的tuner组内实习，作为算法工程师岗位，之前在公司的所有工作，都是围绕S60上的的算子调优展开的

有关算子优化，目前组内已经有了一套算子测试以及离线查找最优配置的框架，叫做autotuning，右图是autotuning的工作流程图，包括客户端与服务端的通信，如何远程启动计算卡进行测试，如何回收结果以及测试数据等。我在加入tuner组后，日常工作主要是负责框架的测试以及debug工作。梳理从模型输入到算子级别优化，再到机器执行的全过程，维护公司的这一套框架并使用该框架对主流算子进行针对性手动测试和调优。在今年三四月份的时候，组内计划是将这一套框架重构，并且将调优工作逐步从离线手动调优转向自动搜索，采用机器学习的方法构建一套配置推理模型，这也是我论文的选题方向

下面我会分三个方面介绍一下我的工作内容

第一是组内的日常优化工作。在收到针对某网络的性能优化需求后，我们会使用组内研发的一套调优框架来处理这个网络中的可调优算子。我们知道算子是模型的基本计算单元，算子中的张量运算往往涉及大量的数据并行和吞吐，这就涉及到一个数据调度的策略，而芯片由于核心数量、缓存大小等限制，对张量的不同调度策略会导致处理这些数据时巨大的性能差异。我们会利用组内的调优框架，得到针对某个算子的所有调度方式，再对每一个调度方式进行上机测试，得到该算子的最优调度，即完成了一次调优工作。

第二部分是组内调优框架的重构工作，我们称为tuner2.0。原先的框架更多是面向A端，也就是我们在收到客户对他们的模型的优化需求时，需要手动的筛选并优化其中的算子。在后续使用场景上，我们希望这一套自动调优系统是可以直接面向用户，甚至是直接融入深度学习编译的流程之中。因此工作重点在于将原先的框架做一个拆解和重写。原先的框架在流程上主要分为算子提取、切分生成、切分搜索、性能测试等等。我在其中主要负责切分搜索模块的一个重构工作，包括应用全新的单例模式和工厂模式对搜索模块做一个解耦，提供多种不同的搜索模型接口，为核心切分性能计算引入多线程、完善异常处理等等。

第三部分，也是我毕业论文的研究方向，是为自动调优系统引入一个基于深度学习的启发式搜索模型。我们知道一个算子的调度策略可以分为多个维度，称作调度原语。比如切分原语用于决定张量形状的切割大小，重排原语用于调整张量计算中的循环次序，还有一些计算局部性、内存控制等等原语。这些调度原语的取值可以组成一个多维的参数空间，空间中的每一个点，就是算子的一种调度方式，或者说一个配置。对应到右图，我们给定张量运算e一个调度模板Te后，它所使用的所有可调旋钮记为向量K，K的长度|K|即为此模板T中旋钮的个数。向量K的所有可能的取值构成了一个|K|纬的搜索空间S。搜索空间中的一个点，称之为一个配置config，即向量K的一个实例，它与调度模板Te构成的元组（Te ,config）即构成一个完整的可调度算子的完整信息。让x=g（Te ,config）代表生成的算子可执行程序,其中为生成可执行程序的深度学习编译器基础软件栈, f（x）代表对生成可执行程序性能的评价。
自动调优系统，就是在这个多维的参数空间中找到性能最佳的配置也就是f（x）的极值点进行输出。由于将整个参数空间中的每一个点都进行测试非常耗时，而且往往也并不需要这么极限的调优，可能只需要性能在前5%，或者达到某个基准性能的配置就可以作为输出了。因此我们希望设计出一个代理模型，能在实测数据有限的情况下，直接评估出这个参数空间中剩余点的性能，并且从里面选出符合条件的配置作为输出。我目前的研究是设计一个在线的自学习模型，伴随我们框架的调优周期不断迭代更新，逐渐取代原有的实机测试。

对一个AI编译框架来说，算子级别的调优往往处于整个编译流程的后端部分，编译器在接收包括tensorflow、pytorch、ONNX格式的深度学习模型之后，首先要经过多个级别的pass处理，完成高阶图IR的各种硬件无关的转换和优化，并交由后端将图IR转换为以图节点为单位的低阶IR，也就是算子，而算子调优系统，就是在接受到这些带参数信息的算子之后，针对该算子类型为其找到最优数据调度方式，作为该算子的参数配置传递给底层LLVM编译执行
下面是我们组内autotuning框架设计的算子IR，是一串我们叫做tuning string的字符串，这是一个conv以及bias的融合算子，字符串中包含了计算平台、数据类型，IO形状、步长、填充、数据布局等等算子的描述，再进过调优系统后，可以根据这串描述信息得到这个算子的调度方式，比如逐元素操作的方式、采用机器的哪种实现、在什么层面进行loop之类的，并且得到一个该配置的性能分数，这里用的是运行时间

上面是系统功能需求有了，而系统另一个设计重点是如何高效的找到更好的性能配置。传统的调优方式，一般是使用离线搜索，由有经验的工程师根据算子特点以及机器参数，针对每一种算子手写调度模板，用以确定算子的配置搜索空间，并采用诸如穷举、模拟退火、遗传算法等各种搜索方法进行搜索，这种方式往往效率比较低，对手写模板的要求比较高，成本过大。
而如果采用离线的机器学习模型进行调优，首先是多种多样的算子以及计算平台会极大的限制模型的灵活性，此外每个算子动辄十万级的学习样本也会增大模型训练的复杂度，费时费力
因此，我的工作，或者说在runner模块上的重构，就是探索一种基于在线学习的自动调优方法，使用代理模型来量化算子配置的好坏程度，并且边搜索边更新模型，在传统搜索的繁重搜索消耗与离线模型训练的繁重训练消耗之间取得一个良好的平衡

右图是本系统核心模块的工作流程图，在线学习将以迭代的方式逐步推理算子的最优配置，模型在得到搜索空间后，每次选择一批配置上机进行硬件测量，得到性能数据，再根据这批数据更新模型，进行一次迭代。这种方式极大的降低的调优的时间消耗，但也产生了一个新的问题，就是在线学习模型的利用——探索权衡。由于搜索空间的巨大，在迭代过程中每次仅能使模型学习到一部分的数据，是利用模型已经学到的数据来做出决策，还是认为模型还未学习到全局最优解附近的分布，应当继续探索参数空间，将成为影响模型效果好坏的一个关键问题

因此，为了兼顾利用和探索，在每轮迭代中，除了采用基于模型上轮筛选出高潜力配置之外，还要加入了一些随机配置，以供模型跳出局部最优。在右边的实验中，每轮迭代时取ε比例的随机配置交由机器学习，观察迭代结果可以看到，ε取值较小的时，调优的过程偏重于选择模型视角下的最优值附近的配置，所选出的待测配置相对集中，缺乏对配置空间中模型未知部分的探索；当ε取值过大的时，代理模型的作用明显减弱，使得基于模型搜索的调优呈现出一种朝着随机调优退化的态势，损害调优效率。因此一个合适的ε值对模型效果影响非常巨大。
一般的其他家类似的模型里面，这个加入随机候选配置的比例往往是固定的，以一个ε超参来确定，这就带来一个问题，当ε过小时，调优会过度偏重于模型视角下的局部最优，而ε过大，又会导致模型朝着随机调优的方向退化，收敛速度极慢，这就和我们当初既要照顾收敛速度又要考虑泛化性能的需求相悖了。所以我们在这个点上，设计了一种自适应的ε值，我们希望模型在训练的前期，尽量多尝试一些随即配置，更偏向搜索；而后期则可以相应的降低这个ε值，是模型更偏向利用。然而这就需要模型对自身训练状态有一个度量，考虑到最后，我们是选择了贝叶斯模型来作为神经网络的主体，贝叶斯作为一种概率式的模型，通过对每条权值边的概率量化可以确定模型的整体可靠性，我们将ε值设置与模型所有权重边分布的标准差成对数正比关系，当模型前期权变标准差很大时，代表模型可靠性还比较低，此时将ε值设置搞一点，推进模型的探索；在后期模型可靠性随着迭代逐渐提高时，就可以相应的降低这个ε值，这也是我的主要工作之一

至于如何实现这一点，我和另外一个同事在参考了深度学习编译器的其他论文，包括学长的科研成果之后，决定采用一种基于贝叶斯神经网络的概率式模型作为搜索模型的主神经网络。普通的神经网络，在反向传播结束后，模型的参数是一个确定的值。而贝叶斯神经网络假设每个参数都服从一个分布函数，通常选择均值为𝜇, 标准差为𝜎的高斯分布。贝叶斯神经网络的学习过程，是在调整每条边上的分布函数。引入贝叶斯神经网络作为代理模型后，在每一轮迭代结束后，可以通过评估网络上所有参数的标准差的平均水平，以为衡量代理模型当前状态下的不确定性，并据此
适当调整下一轮调优迭代中随机候选配置的比例𝜀。 -->

#### 技术三面 0929
原先部门不招人，调岗之后重新讲一遍ppt，难绷

#### hr面 1009
电话询问base，薪资等等，面经上说这家公司很好A于是直接说了个30+，流程审批大概1-2周

#### oc 1015
还真给到了30+，21k*12+5w年终，无绩效压力+五险一金拉满，base经开，组内大概20人，除了是小厂各方面都不错了

### ✅招行 后端

#### 技术一面 0905
八股基础，会问到数据库，代码题简单写一个冒泡排序

#### 线下二面 0911
基础+一些场景题目，如何为淘宝订单设计一个独一无二的订单号，如果和同事意见不一致怎么解决

#### 邮件oc 1018
等了一个多月。。可能是前面释放hc轮到我了。20*15，只能说一般，可能比较稳定？

### TP联洲 软开

#### 技术一面 0912
忘记写了 常规

#### 技术二面 0925
常规 投屏写个排序 被夸专业还行

#### 三面 1014 线下
又迟到了。。基础八股，面完心理测评，等一个座谈会

#### 座谈会 1018 线下
16薪，7.5小时工作制，公司目前发展状况还行，看能开到多少吧

### 金山办公 客户端

#### 技术一面 0925
面试官迟到十分钟，然后是至今为止最漫长最细的八股拷打，预计45分钟结束结果面了70分钟
多态的意义、编译器在构造类的对象时会做什么，运算符重载的意义，静态成员的意义，泛型编程，C++的特色语法，lambda表达式怎么存储，C++多线程怎么设计，async，多线程的意义、困难点，怎么减少线程竞争，死锁如何避免，多线程和多进程的意义
关系型数据库和普通表的区别，怎么设计关系型数据库，数据库怎么保证完整性

### ❌奕行智能 编译器
智联猎头推荐的，一看名字还怪有缘就面面吧

#### 技术一面 0830
一面和笔试一起俩小时，小公司流程比较随意，前面拷打半个小时项目，主要问燧原加速卡自动调优系统，有点偷师嫌疑。后面直接发了三个leetcode，2mid1hard要求做两个以上，最难绷的是由于开启的录屏和摄像头，腾讯会议被强行缩减时长到一小时，中途到一小时后强行退出会议，再上线也就是继续做，这不直接百度天理难容，怕后面露馅还是只做了两个mid

问base主要在杭州，薪资也就20

#### 技术二面 0905
拒

### ❌联想 linux

#### 技术一面 0910
开场直接问linux不bb，问得比较深

linux进程管理和内存管理，是怎么管理物理内存到虚拟内存的，伙伴算法 slab分配器，伙伴算法为什么分内存类型，伙伴算法和slab会不会导致缺页中断，linux进程调度的时机。。

有点知识盲区，寄

### SHEIN 后台

#### 技术一面 0912
常规

#### 技术二面 0914
十五分钟简单聊天，主管说主要面向N卡做一些AI平台的优化，问我对国产卡的前景的看法之类，表示比较合适然后结束，后面还有总经理面

#### 三面 1004
hr假期晚上10点约面。。。简单聊了下项目，base，最近学的东西，对寒武纪、摩尔线程的看法，胡言乱语，但体验还不错

#### hr面 1011
常规问题 性格优缺点 加班看法

### ❌联影医疗 后端

#### 技术一面 0913
常规，说主要面向前后端，后续会往全栈发展，可能不太合适

### ❌开立医疗 C++

#### 技术一面 0914
挺敷衍的，20分钟，基础问题，看得出来面试官没什么耐心

### ❌长存 软开

#### 技术一面 0918
女面试官，人好说话，比较在意我去迟了。。几点去还不是要排队吗。。

linux inode是65535，inode溢出可能的原因

0923感谢信 牛批

### 海康威视 软开

#### 技术一面 0926
明显对嵌入式更感兴趣，但是还比较好说话，手撕一道easy，不知道有无后续

#### 综合二面 1017 线下
15分钟简单聊天，武汉要了30

### 平头哥 芯片软件工程师

#### 技术一面 0929
常规，忘了，手撕是一个基础矩阵相乘

#### 技术二面 1011
沈正海，人很好，项目问很细，答得不好

### 黑芝麻 嵌入式

#### 技术一面 1012
面试官贼坦诚，50分钟有45分钟都是他在说，包括各种经验分享，公司加班情况，工作内容。。。总结小厂，人不多，加班强度高，需要驻场，让我快跑的意思

### ✅烽火通信 软开

#### 一面 0930
20分钟，一点点八股，面试官像赶时间一样，判断你是个人就过了？

#### 二面 1010
15分钟聊天，base意向，有无其他offer，会不会选烽火，还是没看出来考察了个什么

#### 邮件oc 1016
总包22.4，月薪12+3，不知道怎么算的，能开出这个价也挺幽默

<!-- ## 简历介绍

面试官您好，我叫XXX，来自湖北省荆州市。本科毕业于武汉大学计算机系，研究生目前就读于中国科学技术大学软件学院，预计将于明年六月份毕业。

在校期间，我以年级前10%的GPA获得过一次二等学业奖学金。研一时，我独立完成了MIT的6.S081课程项目，学习操作系统的一些功能设计，主要内容是在linux上模拟一个小的类Unix系统，并完成他的大部分核心功能，包括内存管理、进程管理和文件系统等。在校期间我开始写个人博客，主要记录一些学习心得。

从研二开始，也就是去年的七八月份，我去到上海的燧原科技进行日常实习，这是一家做国产推理加速芯片的独角兽公司。我是作为算法工程师参与公司加速芯片的一些优化工作。这段时间里，主要利用组内的自研框架完成一些算子调优，并且在框架上做一些改进与研究。实习期间产出了一篇关于深度学习编译器中自动调优框架的专利，目前还在审核之中。

以上就是我目前的一些实习经历和项目成果。谢谢！

### 燧原实习

第一是组内的日常优化工作。在收到针对某网络的性能优化需求后，我们会使用组内研发的一套调优框架来处理这个网络中的可调优算子。我们知道算子是模型的基本计算单元，算子中的张量运算往往涉及大量的数据并行和吞吐，这就涉及到一个数据调度的策略，而芯片由于核心数量、缓存大小等限制，对张量的不同调度策略会导致处理这些数据时巨大的性能差异。我们会利用组内的调优框架，得到针对某个算子的所有调度方式，再对每一个调度方式进行上机测试，得到该算子的最优调度，即完成了一次调优工作。

第二部分是组内调优框架的重构工作，我们称为tuner2.0。原先的框架更多是面向A端，也就是我们在收到客户对他们的模型的优化需求时，需要手动的筛选并优化其中的算子。在后续使用场景上，我们希望这一套自动调优系统是可以直接面向用户，甚至是直接融入深度学习编译的流程之中。因此工作重点在于将原先的框架做一个拆解和重写。原先的框架在流程上主要分为算子提取、切分生成、切分搜索、性能测试等等。我在其中主要负责切分搜索模块的一个重构工作，包括应用全新的单例模式和工厂模式对搜索模块做一个解耦，提供多种不同的搜索模型接口，为核心切分性能计算引入多线程、完善异常处理等等。

第三部分，也是我毕业论文的研究方向，是为自动调优系统引入一个基于深度学习的启发式搜索模型。我们知道一个算子的调度策略可以分为多个维度，称作调度原语。比如切分原语用于决定张量形状的切割大小，重排原语用于调整张量计算中的循环次序，还有一些计算局部性、内存控制等等原语。这些调度原语的取值可以组成一个多维的参数空间，空间中的每一个点，就是算子的一种调度方式，或者说一个配置。自动调优系统，就是在这个多维的参数空间中找到性能最佳的配置进行输出。由于将整个参数空间中的每一个点都进行测试非常耗时，而且往往也并不需要这么极限的调优，可能只需要性能在前5%，或者达到某个基准性能的配置就可以作为输出了。因此我们希望设计出一个代理模型，能在实测数据有限的情况下，直接评估出这个参数空间中剩余点的性能，并且从里面选出符合条件的配置作为输出。我目前的研究是设计一个在线的自学习模型，伴随我们框架的调优周期不断迭代更新，逐渐取代原有的实机测试。

#### 困难点

如果将这个搜索模块建模的话，可能就是一个比较直接的回归任务，接受多维输入，得到一维输出。以一些调度策略比较少的算子来说，可能一个xgboost收敛后也能取得很好的效果。但困难点在于我们要利用非常有限的数据集，对整个参数空间进行搜索，这对模型的泛化性能要求非常高，同时也要考虑的模型的收敛速度或者说利用程度。为了解决这一点，我的想法是设计一个在线的自学习模型，每轮迭代时使用模型挑选出一些待测配置，以及一部分用于提高泛化性能的随机配置，将这些配置上机实跑，得到实际性能后再反哺给模型进行训练。通过不断地迭代，慢慢提高模型对配置选取的精度，直到取代上机实跑直接输出。
初始化性能数据集 -> 代理模型选择一批待测配置+随机配置 -> 实跑得到每个配置的性能数据，并加入性能数据集 -> 利用性能数据集更新代理模型

一般的其他家类似的模型里面，这个加入随机候选配置的比例往往是固定的，以一个ε超参来确定，这就带来一个问题，当ε过小时，调优会过度偏重于模型视角下的局部最优，而ε过大，又会导致模型朝着随机调优的方向退化，收敛速度极慢，这就和我们当初既要照顾收敛速度又要考虑泛化性能的需求相悖了。所以我们在这个点上，设计了一种自适应的ε值，我们希望模型在训练的前期，尽量多尝试一些随即配置，更偏向搜索；而后期则可以相应的降低这个ε值，是模型更偏向利用。然而这就需要模型对自身训练状态有一个度量，考虑到最后，我们是选择了贝叶斯模型来作为神经网络的主体，贝叶斯作为一种概率式的模型，通过对每条权值边的概率量化可以确定模型的整体可靠性，我们将ε值设置与模型所有权重边分布的标准差成对数正比关系，当模型前期权变标准差很大时，代表模型可靠性还比较低，此时将ε值设置搞一点，推进模型的探索；在后期模型可靠性随着迭代逐渐提高时，就可以相应的降低这个ε值

关键问题：在线学习模型在迭代的过程中，如何评估模型的泛化性能，以及对模型的性能进行一个度量。

### 6.s081

这个项目主要是参考MIT的一门操作系统课程，在一个基于RISCV架构的精简版操作系统上完成他的一系列功能。从任务分类上来说，大致做了三项工作：

第一是 虚拟内存管理，

第二是 中断处理

第三是 文件系统

#### 困难点 -->

## HR面准备

### 为什么选择XXX公司


### 职位方向选择：为什么投C++/linux

我之前的实习经历中有过一些算法设计相关的研究，但主要工作还是集中在工程实现上。而且在实习的过程中，我发现尽管有时候设计和理论研究很关键，但真正决定项目质量的核心还是在工程化能力上，包括对C++/linux系统的底层理解、代码能力以及软件工程设计等等。实习期间这一方面的学习让我自己项目的实现有很大的帮助。所以我感觉相比深度学习里面一些比较玄学的研究，底层实现包括操作系统的工作原理、以及编程语言的深入学习等等反而更加吸引我，这也是我选择C++/linux岗位的主要原因。

### 职业规划

我觉得作为研发岗位来说，职业道路的第一步首先是精通公司需要的技术栈以及工作流程吧，这方面首先是需要学习，因为我们刚进去可能对组内某些特定领域的侧重点还不太了解，我觉得至少能将自己组内的工作任务和所需技能研究透，这是规划的第一步。
然后在实现自己的工程能力的目标之后，我希望自己可以开始参与公司项目的一些关键技术的设计，从小的开发需求逐步转向系统设计、架构研究等等。我希望自己在这一阶段能够对团队的包括代码质量、系统整体效率等等带来一个推动作用。
再往上就是，我希望自己可以从更加宏观的角度，比如产品的整体流程、各个系统模块之间的构思等等来思考问题，并且最终能够领导一个项目的落地工作。
总而言之，我首先是希望自己在技术上深耕，能够把一个系统设计完全研究透彻，然后在这个基础上开始由微观到宏观，逐渐过渡到一些设计和领导工作，让自己在工作上发挥越来越大的价值。这是我目前想到的对自己的职业规划。

<!-- ### 性格优缺点

我认为我的优点是执行力还比较强，包括工程化思维，解决问题的能力这一块吧。因为之前在实习的过程中，很多场景都是leader会给一个大致的解决思路，然后交给我们自己去实现，这就给了我一个很大的试错空间，可以帮助我去学习怎么将问题拆解，实现，然后再后续一步一步调整完善。

过于关注细节：

### 最成功/失败的经历

我认为我最成功的经历都是自己在未来规划上的抉择吧。其实大四秋招的时候我是有几个offer的，因为当时比较爱玩，然后觉得自己对游戏开发更感兴趣，就去到广州那边的三七互娱做了差不多三个月的开发类的管培生。那边其实开的条件也比较好，然后环境也很好，我觉得如果大部分人可能在有了这个工作之后都会选择留下来吧。但是我在那边实习的过程中，逐渐感觉自己对游戏运营、甚至策划方面没有那么多兴趣

### 加班看法

我个人还是比较倾向于任务驱动的工作方式，然后任务导向嘛，就得适应工作强度上的波动，所以我还蛮能接受在推进自己的任务期间的一些加班，但是我希望加班是有一个清晰的目标或者说是我知道我在推进一个我所认同的项目。而不是为了混时长而加班，总体上来说，还是工作效率第一吧，然后任务优先，为了完成任务而加班吧。

### 出差看法

我目前还没有女朋友，而且感觉自己在生活中还是比较偏向工作优先，所以平时的加班或者出差对我来说都是可以接受的。而且我觉得出差也是一个还不错的机会去了解一些不同的地方或者扩充自己的视野。当然说的都是一般情况下的出差，如果是长期比如三个月以上或者异地太远比如说出国之类的，可能就需要考虑的多一点 -->

## 反问

目前在什么轮次，hc是否充足，后面是什么流程

公司对应届生的培养模式

我投递的岗位有没有直接对接的部门，如果有，组内目前主要负责什么方面的工作

组内一个典型的一周工作是怎样安排的

您在这里工作多久了，您觉得体验如何

## 常见八股

const：常量修饰符，表示变量的值无法被修改
修饰指针：指针常量——指向的地址中的值无法被改变；常量指针——指向的地址无法改变
修饰成员函数：不能修改类中未被mutable修饰的成员变量
修饰对象：表示该对象的成员无法被修改，且只能调用const修饰的成员函数

static：静态修饰符，
修饰局部变量：表示该变量初始化后的生命周期从函数调用变成程序的整个生命周期，后续每次调用都会保留之前的值
修饰全局变量/函数：将他的作用范围限制在定义它的文件内，不能被其他文件访问
修饰成员变量/函数：表示该变量/函数属于这个类而不是某个具体的对象，所有该类的对象共享这个变量/函数。静态成员变量在类外初始化，静态成员函数只能访问静态成员变量

内存分区：
代码区：程序的机器指令
数据区（全局区）：字符串常量、全局常量、全局变量、静态变量，包括data段（已初始化）和bss段（未初始化）
堆区：手动申请和释放的空间，使用malloc/free/new/delete来手动管理的区域
栈区：编译器自动分配和释放的空间，存储一些局部变量、函数参数、返回地址等等

malloc/free：C的标准库，分配指定大小字节数，返回指向该块的指针。只分配和释放内存，不会调用构造或析构
new/delete：C++的运算符，为某个对象分配内存，返回该对象的指针，会调用构造和析构函数

内存泄漏：动态分配的堆内存在使用完毕后没有得到适当的回收和释放，最主要的原因就是malloc之后没有free，new之后没有delete
避免：使用智能指针、内存检测工具、记录日志等等

智能指针：用于管理动态分配的内存
unique：独占指针，无法复制，只能移动；同一时间只有一个独占指针拥有对象的所有权，超出作用域时自动释放内存
shared：共享指针，内部使用引用计数，当最后一个共享指针被销毁时，指向的那块内存才被回收
weak：弱指针，用来解决共享指针可能导致的循环引用问题，弱指针不会增加共享指针的引用计数，可以在不影响指向对象的情况下安全的观察对象，但也不能直接访问，只用使用lock方法获取对应的共享指针后才能访问

i++ ++i的性能差异：一般来说++i更高效，因为不需要生成一个临时值来保存自增前的值

左值引用：常规引用，用于引用一个可以被修改的对象
右值引用：在移动构造时，引用一个临时对象，主要用于移动语义，避免不必要的复制

静态多态：编译时的多态，通过函数重载或运算符重载，在编译时就确定具体调用的函数或运算运算符
动态多态：运行时多态，主要通过继承和虚函数实现，子类重写基类中的虚函数后，使用基类指针或引用来调用虚函数时，会在运行时确定调用的函数

C++ 虚函数
编译器为每一个含有虚函数的类生成一个虚函数表，其中存储该类的虚函数的地址。每个对象会包含一个指向该类的虚函数表的指针，对象初始化时，构造函数会初始化这个vptr，使其指向所属类的虚函数表

C++ 常见stl及其底层
vector:动态数组，内部有一个指向数据的指针，当容量不足时，会为指针分配一个更大的数组，并将旧数据拷贝到新数组中
stack:内部由deque或vector实现，
queue：
map：有序的KV对，由红黑树实现，增删改查都是logn级别
unordered_map：无序KV对，由哈希表实现，平均是O1级别，但出现哈希冲突时，最坏可能达到On

C++ 多线程 python多线程

空类大小：1字节，类的大小通常是所有非静态成员变量的大小之和
带虚函数的类大小：4字节，存储指向虚函数表的指针
/结构体 const类大小

常见排序算法

C++11 新特性
自动类型推断：auto
智能指针：
移动语义和右值引用：
lambda表达式：
标准线程库：
nullptr
静态断言：