

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/logo.png">
  <link rel="icon" href="/img/logo.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Zhang Yix">
  <meta name="keywords" content="">
  
    <meta name="description" content="投递情况 私企提前批 x OPPO 7.17——投简历  第一志愿——机器学习算法工程师——成都 第二志愿——模型压缩算法工程师——北京  8.2——笔试——放弃 8.3——测评 x 芯动科技 7.17——投简历  第一志愿——算法工程师——武汉 第二志愿——GPU软件开发工程师——武汉  7.29——笔试  填空题5题25分   流水线数据冲突三种情况：RAW、WAR和WAW   三种地址映像方">
<meta property="og:type" content="website">
<meta property="og:title" content="page.title">
<meta property="og:url" content="http://example.com/papers/%E7%A7%8B%E6%8B%9B%E6%83%85%E5%86%B5-wsy.html">
<meta property="og:site_name" content="Zhyx&#39;s Blog">
<meta property="og:description" content="投递情况 私企提前批 x OPPO 7.17——投简历  第一志愿——机器学习算法工程师——成都 第二志愿——模型压缩算法工程师——北京  8.2——笔试——放弃 8.3——测评 x 芯动科技 7.17——投简历  第一志愿——算法工程师——武汉 第二志愿——GPU软件开发工程师——武汉  7.29——笔试  填空题5题25分   流水线数据冲突三种情况：RAW、WAR和WAW   三种地址映像方">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://pic1.zhimg.com/80/v2-87d919fbb9fd98973d2b885ab0d407a0_1440w.webp">
<meta property="og:image" content="http://qiniu.ben286.fun/QQ1.png">
<meta property="og:image" content="http://qiniu.ben286.fun/QQ2.png">
<meta property="article:published_time" content="2024-08-28T03:22:45.718Z">
<meta property="article:modified_time" content="2024-08-28T03:22:45.718Z">
<meta property="article:author" content="Zhang Yix">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://pic1.zhimg.com/80/v2-87d919fbb9fd98973d2b885ab0d407a0_1440w.webp">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>page.title - Zhyx&#39;s Blog</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />





<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.5","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4","collapseDepth":1},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 60vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Zhyx&#39;s Blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/bg0.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="page.title"></span>
          
        </div>

        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      <div class="container nopadding-x-md">
        <div id="board"
          >
          
          <div class="container">
            <div class="row">
              <div class="col-12 col-md-10 m-auto">
                

<article class="page-content">
  <h2 id="投递情况">投递情况</h2>
<h3 id="私企提前批">私企提前批</h3>
<h4 id="x-OPPO">x OPPO</h4>
<p>7.17——投简历</p>
<ul>
<li>第一志愿——机器学习算法工程师——成都</li>
<li>第二志愿——模型压缩算法工程师——北京</li>
</ul>
<p>8.2——笔试——放弃</p>
<p>8.3——测评</p>
<h4 id="x-芯动科技">x 芯动科技</h4>
<p>7.17——投简历</p>
<ul>
<li>第一志愿——算法工程师——武汉</li>
<li>第二志愿——GPU软件开发工程师——武汉</li>
</ul>
<p>7.29——笔试</p>
<blockquote>
<p>填空题5题25分</p>
<ul>
<li>
<p>流水线数据冲突三种情况：RAW、WAR和WAW</p>
</li>
<li>
<p>三种地址映像方式：直接映像方式、全相连映像方式、组相连映像方式</p>
</li>
<li>
<p>单地址指令与双地址指令：字长16位，地址6位，双地址指令A条，问单地址指令多少条？</p>
<p>​	跟哈夫曼编码有关：<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_44840079/article/details/104964582">https://blog.csdn.net/qq_44840079/article/details/104964582</a></p>
</li>
<li>
<p>算时间复杂度</p>
</li>
<li>
<p>图中的关键路径</p>
</li>
</ul>
<p>单选5题25分</p>
<ul>
<li>冒泡排序</li>
<li>二叉树深度</li>
<li>递归次数</li>
<li>二维数组行主序与列主序（画矩阵，横着存还是竖着存，跟找threadIdx一个样子）</li>
</ul>
<p>问答15+15+25</p>
<ul>
<li>
<p>CPI：执行一条指令所需要的时钟周期数 = 总时钟周期数/IC</p>
<p>CPU执行时间：运行一个程序所花费的时间 = CPU时钟周期数/主频 = (指令条数*CPI)/主频</p>
<p>MIPS：每秒执行多少百万条指令 = 指令条数/(执行时间x10^6) = 主频/CPI</p>
</li>
<li>
<p>存储器有效存取时间、平均成本</p>
</li>
<li>
<p>编程：子数组和最大值（小红书笔试第三题简单版）</p>
<p>注：手写代码，无需跑通</p>
</li>
</ul>
</blockquote>
<p>8.11——感谢信</p>
<h4 id="联想">联想</h4>
<p>7.18——投简历——算法工程师——武汉</p>
<h4 id="x-虹软科技">x 虹软科技</h4>
<p>7.18——投简历——算法优化工程师(CUDA\GPU\DSP)——杭州</p>
<p>8.20——笔试</p>
<blockquote>
<p>选择题涉及的内容非常多，如图像处理算法、高数（求导、极限）、线代（奇异矩阵）、数值分析、操作系统等</p>
<p>两道算法题第一道为字符串：()表示0分，()1表示0+1分，(1)表示2*1=2分，求字符串分数。我的想法是将所有()符号全部换成0，需要乘的部分设一个因子表示倍数，最后遍历相加。只通过了33%，不知道哪里错了。</p>
<p>第二道为BBABABB中满足条件的最长字符串，只通过了45%。</p>
<p>数据结构论述题为构建哈夫曼树，这个当时忘记了！！！！！</p>
<p>还有一个四选一论述题，都跟图像处理、神经网络相关，我做的一个是如何判断三维空间中两个向量的最短距离（瞎写的）。</p>
</blockquote>
<p>笔试挂</p>
<h4 id="x-小红书">x 小红书</h4>
<p>7.20——投简历——高性能异构计算工程师——上海</p>
<p>7.23——笔试</p>
<blockquote>
<p>选择题20道，一题2分，涉及：</p>
<p>​	操作系统：PV同步信号量计算、时间片轮转算法计算平均周转时间</p>
<p>​	SQL语句：OVER、ORDER BY、SIZE IN、ALL、BETWEEN、HAVING</p>
<p>​	算法：KMP next数组计算、栈容量、循环队列、递归计算</p>
<p>​	Linux：地址空间栈段、文件系统（ext2、ext3、ext4、NTFS）</p>
<p>​	计算机网络：UDP连接已经关闭的状态、HTTP状态码</p>
<p>​	C++基础：构造函数、操作符重载、内联函数、引用、继承</p>
<p>算法题3道，一题20分：</p>
</blockquote>
<figure class="highlight excel"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs excel">小红希望你构造一个数组满足以下条件：<br><span class="hljs-number">1</span>. 数组共有<span class="hljs-built_in">n</span>个元素，且所有元素两两不相等。<br><span class="hljs-number">2</span>. 所有元素的最大公约数等于k。<br><span class="hljs-number">3</span>. 所有元素之和尽可能小。<br>请你输出数组元素之和的最小值。<br>输入：	两个正整数<span class="hljs-built_in">n</span>和k<br>       <span class="hljs-number">1</span>≤ <span class="hljs-built_in">n</span>,k ≤ <span class="hljs-number">10</span>^<span class="hljs-number">5</span><br>输出： 一个正整数，代表数组元素之和的最小值。<br> <span class="hljs-symbol">AC:</span><br> <span class="hljs-built_in">int</span> main() &#123;<br>     <span class="hljs-built_in">int</span> <span class="hljs-built_in">n</span>, k;<br><br>     scanf(<span class="hljs-string">&quot;%d%d&quot;</span>, &amp;<span class="hljs-built_in">n</span>, &amp;k);<br>     printf(<span class="hljs-string">&quot;%ld&quot;</span>, <span class="hljs-built_in">n</span> * (<span class="hljs-built_in">n</span>+<span class="hljs-number">1</span>) /<span class="hljs-number">2</span> * k);<br> &#125;<br></code></pre></td></tr></table></figure>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs css">小红书的推荐帖子列表为<span class="hljs-selector-attr">[0,n]</span>，其中所有的帖子初始状态为”普通“，现在运营同学把其中的一些帖子区间标记为了”精华“。<br>第一行输入两个正整数n,m,k，代表初始帖子列表长度，精华区间的数量，以及运营同学准备截取的长度。<br><br>接下来的m行，每行输入两个正整数<span class="hljs-selector-tag">li</span>,ri，代表第<span class="hljs-selector-tag">i</span>个区间。<br><span class="hljs-number">1</span> ≤ k ≤ n ≤ <span class="hljs-number">1000000000</span><br><span class="hljs-number">1</span> ≤ m ≤ <span class="hljs-number">100000</span><br><span class="hljs-number">0</span> ≤ <span class="hljs-selector-tag">li</span> &lt; ri ≤ n<br>保证任意两个区间是不重叠的。<br><br>一个正整数，代表最多的精华帖子数量。<br></code></pre></td></tr></table></figure>
<figure class="highlight excel"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs excel">小红拿到了一个数组，她希望进行最多一次操作：将一个元素修改为x。小红想知道，最终的连续子数组最大和最大是多少？<br><br>第一行输入一个正整数<span class="hljs-built_in">t</span>，代表询问次数。<br>对于每次询问，输入两行：<br>第一行输入两个正整数<span class="hljs-built_in">n</span>和x。代表数组的大小，以及小红可以修改成的元素。<br>第二行输入<span class="hljs-built_in">n</span>个正整数a_i，代表小红拿到的数组。<br><span class="hljs-number">1</span> ≤ <span class="hljs-built_in">t</span> ≤ <span class="hljs-number">100000</span><br><span class="hljs-number">1</span> ≤ <span class="hljs-built_in">n</span> ≤ <span class="hljs-number">200000</span><br>-<span class="hljs-number">10</span>^<span class="hljs-number">9</span> ≤ x ,a_i ≤ <span class="hljs-number">10</span>^<span class="hljs-number">9</span><br>每组所有询问的<span class="hljs-built_in">n</span>的和不超过<span class="hljs-number">200000</span>。<br><br>输出<span class="hljs-built_in">t</span>行，每行输出一个整数，代表连续子数组的最大和。<br></code></pre></td></tr></table></figure>
<p>没结果，何东澳说他挂了，那我应该也挂了</p>
<h4 id="x-地平线">x 地平线</h4>
<p>7.20——投简历——AI加速算法工程师——南京</p>
<p>开始走正式批流程，提前批应该结束了</p>
<h4 id="√-x滴滴">√ x滴滴</h4>
<p>7.29——投简历——高性能计算研发工程师-TIG——杭州</p>
<p>8.16——一面</p>
<blockquote>
<p>问的大部分都是CUDA基础问题，比如编程模型、内存模型，cudaMalloc、怎么隐藏数据传输时间、CUDA Stream（其实面试官想问的是CPU上的流水线：取指、译码、执行、访存、写回，分支预测，乱序执行等）、CUDA统一内存模型等等，还问了一点C语言上的问题，比如int*指针占几个字节、CPP文件与CUDA是怎么编译等等</p>
<blockquote>
<p>完成一个C/C++程序后，想要运行起来，必须要经过四个步骤：预处理、编译、汇编和链接。</p>
<p><img src="https://pic1.zhimg.com/80/v2-87d919fbb9fd98973d2b885ab0d407a0_1440w.webp" srcset="/img/loading.gif" lazyload alt="c++编译过程"></p>
<p>预编译把一些<code>#define</code>的宏定义完成文本替换，然后将<code>#include</code>的文件里的内容复制到<code>.cpp</code>文件里，如果<code>.h</code>文件里还有<code>.h</code>文件，就递归展开。预处理之后的程序格式为 <code>*.i</code>，仍是文本文件，可以用任意文本编辑器打开。</p>
<p>编译只是把我们写的代码转为汇编代码，它的工作是检查词法和语法规则，所以，如果程序没有词法或则语法错误，那么不管逻辑是怎样错误的，都不会报错。**编译不是指程序从源文件到二进制程序的全部过程，而是指将经过预处理之后的程序转换成特定汇编代码(assembly code)的过程。**编译完成后，会生成程序的汇编代码<code>main.s</code>，这也是文本文件，可以直接用任意文本编辑器查看。</p>
<p>汇编过程将上一步的汇编代码(<code>main.s</code>)转换成机器码(machine code)，这一步产生的文件叫做目标文件(<code>main.o</code>)，是二进制格式。汇编这一步需要为每一个源文件（本文示例代码中为<code>main.cpp</code>、<code>func.cpp</code>）产生一个目标文件。因此<code>func.cpp</code>也需要执行一次这个汇编过程产生一个<code>func.o</code>文件</p>
<p>编译只是将我们自己写的代码变成了二进制形式，它还需要和系统组件（比如标准库、动态链接库等）结合起来，这些组件都是程序运行所必须的。链接（Link）其实就是一个“打包”的过程，它将所有二进制形式的目标文件(.o)和系统组件组合，还需要将编译器生成的多个<code>.o</code>或者<code>.obj</code>文件组合起来，生成最终的可执行文件(Executable file)。</p>
</blockquote>
<blockquote>
<p>CUDA代码编译过程：</p>
<ul>
<li>将.cu文件分解成host code和device code。</li>
<li>将device code通过CICC compiler编译成PTX code</li>
<li>PTX离线编译：将PTX文件通过 ptxas.exe 编译成某一具体架构的cubin文件</li>
<li>PTX在线编译：将cubin文件与PTX文件通过 fatbin.exe 编译到 .c 文件 。</li>
<li>调用gcc/g++将host代码与device代码编译成 .o 目标文件</li>
<li>链接成可执行文件</li>
</ul>
</blockquote>
<p>手撕代码为力扣300题最长递增子序列</p>
</blockquote>
<p>8.16——二面（连续面）</p>
<blockquote>
<p>二面基本上没问其他问题，全对着简历在问，详细询问了内核融合是什么意思、怎么实现、有什么亮点等等，我准备过的资料基本上全部问到了，模型压缩那篇论文也问到了。</p>
<p>手撕题是面试官随口出的，给一串数组，随机抽出两个数字后打乱，问如何在O(n)时间复杂度、O(1)空间复杂度的条件下找出这两个数。面试官给的提示是列出两个等式求解，首先求抽取前后数组和的差值，即为a+b，第二个等式我想了半天想不到（乘法超过表示范围了），最后回答的是求log，不知道面试官评价如何。</p>
<p>反问他们的技术栈，他们底层也支持多种硬件，主要还是NVIDIA，此外也包括一些DSP等等别的硬件，主要工作还是写CUDA kernel，还比较匹配。</p>
</blockquote>
<p>8.21——三面</p>
<blockquote>
<p>三面也基本上是对着简历在问，不怎么难，手撕题为cuda写reduce</p>
<p>值得记录的问题：</p>
<ul>
<li>为什么要剪枝，而不直接选小网络？？？</li>
<li>降低FLOPs能真正提高速度嘛？？？（学术界与工业界研究模型压缩的区别）</li>
</ul>
</blockquote>
<p>12.4——补录到我了，婉拒</p>
<h4 id="合合信息">合合信息</h4>
<p>7.29——投简历——提前批-图像算法研究员——上海</p>
<h4 id="x-大疆（卓驭科技）">x 大疆（卓驭科技）</h4>
<p>7.29——投简历——高性能计算开发工程师（卓驭科技-车载-深圳）——深圳</p>
<p>7.31——测评——放弃</p>
<h4 id="x-百度">x 百度</h4>
<p>8.15——投简历——AI训练框架研发工程师(J60006)——上海（吴锐内推）</p>
<p>8.23——一面（郭子滨）</p>
<blockquote>
<p>项目问的还行，CUDA这边问题不大，可以再看看锁页内存相关的东西，同时了解一下pytorch分布式训练相关的知识。</p>
<p>哦还有一个重要的问题：<strong>V100、A100、H100三代Tensor Core的区别？</strong></p>
<ul>
<li>第四代Tensor Core配备了全新的FP8引擎，张量处理性能高达1.32 PetaFlops（相对上代提升了五倍之多）</li>
</ul>
<p>C++基础答的不是太好，特别是new与malloc的区别，面试官对底层堆栈相关的知识问的很深</p>
<p>手撕写了一个判断链表环，不过面试官问我怎么寻找环入口节点时没想到，后来发现其实非常简单，固定一个指针把另一个从头开始遍历一下就完事。。。</p>
<p>口述了一下怎么在一个先增后减的数组内寻找某个值，可以先用二分找到顶点在哪，然后再对左右分别使用二分即可。</p>
</blockquote>
<p>8.28——二面（张孝慈）</p>
<blockquote>
<p>项目跟CUDA方面也问题不大，面试官说我简历上这些东西还搞得蛮好。</p>
<p>问了我一些操作系统与并行计算的东西，比如多线程同步的几种方式，他看出来了我并行这块了解的不多。</p>
<p>代码题因为我不会用如流，用浏览器面试的看不到题，最后只能在本地手写了一个c语言的字符串逆序，然后问我怎么不用临时变量来交换两个int的值，我就答了个位运算就结束了。</p>
<p>最后谈我的问题的时候，我跟他唠到了吴锐，聊了一下他们小组做的东西，他们说他们前期已经做了大量的适配，包括文心一言也是在他们上面做的，后面很长一段时间的重点工作是做多机并行，吴锐帮我查了下他就是并行方面的负责人。</p>
</blockquote>
<p>8.30——三面（陈庆澍 大leader）</p>
<blockquote>
<p>陈庆澍人挺好的，问的问题虽然不难但挺尖锐，比如：</p>
<ul>
<li>数据流这个项目我跟潘凡星是怎么分工的？</li>
<li>IPDPS这篇论文的创新点在哪？</li>
<li>介绍摩尔线程相关的工作，我做的贡献在什么地方？</li>
</ul>
<p>问了个操作系统虚表的问题，问了个毒药水智力问题，写了个数组中寻找众数的代码。</p>
<p>反问：</p>
<blockquote>
<p>您这边的主要工作我在跟前两位面试官聊过之后大致上也比较了解了，主要是在XPU上适配paddle，前期已经做了大量的适配，也包括文心一言这样的大模型，我对这方面还是挺有兴趣的。</p>
<p>上一位面试官后来也提到了，您这边后面很长一段时间重点是要解决多机并行的问题，这方面我以前只用过Pytorch DDP相关的API，对于底层实现确实不怎么了解，下来之后我专门在网上查了一下，这可能跟NCCL框架相关，因此我也是想借这个机会像您请教一下，多机并行这一块应该从哪里入手开始学习？</p>
<p>答：多机并行分为两部分，NCCL通信相关的部分以及框架上张量并行等分块方式，推荐直接看NCCL与Pytorch DDP源码。。。</p>
</blockquote>
</blockquote>
<p>8.30——面完直接被共享了，感觉面试的挺好啊，不知道为什么挂了，潘凡星还在流程中，我猜是hc太少了，庆澍想要她就没法要我了？</p>
<p>后续正式批又给我捞出来发笔试邀请，我联系了一个北京搜索架构部的想把简历转过去，一直没跟我推进，笔试懒得做了，放弃了。</p>
<h3 id="私企正式批">私企正式批</h3>
<h4 id="壁仞科技">壁仞科技</h4>
<p>7.5——投简历——AI 软件开发工程师——杭州</p>
<h4 id="x-燧原科技">x 燧原科技</h4>
<p>7.28——投简历——AI框架开发工程师——上海</p>
<p>8.9——笔试</p>
<blockquote>
<p>三道编程题</p>
<ul>
<li>求long二进制里面的1个数（难点在负数）</li>
<li>求linux地址（如何把./与…/去掉）</li>
<li>求下三角矩阵</li>
</ul>
</blockquote>
<p>8.18——笔试复试</p>
<blockquote>
<p>第一题，手写transpose矩阵，将N,C,H,W维度的矩阵转换为N,H,W,C</p>
<p>第二题，将三维彩色图像C,H,W进行裁剪，上下左右各裁剪若干行，输出裁剪后的像素</p>
<p>第三题，输出一个指定维度的矩阵（难点在如何处理[]与,符号上）</p>
<p>前两题通过找规律做出来了，第三题没做出来，后来发现好像可以使用递归来做。</p>
</blockquote>
<p>8.22——感谢信</p>
<h4 id="x-快手">x 快手</h4>
<p>8.9——投简历——机器学习平台研发工程师——北京</p>
<p>8.18——一面</p>
<blockquote>
<p>一上来就写题，实现LRU，并在此基础上实现模板化、单例模式及线程安全。（完全gg）</p>
<p>面试官人挺好，一直在不断提示我，后面看我实在写不出来，开始问简历去了，后面倒没什么问题，值得记录的几个问题：</p>
<ul>
<li>
<p>为什么Tensor Core比CUDA Core快？</p>
<p><strong>CUDA Core在每个时钟周期只能执行一次浮点混合乘加 FMA 计算，而Tensor Core可以在每个时钟周期执行64次 FMA 计算</strong></p>
</li>
<li>
<p>C++为什么比Python快？</p>
<p><strong>C++经过预处理、编译、汇编、链接后生成的应用程序包含的是二进制机器码，计算机可以直接执行，只需要第一次编译即可，而Python在运行过程中被解释器逐句转换为二进制机器码，相当于每次执行 Python 脚本，都要再进行一次转换为二进制的过程，因此在这一点上 Python 就已经慢了很多。</strong></p>
</li>
</ul>
<p>反问他们的技术栈，面试官回复他们做的是推广搜算法，这种算法模型的特点是非常稀疏，并不是直接用的传统CNN、Transformer这种。同时因为计算量太大，仅仅用分布式依然不够，所以有相当一部分工作其实是用CPU完成的，这也就是高性能计算岗位不仅仅要求CUDA与GPU知识，还对C++及CPU体系结构要求高的原因。</p>
</blockquote>
<p>流程结束</p>
<p>leetcode——146.LRU缓存</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">DLinkedNode</span> &#123;<br>    <span class="hljs-type">int</span> key, value;<br>    DLinkedNode* prev;<br>    DLinkedNode* next;<br>    <span class="hljs-built_in">DLinkedNode</span>(): <span class="hljs-built_in">key</span>(<span class="hljs-number">0</span>), <span class="hljs-built_in">value</span>(<span class="hljs-number">0</span>), <span class="hljs-built_in">prev</span>(<span class="hljs-literal">nullptr</span>), <span class="hljs-built_in">next</span>(<span class="hljs-literal">nullptr</span>) &#123;&#125;<br>    <span class="hljs-built_in">DLinkedNode</span>(<span class="hljs-type">int</span> _key, <span class="hljs-type">int</span> _value): <span class="hljs-built_in">key</span>(_key), <span class="hljs-built_in">value</span>(_value), <span class="hljs-built_in">prev</span>(<span class="hljs-literal">nullptr</span>), <span class="hljs-built_in">next</span>(<span class="hljs-literal">nullptr</span>) &#123;&#125;<br>&#125;;<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">LRUCache</span> &#123;<br><span class="hljs-keyword">private</span>:<br>    unordered_map&lt;<span class="hljs-type">int</span>, DLinkedNode*&gt; cache;<br>    DLinkedNode* head;<br>    DLinkedNode* tail;<br>    <span class="hljs-type">int</span> size;<br>    <span class="hljs-type">int</span> capacity;<br><br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-built_in">LRUCache</span>(<span class="hljs-type">int</span> _capacity): <span class="hljs-built_in">capacity</span>(_capacity), <span class="hljs-built_in">size</span>(<span class="hljs-number">0</span>) &#123;<br>        head = <span class="hljs-keyword">new</span> <span class="hljs-built_in">DLinkedNode</span>();<br>        tail = <span class="hljs-keyword">new</span> <span class="hljs-built_in">DLinkedNode</span>();<br>        head-&gt;next = tail;<br>        tail-&gt;prev = head;<br>    &#125;<br><br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">get</span><span class="hljs-params">(<span class="hljs-type">int</span> key)</span> </span>&#123;<br>        <span class="hljs-keyword">if</span> (!cache.<span class="hljs-built_in">count</span>(key)) &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;<br>        &#125;<br>        DLinkedNode* node = cache[key];<br>        <span class="hljs-built_in">moveToHead</span>(node);<br>        <span class="hljs-keyword">return</span> node-&gt;value;<br>    &#125;<br><br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">put</span><span class="hljs-params">(<span class="hljs-type">int</span> key, <span class="hljs-type">int</span> value)</span> </span>&#123;<br>        <span class="hljs-keyword">if</span> (cache.<span class="hljs-built_in">count</span>(key)) &#123;<br>            DLinkedNode* node = cache[key];<br>            node-&gt;value = value;<br>            <span class="hljs-built_in">moveToHead</span>(node);<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            DLinkedNode* node = <span class="hljs-keyword">new</span> <span class="hljs-built_in">DLinkedNode</span>(key, value);<br>            cache[key] = node;<br>            <span class="hljs-built_in">addToHead</span>(node);<br>            ++size;<br>            <span class="hljs-keyword">if</span> (size &gt; capacity) &#123;<br>                DLinkedNode* removed = <span class="hljs-built_in">removeTail</span>();<br>                cache.<span class="hljs-built_in">erase</span>(removed-&gt;key);<br><br>                <span class="hljs-keyword">delete</span> removed;<br>                --size;<br>            &#125;<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">moveToHead</span><span class="hljs-params">(DLinkedNode* node)</span> </span>&#123;<br>        <span class="hljs-built_in">removeNode</span>(node);<br>        <span class="hljs-built_in">addToHead</span>(node);<br>    &#125;<br><br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">removeNode</span><span class="hljs-params">(DLinkedNode* node)</span> </span>&#123;<br>        node-&gt;prev-&gt;next = node-&gt;next;<br>        node-&gt;next-&gt;prev = node-&gt;prev;<br>    &#125;<br><br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">addToHead</span><span class="hljs-params">(DLinkedNode* node)</span> </span>&#123;<br>        node-&gt;next = head-&gt;next;<br>        node-&gt;prev = head;<br>        head-&gt;next-&gt;prev = node;<br>        head-&gt;next = node;<br>    &#125;<br><br>    <span class="hljs-function">DLinkedNode* <span class="hljs-title">removeTail</span><span class="hljs-params">()</span> </span>&#123;<br>        DLinkedNode* node = tail-&gt;prev;<br>        <span class="hljs-built_in">removeNode</span>(node);<br>        <span class="hljs-keyword">return</span> node;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure>
<p>第二步，对LRU进行模板化，加上<code>template &lt;typename T1, typename T2&gt;</code>即可</p>
<p>第三步，加上线程安全的单例模式</p>
<blockquote>
<p>单例模式有两种实现方法：懒汉与饿汉。</p>
<ul>
<li>懒汉：故名思义，不到万不得已就不会去实例化类，也就是说在第一次用到类实例的时候才会去实例化，所以上边的经典方法被归为懒汉实现；</li>
<li>饿汉：饿了肯定要饥不择食。所以在单例类定义的时候就进行实例化。</li>
</ul>
<p>由于要进行线程同步，所以在访问量比较大，或者可能访问的线程比较多时，采用饿汉实现，可以实现更好的性能。这是以空间换时间。</p>
<p>在访问量较小时，采用懒汉实现。这是以时间换空间。</p>
<p><strong>简单的懒汉模式是线程不安全的，两种解决方法：加锁、内部静态变量</strong></p>
<p><strong>饿汉模式本来就是线程安全的</strong></p>
</blockquote>
<p>懒汉模式实现：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">LRUCache</span> &#123;<br><span class="hljs-keyword">private</span>:<br>    ...<br>    <span class="hljs-comment">// static LRUCache* instance;</span><br>    <span class="hljs-built_in">LRUCache</span>(<span class="hljs-type">int</span> _capacity): <span class="hljs-built_in">capacity</span>(_capacity), <span class="hljs-built_in">size</span>(<span class="hljs-number">0</span>) &#123;<br>        head = <span class="hljs-keyword">new</span> <span class="hljs-built_in">DLinkedNode</span>();<br>        tail = <span class="hljs-keyword">new</span> <span class="hljs-built_in">DLinkedNode</span>();<br>        head-&gt;next = tail;<br>        tail-&gt;prev = head;<br>    &#125;<br>    ~<span class="hljs-built_in">LRUCache</span>();<br>    <span class="hljs-built_in">LRUCache</span>(<span class="hljs-type">const</span> LRUCache&amp; tmp);<br>    LRUCache&amp; <span class="hljs-keyword">operator</span> = (<span class="hljs-type">const</span> LRUCache&amp; tmp);<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">static</span> LRUCache* <span class="hljs-title">initance</span><span class="hljs-params">()</span></span>;<br>    ...<br>&#125;;<br><br><span class="hljs-comment">// C++11 标准规定: static local 的变量会保证初始化一次，并且是多线程安全的</span><br><span class="hljs-function">LRUCache* <span class="hljs-title">LRUCache::initance</span><span class="hljs-params">()</span> </span>&#123;<br>    <span class="hljs-type">static</span> LRUCache* instance = <span class="hljs-keyword">new</span> <span class="hljs-built_in">LRUCache</span>(<span class="hljs-number">10</span>);<br>    <span class="hljs-keyword">return</span> &amp;instance;<br>&#125;<br></code></pre></td></tr></table></figure>
<p>恶汉模式实现：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">LRUCache</span> &#123;<br><span class="hljs-keyword">private</span>:<br>    ...<br>    <span class="hljs-type">static</span> LRUCache* instance;<br>    <span class="hljs-built_in">LRUCache</span>(<span class="hljs-type">int</span> _capacity): <span class="hljs-built_in">capacity</span>(_capacity), <span class="hljs-built_in">size</span>(<span class="hljs-number">0</span>) &#123;<br>        head = <span class="hljs-keyword">new</span> <span class="hljs-built_in">DLinkedNode</span>();<br>        tail = <span class="hljs-keyword">new</span> <span class="hljs-built_in">DLinkedNode</span>();<br>        head-&gt;next = tail;<br>        tail-&gt;prev = head;<br>    &#125;<br>    ~<span class="hljs-built_in">LRUCache</span>();<br>    <span class="hljs-built_in">LRUCache</span>(<span class="hljs-type">const</span> LRUCache&amp; tmp);<br>    LRUCache&amp; <span class="hljs-keyword">operator</span> = (<span class="hljs-type">const</span> LRUCache&amp; tmp);<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">static</span> LRUCache* <span class="hljs-title">initance</span><span class="hljs-params">()</span></span>;<br>    ...<br>&#125;;<br><br>LRUCache* LRUCache::instance = <span class="hljs-keyword">new</span> <span class="hljs-built_in">LRUCache</span>(<span class="hljs-number">10</span>);<br><span class="hljs-function">LRUCache* <span class="hljs-title">LRUCache::initance</span><span class="hljs-params">()</span> </span>&#123;<br>    <span class="hljs-keyword">return</span> instance;<br>&#125;<br></code></pre></td></tr></table></figure>
<p>补充，leetcode——460.LFU缓存</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">Node</span> &#123;<br>    <span class="hljs-type">int</span> cnt, time, key, value;<br><br>    <span class="hljs-built_in">Node</span>(<span class="hljs-type">int</span> _cnt, <span class="hljs-type">int</span> _time, <span class="hljs-type">int</span> _key, <span class="hljs-type">int</span> _value)<br>        :<span class="hljs-built_in">cnt</span>(_cnt), <span class="hljs-built_in">time</span>(_time), <span class="hljs-built_in">key</span>(_key), <span class="hljs-built_in">value</span>(_value)&#123;&#125;<br><br>    <span class="hljs-comment">// 我们需要实现一个 Node 类的比较函数</span><br>    <span class="hljs-comment">// 将 cnt（使用频率）作为第一关键字，time（最近一次使用的时间）作为第二关键字</span><br>    <span class="hljs-type">bool</span> <span class="hljs-keyword">operator</span> &lt; (<span class="hljs-type">const</span> Node&amp; tmp) <span class="hljs-type">const</span> &#123;<br>        <span class="hljs-keyword">return</span> cnt == tmp.cnt ? time &lt; tmp.time : cnt &lt; tmp.cnt;<br>    &#125;<br>&#125;;<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">LFUCache</span> &#123;<br><span class="hljs-keyword">private</span>:<br>    <span class="hljs-comment">// 缓存容量，时间戳</span><br>    <span class="hljs-type">int</span> capacity, time;<br>    unordered_map&lt;<span class="hljs-type">int</span>, Node&gt; map;<br>    set&lt;Node&gt; s;<br><br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-built_in">LFUCache</span>(<span class="hljs-type">int</span> _capacity): <span class="hljs-built_in">capacity</span>(_capacity), <span class="hljs-built_in">time</span>(<span class="hljs-number">0</span>) &#123;&#125;<br><br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">get</span><span class="hljs-params">(<span class="hljs-type">int</span> key)</span> </span>&#123;<br>        <span class="hljs-keyword">auto</span> it = map.<span class="hljs-built_in">find</span>(key);<br>        <span class="hljs-keyword">if</span> (it == map.<span class="hljs-built_in">end</span>()) &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;<br>        &#125;<br>        <span class="hljs-comment">// 从哈希表中得到旧的缓存</span><br>        Node node = it-&gt;second;<br>        <span class="hljs-comment">// 从平衡二叉树中删除旧的缓存</span><br>        s.<span class="hljs-built_in">erase</span>(node);<br>        <span class="hljs-comment">// 将旧缓存更新</span><br>        node.cnt += <span class="hljs-number">1</span>;<br>        node.time = ++time;<br>        <span class="hljs-comment">// 将新缓存重新放入哈希表和平衡二叉树中</span><br>        s.<span class="hljs-built_in">emplace</span>(node);<br>        it-&gt;second = node;<br>        <span class="hljs-keyword">return</span> node.value;<br>    &#125;<br><br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">put</span><span class="hljs-params">(<span class="hljs-type">int</span> key, <span class="hljs-type">int</span> value)</span> </span>&#123;<br>        <span class="hljs-keyword">auto</span> it = map.<span class="hljs-built_in">find</span>(key);<br>        <span class="hljs-keyword">if</span> (it == map.<span class="hljs-built_in">end</span>()) &#123;<br>            <span class="hljs-keyword">if</span> (map.<span class="hljs-built_in">size</span>() == capacity) &#123;<br>                <span class="hljs-comment">// 从哈希表和平衡二叉树中删除最近最少使用的缓存</span><br>                map.<span class="hljs-built_in">erase</span>(s.<span class="hljs-built_in">begin</span>()-&gt;key);<br>                s.<span class="hljs-built_in">erase</span>(s.<span class="hljs-built_in">begin</span>());<br>            &#125;<br>            <span class="hljs-comment">// 创建新的缓存</span><br>            Node node = <span class="hljs-built_in">Node</span>(<span class="hljs-number">1</span>, ++time, key, value);<br>            map.<span class="hljs-built_in">emplace</span>(key, node);<br>            s.<span class="hljs-built_in">emplace</span>(node);<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            Node node = it-&gt;second;<br>            s.<span class="hljs-built_in">erase</span>(node);<br>            node.cnt += <span class="hljs-number">1</span>;<br>            node.time = ++time;<br>            node.value = value;<br>            s.<span class="hljs-built_in">emplace</span>(node);<br>            it-&gt;second = node;<br>        &#125;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure>
<p>8.3——重新投简历——机器学习平台研发工程师——北京</p>
<h4 id="x-恒生电子">x 恒生电子</h4>
<p>8.14——投简历——C/C++开发工程师——武汉</p>
<p>9.22——笔试</p>
<blockquote>
<p>这题目太恶心了。。。</p>
<p>选择题全是跟c语言指针地址那些东西相关的，写的人头大，居然还有SQL编程题，这个我只记得最基本的了，两道编程题我直接放弃，要求用纯c写，一题太长了好像是跟牛顿下山这种数学分析公式相关，还有一题输入奇奇怪怪的，用纯c不知道怎么处理，懒得写了。</p>
</blockquote>
<p>9.24——测评</p>
<p>9.26——线下面试</p>
<blockquote>
<p>他们是做金融软件的，对技术要求不高，就是用c语言写一些业务逻辑，以及用一种比C#更老的语言写客户端，数据库方面使用oracle，基本上培训一个星期就能干活的那种，基本上没有使用算法的场景，面试官都说我们去他们那里是浪费，以前他们很少收到华科的简历，今年他说他今天面试24个人一半华科一半武大，还问我是不是就业环境太差了。。。</p>
<p>他们技术总部在杭州，阿里滨江园区旁边，两万人左右，武汉这边只有一个不到500人的小团队，也是写一点c业务的，说是未来几年会有自己的写字楼，但现在还是租房办公。</p>
<p>整体上来看是完全不匹配且不感兴趣，后续流程可以考虑不用走了。</p>
</blockquote>
<p>9.28——感谢信</p>
<h4 id="海康威视">海康威视</h4>
<p>8.14——投简历——高性能计算工程师——杭州</p>
<ul>
<li>第一志愿——研究院（部门）</li>
<li>第二志愿——机器人（部门）</li>
</ul>
<p>8.14——测评</p>
<p>8.22——笔试</p>
<blockquote>
<p>都是C++基础知识</p>
<ul>
<li>
<p>open-close原则：软件实体(类、模块、函数等)应该对扩展开放，但对修改关闭。这样的实体可以允许在不修改源代码的情况下对其行为进行扩展。</p>
<p>扩展：面向对象五大基本原则：</p>
<ul>
<li>单一职责原则（SRP: Single Resposibility Principle）：一个类只做好一件事情。</li>
<li>开放封闭原则（OCP: Open Closed Principle）：对扩展开放，对修改封闭。</li>
<li>里氏替换原则（LSP: Liskov Substituion Principle）：<strong>子类可以替换父类并出现在父类能够出现的任何地方。</strong></li>
<li>依赖倒置原则（DIP: Dependecy Inversion Principle）：依赖于抽象。具体而言就是高层模块不依赖于底层模块，二者都依赖于抽象；抽象不依赖于具体，具体依赖于抽象。</li>
<li>接口分离原则（ISP: Interface Segregation Principle）：使用多个小的专门的接口，而不要使用一个大的总接口</li>
</ul>
</li>
<li>
<p>结构体末尾char data[0]的作用：<strong>方便管理内存缓冲区、减少内存碎片化（柔性数组，本身不占用空间，使得结构体可变长）</strong>，没有标识结构体结束的作用</p>
</li>
<li>
<p><strong>在 C89 中，必须使用常量表达式指明数组长度；也就是说，数组长度中不能包含变量，不管该变量有没有初始化。而在 C99 中，可以使用变量指明数组长度。</strong></p>
</li>
<li>
<p><strong>volatile不保证线程安全，线程本地存储可以保证线程安全</strong></p>
</li>
<li>
<p>手动实现itoa函数</p>
</li>
</ul>
</blockquote>
<p>9.5——专业面试</p>
<blockquote>
<p>表现一般，c++八股没答好，unique_ptr为什么是唯一的，vector底层数据搬移的原理、erase的原理，多态的实现方式，重载与重写的区别（重载是一个类中的，重写实现在子类上）</p>
<p>项目亮点没有展现出来，问gemm有什么优化方式，我答的pipeline，他说这是并发手段，他想听技术上的，我只想到了共享内存bank冲突优化，这个还要再准备一下。</p>
<p>问我CNN有哪些基本层，问我pooling的原理，我忘了，可以回答数据降维、特征压缩、增大感受野等。</p>
<p>问我一个职场问题，领导让你干你不感兴趣的跟你的方向不沾边的工作，你应该怎么办？</p>
<p>他们那边做的工作主要是推理上的一些优化，边缘设备的部署等，训练优化不是他们组在做。</p>
</blockquote>
<p>9.19——综合面试</p>
<blockquote>
<p>有点综合专业面试与HR面试的意思，既问了我项目上的难点，前景，任务分配等技术上的问题，也问了我职业规划、读博、考公、工作地点等HR方面的问题，自我感觉答的还行，期望薪资报的总包40w，可能对海康来说报的有点高了</p>
</blockquote>
<p>11.5——根据HR反馈，目前就一个hc了，前面还有好几个博士泡着在，HR问我要不要换个岗，暂时先不管了。</p>
<h4 id="x-得物">x 得物</h4>
<p>8.15——投简历——算法工程师（工程方向）——上海</p>
<p>8.23——笔试</p>
<blockquote>
<p>好多Java题。。。</p>
<p>值得记录的问题：</p>
<ul>
<li>
<p>编译过程中,常见的中间语言形式有：逆波兰表示、四元式、三元式和树表示等。</p>
<ul>
<li>
<p>把运算符写在操作数之前，称为波兰表达式(Polish Expression)或前缀表达式(Prefix Expression)，如+AB；把运算符写在操作数之后，称为逆波兰表达式(Reverse Polish Expression)或后缀表达式(Suffix Expression)，如AB+</p>
</li>
<li>
<p>假设有一个中缀表达式a+b*c-(d+e)</p>
<p>首先将这个中缀表达式的所有运算加括号((a+(b*c))-(d+e))</p>
<p>然后将所有运算符放到括号后面，这样就变成了((a(bc)* )+ (de)+ )-</p>
<p>把所有括号去掉abc*+de±，最后得出的结果就是后缀表达式。</p>
</li>
</ul>
</li>
<li>
<p><strong>一致性哈希：就是普通取模哈希算法的改良版，哈希函数计算方法不变，只不过是通过构建环状的 Hash 空间代替普通的线性 Hash 空间，它可以保证当机器增加或者减少时，节点之间的数据迁移只限于两个节点之间，不会造成全局的网络问题。</strong></p>
</li>
<li>
<p>进程的特征：动态性、并发性、独立性、异步性。</p>
</li>
<li>
<p>梯度下降能否用于线性回归与逻辑回归？</p>
</li>
<li>
<p><strong>LDA</strong>、FA、LLE、PCA哪个是监督学习算法</p>
</li>
<li>
<p>算法题为一个0-1背包问题与图中最大生成树算法，前者我还得多刷几道，现在对哪个是外循环哪个是内循环、正序还是倒序仍不清楚，后者我构建struct后排序，再按分数最大值加入，通过了82%</p>
</li>
</ul>
</blockquote>
<p>9.9——一面</p>
<blockquote>
<p>就不该投这种小公司，感觉想招全栈的，啥都问，问c++问cuda，问操作系统问计算机网络，问java问数据库问spring，每个都问的不深，但又不能很好地展现我在cuda方面的优势，感觉面试官在没话找话，还兼任了hr的工作问我为什么考研，感觉一团混乱。</p>
<p>我问了他为什么要问java，他说他们也做后端，感觉意思是工程团队都没多少人，把整个公司能做的底层支持工作都做了。</p>
</blockquote>
<p>9.12——测评</p>
<p>9.16——二面</p>
<blockquote>
<p>20分钟结束，还写了个题。。。</p>
<p>面试官对项目问的不是特别多，但对之江的经历特别感兴趣，详细了解了我与国产GPU公司的沟通过程，他认为这段实习是我比较大的一个亮点</p>
<p>写了个简单的二维数组寻找元素的题，我用暴力解决，正在想进一步优化面试官直接过了</p>
<p>问了他这边的工作，他们c++部分主要分为两块——搜索引擎与机器学习平台，搜索引擎就是ES那套，但是c++版的，机器学习平台以前他们使用阿里云的Paas平台，现在在追求自建，可能刚启动没有多久，各方面缺口都挺大。机器学习平台分为两块，一块是做阿里那套电商预估，一块是做百度那套社区体系，这是得物的特点——电商+社区。不过他们平台这边对传统深度学习算法需求更大一些，对CUDA需求小一些，可能还没到需要考虑性能的程度。</p>
</blockquote>
<p>10.14——三面</p>
<blockquote>
<p>为什么三面还是技术面啊？？？</p>
<p>这个面试官一看就是大负责人，问的问题都比较顶，一上来就问分布式计算框架，我都答不上来，然后问CPU、GPU交互的瓶颈，我答数据传输他问我为什么慢，我只能跟他扯了点带宽、PCIe、NVLink相关的东西，我也不咋懂；项目倒没怎么问，老样子问了点困难的问题就完事了，还问了我如何实现操作系统中的空闲链表使得内存利用率尽可能高，我刚开始都不知道这是啥，后来听明白了就是个内存碎片管理，最右那笔试做过，顺着他的思路答了链表与哈希索引，然后让我写题，写了个打家劫舍，不过是带循环的那种，我没把循环的写出来，通过了一半。</p>
<p>他是搜广推部门的，跟上一位面试官不是一个部门，他说隔壁才是做机器学习平台的，听口气我怀疑是交叉加面，感觉可能过不了。</p>
</blockquote>
<p>10.18——感谢信</p>
<h4 id="x-字节">x 字节</h4>
<p>8.19——投简历——机器学习系统研发工程师-Data AML——北京</p>
<p>8.29——一面</p>
<blockquote>
<p>全程在问CUDA的知识，问的很深，下次别提持久线程块了，这玩意属于是科研亮点而不是技术亮点，面试官不在意的。另外有些细节忘了比如GPU的最小内存访问单位：</p>
<ul>
<li>CUDA在Global Memory上访问粒度是32B，而每32B组成一个sector，一个cacheline则对应4个sector，总共大小为128B。</li>
</ul>
<p>而CUDA执行指令的单位是线程束，当发生一次访存的时候，其实是该线程束的所有线程执行访存操作。每个线程访存粒度可以是1B,2B,4B,8B,16B。</p>
<p>手撕了两题：</p>
<ul>
<li>用C++实现COO与CSR格式，写COO转CSR的转换代码，再写CSR的矩阵乘法</li>
<li>用CUDA实现前缀和</li>
</ul>
<p>这个面试官是字节中台里面专门负责训练优化部分的，应该算是完全对口了，他们也适配别的硬件不过没说是什么。</p>
</blockquote>
<p>8.31——感谢信</p>
<h4 id="阿里达摩院">阿里达摩院</h4>
<p>8.24——投简历——通义千问团队内推——杭州</p>
<p>9.8——一面（梦可）</p>
<blockquote>
<p>他们是通义千问——融合计算团队的，做图计算、图神经网络方面的加速，也做非nv卡的工作，与我的方向应该算是最匹配的了，面试官还了解GNNAdvisor。</p>
<p>八股倒没怎么问，但是对CUDA这边问的特别细，对GNN怎么极化、怎么解决负载均衡问题也问了很多，也问了多机并行、RDMA等别的问题，我反正在能力范围内已经回答的最好了。</p>
<p>另外问了三个优化问题，规约怎么优化、前缀和怎么优化、矩阵转置怎么优化，我都是简单口述了一下。</p>
<p>手撕负载均衡问题，第一步问集合中n个元素，划分为m个子集，怎么划分使得子集内数据总和的最大值最小，这是个np难的问题，没有精确解，我就用贪心实现了，也就是从最大的开始一个一个往最小的子集里面添加。</p>
<p>第二步问数组中n个元素，划分为m个子集，怎么划分使得子集内数据总和的最大值最小，这个是有精确解的，我实在动不了笔，面试官很耐心一步一步提示我二维DP，但是没办法直到最后我都没想出来，如果这一面没通过最大的原因应该就是这里。</p>
</blockquote>
<h4 id="x-黑芝麻">x 黑芝麻</h4>
<p>8.31——投简历——算法优化工程师——武汉</p>
<p>笔试不限时间，拖到后面懒得做了</p>
<h4 id="x-华为">x 华为</h4>
<p>8.31——投简历——计算产品线（昇腾）——杭州</p>
<p>9.20——笔试</p>
<blockquote>
<p>第一题还挺简单，a了，100分</p>
<p>第二题问怎么传接力棒路径最短的问题，感觉就是个图DFS问题，但是搞了一个小时都没搞出来，反正输出-1也能得25%*200=50分</p>
<p>第三题是手动实现编程语言中的let、out关键字，但是我忘记c++怎么读取带空格的一行了，解决了几个简单的特殊情况，得了15%*300=45分</p>
<p>华为是固定150分通过，可以进入下一轮了</p>
</blockquote>
<p>9.24——测评</p>
<p>10.19——一面</p>
<blockquote>
<p>问的都是基础，这都还好，手撕共享屏幕写力扣第6题——Z字型变换，g了</p>
</blockquote>
<p>10.19——流程结束</p>
<h4 id="x-美团">x 美团</h4>
<p>8.31——投简历——机器学习引擎工程师——北京</p>
<p>9.2——笔试</p>
<p>第四题：</p>
<p><img src="http://qiniu.ben286.fun/QQ1.png" srcset="/img/loading.gif" lazyload alt="QQ1"></p>
<p>第五题：</p>
<p><img src="http://qiniu.ben286.fun/QQ2.png" srcset="/img/loading.gif" lazyload alt="QQ2"></p>
<p>9.8——一面</p>
<blockquote>
<p>这个面试官比较感兴趣国产GPU相关的事情，后面提问的时候得知美团也受到了nv卡禁售的影响，因此也正在往国产GPU这边发展，比较详细咨询了各个公司产品的区别以及我们选用的原因</p>
<p>对简历的问答还是稳定发挥，不过面试官往Transformer上有所发挥，问我Transformer剪枝有哪几种方式；另外把进化算法的具体类型要看看，面试官问我具体使用的哪种进化算法我答不出来（好像就是最基础的遗传算法）</p>
<p>面试官还对图计算系统比较感兴趣，这方面还得多准备一下，关于图计算系统的性能应用等</p>
<p>手撕了一个寻找平衡二叉树，用递归写出来了，但是只通过了一半的测试用例，面试官没在意，直接过了</p>
<p>美团也在做大模型，不过不是通用的那种，是垂直业务领域的大模型，还没开源，他们部门这几年工作主要是在支持大模型，另外就是传统的在TensorFlow的基础上进行定制优化，针对推广搜等业务（他问了我了不了解Pytorch这种框架的底层实现，这方面有时间的话可以准备一下）</p>
<p>整体上面试还挺顺畅，自我感觉面试官挺满意的，唯一的问题就是他现场看了我的笔试成绩，知道我笔试做的挺糟糕，不知道有没有降低面评。</p>
</blockquote>
<p>9.13——二面</p>
<blockquote>
<p>这个面试官是做图引擎的，对图神经网络太熟了，全程问我项目细节以及跟图相关的东西，一点其他的都不关心，手撕也没有，问的太详细了。。。</p>
<p>首先特别关心了我们实验室跟图相关的团队以及成果，问我们的图计算系统现在做到什么程度了，然后针对VLDB这篇论文，详细了解了具体流程，包括如何实现极化，如何进行的资源分配，Tensor Core与CUDA Core具体是怎么进行数据划分的，我们的baseline是什么，跟DGL比有什么优缺点，DGL是怎么实现的，用到了什么数据集，起到了什么效果等等，问的非常细，非常尖锐，甚至想看我们的源码以及论文，太狠了。。。</p>
<p>然后问我研究生阶段的学习路线，看了多少论文，精读了多少论文，挑几篇讲讲，问我课业余时间有没有学习相关的技术，具体学了什么。。。很多问题感觉他只是不想纠缠我了而已，并不是满意了，没办法，遇到这种太专业的面试官，我们这种基础就跟白纸一样。。。</p>
<p>没有手撕，那只能看他对我的科研评价了，感觉g。</p>
</blockquote>
<p>9.19——感谢信</p>
<h4 id="x-阿里巴巴控股集团">x 阿里巴巴控股集团</h4>
<p>8.31——投简历——研发工程师C/C++（机器学习系统）——杭州</p>
<p>9.9——笔试</p>
<blockquote>
<p>第一题a了，二三题全g。。。</p>
<p>第三题问有多少个子序列中只有一个元素有2个，刚开始用动归尝试花了很长时间，后来发现就是个排列组合题目，把所有元素的数量统计出来，然后遍历应该没想象中这么难。</p>
<p>关键是第二题，a~ai~=n-i+1，求数组。至今没思路，网上都说跟4的倍数有关，我甚至都看不懂。。。</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.nowcoder.com/feed/main/detail/9783274b10b44db997e63e2e9e9636af?sourceSSR=search">https://www.nowcoder.com/feed/main/detail/9783274b10b44db997e63e2e9e9636af?sourceSSR=search</a></li>
<li><a target="_blank" rel="noopener" href="https://www.nowcoder.com/feed/main/detail/c40fe24082af415398f8a40214a3c148?sourceSSR=search">https://www.nowcoder.com/feed/main/detail/c40fe24082af415398f8a40214a3c148?sourceSSR=search</a></li>
</ul>
</blockquote>
<p>9.12——测评</p>
<p>9.21查看流程——第一志愿面试结束？？？第二志愿简历未过评估，现处于第三志愿——阿里集团-控股集团-橙盾科技-算法工程师-算法工程——简历评估阶段</p>
<p>9.28——橙盾科技简历评估通过，一面</p>
<blockquote>
<p>面试官就对着简历问了问，没手撕，半个小时就结束了，不知道是赶着放假还是KPI面</p>
<p>我发现这些面试官都对GNN极化部分的预处理过程感兴趣，对内核融合反而简单问了问就完事，这方面我倒没什么太多可以回答的；另外就是陈雨浩那篇论文，梯度下降迭代更新概率值的时候，如何确定loss的，怎么解决不收敛的问题，我对这个没什么印象了。。。</p>
<p>他们也做大模型，感觉他们口里的大模型就是个基础工具，每个团队都在做，中台优化也是自己在做，跟通义那边没什么交集，但也是在西溪总部上班。</p>
</blockquote>
<p>9.28——我总结都没写完就挂了。。。果然KPI</p>
<h4 id="网易互娱">网易互娱</h4>
<p>8.31——投简历——AI研究工程师——杭州</p>
<h4 id="京东">京东</h4>
<p>8.31——投简历——算法工程师-机器学习——北京</p>
<p>9.8——测评</p>
<blockquote>
<p>标准的行测+性格测试四部分，行测还是答的不好，看见大段的文字就很头疼</p>
</blockquote>
<p>9.16——笔试放弃</p>
<p>9.23——笔试放弃</p>
<p>9.28——笔试</p>
<blockquote>
<p>由于投的是算法岗，对机器学习基础要求就挺高了，线代以及过拟合那些东西有点忘了，选择题写的不是太好</p>
<p>三道算法题，a了两题，第三题是个数学问题，就是求圆的半径，公式我列出来了，但解出来的结果只能通过20%，怀疑是sqrt开方步骤的精度问题，要求误差在10-6内，不知道怎么进一步提高精度</p>
</blockquote>
<h4 id="Momenta">Momenta</h4>
<p>8.31——投简历——机器学习系统工程师（训练优化/模型量化）——上海、深圳、北京</p>
<h4 id="芯动科技">芯动科技</h4>
<p>8.31——投简历——GPU软件开发工程师——武汉</p>
<h4 id="x-图森未来">x 图森未来</h4>
<p>9.4——投简历——算法优化部署工程师——上海</p>
<p>10.8——投简历——研发工程师-算法平台——上海</p>
<h4 id="海格通信">海格通信</h4>
<p>9.4——投简历——算法设计师——武汉</p>
<h4 id="x-地平线-2">x 地平线</h4>
<p>9.5——投简历——深度学习算法框架工程师——北京</p>
<p>9.23——笔试</p>
<blockquote>
<p>没有注意到笔试总共就1个小时，吃饭耽误了20分钟，极限操作40分钟完成试卷，还好题量不大，选择填空都挺简单，有两个填空一个太长一个雅可比行列式不会直接放弃了。编程是一个字符串压缩一个盛水最多的容器，直接是力扣模式，分分钟搞定了，不过字符串压缩的题当数字大于10时int转string好像写的有点小问题，只有2分钟检查没想到问题原因，通过了90%，问题应该不大。</p>
</blockquote>
<p>11.1——一面</p>
<blockquote>
<p>感觉聊的还行，面试官主要在问cuda跟模型训练相关的问题，另外就是聊了很久的数据预取跟流水线的东西，手撕了一个用cuda实现softmax，其实本质上也就是个reduce，但是对softmax的一些优化手段比较如何解决数据溢出等问题我还是没答上来。</p>
<p>他这边模型训练推理也都做，在云上做训练优化之后部署到他们自己的智能车载芯片BPU上，也做过一些国产化的卡，反正也是一个跟我完全对口的岗位，主要是面试太迟了，现在估计是补招阶段，不知道能不能走到最后的流程。</p>
</blockquote>
<p>11.6——感谢信，应该是KPI面了</p>
<h4 id="深信服">深信服</h4>
<p>9.5——投简历——机器学习工程师——深圳</p>
<p>9.6——笔试</p>
<blockquote>
<p>选择题考了很多概率论的知识，有点忘记了</p>
<p>填空题：</p>
<ul>
<li>给14个数组成一个乘式，求乘积最大的组合；</li>
<li>数组a[1…5]，a[i]表示i出现的次数，给出一种组合</li>
</ul>
<p>编程题：</p>
<ul>
<li>给一个NxN的矩阵，问里面是否存在一个MxM的矩阵</li>
<li>把一个数字所有值打乱重组，求原数字大小在重组后所有数字里面排第几</li>
<li>第三题跟深信服实际应用相关，太长了懒得看</li>
</ul>
</blockquote>
<h4 id="√-x-长江存储">√  x 长江存储</h4>
<p>9.5——投简历——数据科学工程师(J12979)——武汉</p>
<p>9.12——测评</p>
<p>9.18——线下初试</p>
<blockquote>
<p>聊了大概20分钟，因为岗位不是特别匹配，他也看不懂我做的是什么，简历上的东西倒没怎么聊，我在自我介绍的时候也提前说明了，主要还是围绕他们现在正在做的工作展开的。因为我不懂芯片工艺的专有名词，他说话也有点口音，我只能大概回忆一下：数据科学工程师这个岗位主要分为四个方向，一是做芯片良率预测，这是在工艺流程中的；二是做工厂设备调度，因为他们都是无人工厂，对设备智能化要求较高；三是做工艺全流程的大平台管理，因为有一千多道工艺，所以需要一个大数据平台来管理；四是设备监控，及时处理各种故障。我最感兴趣的应该是第三个方向。</p>
<p>他们整个团队大概七八十人左右，今年的数据科学岗位hc大概20个。整体上聊的还行，薪资待遇他说在武汉这边制造业算是中上了，我倒是没有特别的兴趣，主要是长存位置太偏了，看后面HR聊的怎么样吧。</p>
</blockquote>
<p>9.21——线下复试</p>
<blockquote>
<p>这次应该是智能制造部门的一个负责人面试的我，我这次倒没有说什么匹不匹配的事，直接按标准自我介绍说了，他还真就顺着我的简历开始问，不过因为他也不懂具体的技术细节，更多的还是问我数据流整个项目的事情，以及包括FAST在内的一些应用情况（从来没人问过FAST，数据我都有点忘了，现场编的）。</p>
<p>这次的意外收获是发现长存居然还有适合我的岗位，他说整个智能制造部不止上次说的四个方向，从生产、设备、工艺、质量、设计等等各方面他们部门都涉及，与ai相关的地方是使用cv手段对产品进行拍照识别，一方面是精度问题，另一方面是随着数据量增长，模型跑的越来越慢的情况，这就需要我这块模型优化加速方面的工作，据称他们还做大模型来着（我都懒得问他们有没有数据中心了。。。）。不过谈到我进去之后要做什么工作的时候，他也是说看需求，人尽其用，模型优化肯定不会招专人去做，肯定还要涉及其他各方面的杂活来着。</p>
<p>应该能过吧，去不去到时候看待遇了。</p>
</blockquote>
<p>9.24——测评</p>
<p>10.24——oc</p>
<blockquote>
<p>基本工资15.5*12，目标年终奖2.4个月（跟绩效有关），新人奖2年每年2次，每次1个月工资，总计25.4</p>
<p>六险一金（包含商业险），公积金8%，每个月餐补330</p>
<p>提供住房，四人间到双人间 60-240 不等，单人间500-1000，要申请，不住宿舍有班车</p>
<p>加班以15.5基数，工作日1.5倍，周末2倍，节假日3倍（法定标准）</p>
<p>每年4月左右调一次薪</p>
<p>体育馆、食堂、健身房。。。</p>
<p>明天早上10点前答复，违约金一个月工资</p>
</blockquote>
<p>10.25——拒offer</p>
<h4 id="腾讯">腾讯</h4>
<p>9.5——投简历——技术研究-机器学习方向——深圳</p>
<p>9.7——测评</p>
<blockquote>
<p>第一部分第二部分全是列举的职场中真实发生的例子，第一部分主要问某种情况下某人说什么话是为什么这种分析题，第二部分主要问某种情况下我应该如何去做；第三部分是标准行测，但是难度大时间紧。</p>
</blockquote>
<p>9.10——笔试</p>
<blockquote>
<p>腾讯把整个秋招唯一一场的笔试放在牛客上考也是心大，服务器直接崩溃，直到最后都没有提交成功</p>
<p>题目：</p>
<ul>
<li>
<p><a target="_blank" rel="noopener" href="https://www.nowcoder.com/discuss/530510566088081408?anchorPoint=comment">https://www.nowcoder.com/discuss/530510566088081408?anchorPoint=comment</a></p>
</li>
<li>
<p><a target="_blank" rel="noopener" href="https://www.nowcoder.com/discuss/530516419809738752?anchorPoint=comment">https://www.nowcoder.com/discuss/530516419809738752?anchorPoint=comment</a></p>
<p>前面几题没什么好说的，第二题根本就没读懂题意。第五题有研究的必要，我忘记最长公共子串怎么求了，我的思路是先把各个字符串之间是否共生的二维bool数组求出来，然后用DFS做遍历，类似于孤岛问题，每删除一个元素就遍历一次。</p>
<p>网上的做法是反过来做，把删除变成添加，每添加一个节点用dp判断最长子串是不是超过k，然后dfs/并查集算连通块数量</p>
</li>
</ul>
</blockquote>
<p>9.15——笔试重考 52/100</p>
<h4 id="x-阿里淘天集团">x 阿里淘天集团</h4>
<p>9.12——投简历——基础平台研发工程师（阿里妈妈）——北京</p>
<p>9.21查看流程——一志愿简历未过评估，二志愿待筛选——淘天集团-中小企业发展中心-淘工厂技术-算法工程师-机器学习</p>
<p>9.28查看流程——全部结束</p>
<h4 id="阿里大文娱集团">阿里大文娱集团</h4>
<p>9.12——投简历——研发工程师C/C++（优酷）——北京</p>
<p>9.18——测评</p>
<p>9.21查看流程——简历通过评估，待安排面试</p>
<h4 id="迈瑞医疗">迈瑞医疗</h4>
<p>9.15——投简历——RD08 软件开发工程师——武汉</p>
<p>9.15——测评</p>
<p>9.23——一面</p>
<blockquote>
<p>这面试官有点高冷，话不多，不怎么好沟通，而且方向不是特别匹配，他说软件开发这一块涉及深度学习的项目还是不多，更多的还是传统C++方面的开发。</p>
<p>首先叫我写了个题，全排列，在本地写共享屏幕，要能够输出出来，我感觉我写的没什么问题，但一直输出不出来，我还没找到原因。然后简单聊了下项目跟实习经历，反正他也听不懂，随便扯了几句就结束了，算了，不考虑了。</p>
</blockquote>
<p>9.26——二面</p>
<blockquote>
<p>感觉有点像KPI面，面试官自己不懂GPU相关的东西，却一个劲问我项目里面的难点、技术点、怎么解决的这种问题，认为我一直是在以结果为导向在介绍（提launch_bounds的时候有点掉进他的坑里了，最后他认为我就是调了个API就解决了问题，根本听不懂我寻找问题解决方案的逻辑），问完就直接结束了</p>
<p>我问了他岗位匹配程度，他说医疗领域确实有做大模型这块的打算，但还在初期探索阶段，在JD上写这么一句话其实是想招人来探索这方面的工作，可能招的人不多，本来他说我的经历不怎么匹配的，估计他也不懂，我后来跟他说我本质上也是做模型训练推理部署的，他又说匹配了，感觉像开玩笑一样。。。</p>
</blockquote>
<p>10.11——线下三面</p>
<blockquote>
<p>本来跟我分的6号桌，后来临时改成5号桌了，那个面试官可能不是特别对口，也没法问我技术细节，就对着简历聊了聊项目跟实习，碰到了什么问题怎么解决的这种基本问题，然后问了我现有offer跟薪资，我回的是长存还没谈薪，杭州海康期望26k，他这里我报的期望薪资是23k，虽然也给了原因，但后面复盘感觉还是不应该这么说，应该给个区间的，还是经验少了。整体感觉还行，但也看不出面试官有什么特别的偏爱，等结果吧。</p>
</blockquote>
<h4 id="TP-Link">TP-Link</h4>
<p>9.18——投简历——图像算法工程师——深圳</p>
<h4 id="x-中兴">x 中兴</h4>
<p>9.18——投简历——算法工程师——武汉</p>
<p>9.20——测评</p>
<p>9.22——笔试</p>
<blockquote>
<p>难度不大，都是一些基础问题，编程看不到通过了多少，只知道一题通过了，还有一题没通过，但我感觉应该就是个特殊值没处理的问题，整体逻辑应该没问题。</p>
</blockquote>
<p>10.16——面试</p>
<blockquote>
<p>两个面试官，一个技术的一个HR，技术的先问了我数据流项目的一些问题，还好我还能跟他扯一些，然后问我c语言基础，问我操作系统进程线程那些东西，还好我最后扯回GPU上的线程了，然后问我项目里涉不涉及什么通信协议。HR就问一些基本问题，然后问我期望薪资，我答的20k，另外这是第一个问我能不能接受加班的HR，最后问我意向岗位，我还是希望从事AI软件开发方面，他是什么数字能源部的，他也不是特别了解。</p>
<p>随便面面吧，感觉希望不大。</p>
</blockquote>
<p>11.13——有人打电话问我这个岗位只有长沙才有，问我想不想去，婉拒</p>
<h4 id="新浪">新浪</h4>
<p>9.18——投简历——AIGC算法工程师-CV方向——杭州</p>
<h4 id="小红书">小红书</h4>
<p>9.18——投简历——高性能异构计算工程师——上海</p>
<p>10.23——一面</p>
<blockquote>
<p>面试官不怎么关心我的简历，就每个项目让我简单介绍一下就完了，全程都在搞自己的，不怎么上心，感觉应该是KPI面</p>
<p>做了两个题，一个是比较简单的判断字符串是否能改变成回文串，另一个是实际工作中一个cv特效案例，就是对三维矩阵每个元素进行平移，平移随机值，他给出一个python基本实现，让我使用numpy/torch/cuda任选进行加速，我用cuda写了个简单的，就是tx、ty坐标对应比较麻烦，其他还好</p>
<p>他们是智能创作团队的，主要负责做cv特效推理加速，云端与设备端都有，是用python还是用c++主要看业务需求</p>
<p>基本上没有坑点，如果没过必是KPI面</p>
</blockquote>
<h4 id="携程">携程</h4>
<p>9.18——投简历——算法系统开发——上海</p>
<p>9.21——测评</p>
<p>9.21——笔试</p>
<blockquote>
<p>签到题都没做出来。。。给一个序列进行重排，要求对应元素不相等，且重排后的序列字典序尽可能小</p>
<p>第二题挺简单，5分钟搞定，90%</p>
<p>第三题在矩阵中寻找子矩阵，要求子矩阵中所有元素只出现一次，问子矩阵数量。我用DFS搞了半天没搞出来，chatGPT的方案是固定子矩阵右下角，遍历左上角，用O(n3)来实现，感觉可行</p>
<p>第四题给一个非常大的数，最大可能有1000位，问能否修改其中k个元素，使得修改后的元素为75的倍数，求修改方案总数，结果对1000000007求模。</p>
<p>chatGPT的做法是用动态规划，定义一个二维数组 <code>dp[i][j]</code>，其中 <code>i</code> 表示当前考虑到的数字的位置，<code>j</code> 表示当前已经修改了多少个数字，然后 <code>dp[i][j]</code> 表示在考虑前 <code>i</code> 个数字且修改了 <code>j</code> 个数字的情况下，是否存在一种方式使得结果为 75 的倍数。感觉实现起来也有问题，懒得研究了。</p>
</blockquote>
<h4 id="x-最右">x 最右</h4>
<p>9.18——线下宣讲+线下笔试</p>
<blockquote>
<p>题目比较广泛，计算机网络操作系统数据结构等各方面都有，最后还手写了三个编程题，我还是第一次用笔写acm模式的代码。。。</p>
</blockquote>
<p>9.19——线下一面+二面</p>
<blockquote>
<p>一面啥项目都不问，纯粹考算法，首先问我昨天笔试两题的思路，能不能优化，然后又给了我两道逻辑算法题，我都答的不好，最后好不容易看了眼简历偏偏问了我个量化的问题，基本上g了</p>
<ul>
<li>50个青蛙分别标号1-50，从1到50开始遍历，如果遍历的数字是某标号的因子则该青蛙往前跳一步（比如遍历到2时，2、4、6、8等青蛙跳，遍历到3时3、6、9等青蛙跳），当50个数全遍历完时，问跳的步数是奇数的青蛙有多少只？要求用数学公式求解，不能用算法解。</li>
</ul>
<p>二面是CTO亲自面的，他倒是简历问的比较多，主要关心我在之江期间关于国产GPU方面的工作，反正一顿乱吹就完事了。</p>
</blockquote>
<p>9.20——感谢信</p>
<h4 id="荣耀">荣耀</h4>
<p>9.19——投简历——AI平台/性能优化工程师——深圳</p>
<h4 id="新华三">新华三</h4>
<p>9.20——投简历——技术委员会-算法工程师(J16455)——杭州</p>
<p>9.21——测评</p>
<h4 id="NVIDIA">NVIDIA</h4>
<p>9.21——投简历——Arch Engineer (CPU/Security/DL/CV/Display/Video/Image)——上海</p>
<h4 id="摩尔线程">摩尔线程</h4>
<p>9.21——投简历——GPU通用计算软件工程师/架构师——上海</p>
<p>10.9——一面</p>
<blockquote>
<p>两个面试官，其中一个面试官认识mika，看过我们提交上去的报告，对我们100倍的速度咋得出来的比较好奇，我都忘了咋回事了。。。而且他让我写个reduction我都没写出来，国庆前后太久没写代码了。。。面试官人挺好的，而且也是合作方，面试成这鬼样子也太尴尬了。。。</p>
</blockquote>
<h4 id="阿里云">阿里云</h4>
<p>9.21——投简历——基础平台研发工程师——杭州</p>
<p>10.7——测评</p>
<p>自从上次被控股集团KPI面了之后实在懒得走阿里流程了，现在还在笔试阶段，三方都要开了，后续流程放弃了算了</p>
<h4 id="√-平头哥">√ 平头哥</h4>
<p>9.21——投简历——芯片软件工程师——杭州、上海</p>
<p>10.7——测评</p>
<p>10.11——在线笔试</p>
<blockquote>
<p>面试官拉了三个人，搁一个面试房间里发题，当场写代码，写完自己离开，用手撕的方式做笔试。。。手动实现一个数据管理的类，还挺简单</p>
</blockquote>
<p>10.14——一面</p>
<blockquote>
<p>对面也是做ai加速器相关的，跟燧原这种差不多，反正把项目随便讲讲吧，他问我一些专业性的东西像Nsight Compute中的一些指标我都记不清了，然后手写了一个CPU上的矩阵乘，我直接三个for搞完，GPU上的实现口述。</p>
</blockquote>
<p>10.24——二面</p>
<blockquote>
<p>跟面试官聊的挺好，应该是部门负责人，没有让我自我介绍，直接开始聊天了，关于项目的技术细节我也都答的很顺畅，但手撕还是没能做出来，要我用c++实现一个tensor维度变换，比如把(n,h,w,c)变换成(n,w,h,c)，我for了半天没for出来，最后跟他口述了一下，问题变成了需要几层嵌套，然后再扩展问如果有stride的话应该有几层嵌套，答的都不是太好。</p>
<p>他们是做ai芯片的，跟燧原的性质差不多，他们组主要负责写软件加速库，以及写大规模互联相关的函数库，主要工作地点在上海，杭州也有少部分。</p>
</blockquote>
<p>10.30——三面</p>
<blockquote>
<p>估计又是一个大boss，聊了十几分钟就结束了，他重点关心了我在GPU国产化方面的工作，然后大致了解了一下我的基础能力，没有问具体技术细节，后面还问我对他们的工作感不感兴趣，以及现在手上已有的offer情况，整体上看应该是准备要我了，还行还行。</p>
</blockquote>
<p>11.2——HR面</p>
<blockquote>
<p>就问了些基本情况，实习、项目、工作意向、获奖等方面，感觉还行，我被分到并行计算软件团队，HR下来之后跟主管沟通一下，一个星期之内主管会打电话问我意向，如果我确定要来再发offer与谈薪。</p>
</blockquote>
<p>11.2——主管电话</p>
<p>11.3——意向书</p>
<p>11.22——正式offer</p>
<p>11.23——签署三方，秋招结束</p>
<h4 id="金山云">金山云</h4>
<p>9.21——投简历——C/C++研发工程师——武汉</p>
<p>9.28——笔试</p>
<blockquote>
<p>选择题基本知识部分还挺简单，c++部分不咋会，感觉很多是软件工程的题，各种模式啥的</p>
<p>编程题两题都a了，提前半个小时交卷</p>
</blockquote>
<h4 id="x-小米">x 小米</h4>
<p>9.21——投简历</p>
<ul>
<li>第一志愿——机器学习算法工程师——武汉</li>
<li>第二志愿——深度学习框架工程师——北京</li>
</ul>
<p>9.23——笔试</p>
<blockquote>
<p>两道编程还挺简单，一题100%一题80%，选择题不好做，太多机器学习基础忘记了</p>
</blockquote>
<p>11.22——约面放弃</p>
<h4 id="SHEIN">SHEIN</h4>
<p>9.21——投简历——后台开发工程师（AI方向）——深圳</p>
<p>9.28——测评</p>
<p>10.14——笔试放弃</p>
<h4 id="旷视">旷视</h4>
<p>9.21——投简历——【MegEagle】深度学习系统工程师/研究员——北京</p>
<h4 id="特斯拉">特斯拉</h4>
<p>9.21——投简历——C++软件工程师，地图与导航 C++ Software Engineer, Maps &amp; Navigation——上海</p>
<h4 id="科大讯飞">科大讯飞</h4>
<p>9.21——投简历——C++开发工程师——武汉</p>
<p>9.24——测评</p>
<p>9.27——笔试</p>
<blockquote>
<p>选择题是通用基础，啥玩意都包含了，随缘做</p>
<p>编程题感觉奇奇怪怪的，都是那种没有固定答案的题，比如如何对网格进行一笔画，我直接Z字形遍历就完事了。。。最后一题自定义了字符串权重的定义，要我构造一个满意条件的字符串，我自认为没什么问题，怎么测试都是对的，但就是只能通过12.5%的结果，其中10%还是无法构造的结果-1，怀疑是题目判断正确的方式有问题，懒得管了。</p>
</blockquote>
<p>10.9——一面</p>
<blockquote>
<p>面试官也是用c++做深度学习模型部署工程化方面的，理论上方向是匹配的，一直在问我c++基础，太多八股了，还问了操作系统进程线程间通信这方面的知识，基础还是太薄了</p>
<p>科大讯飞合肥那边主要是做一些比较核心的东西，武汉这边是研发中心，主要是对合肥那边的成果做一定的包装，然后发布给其他部门调用，c++在这里面既起到封装SDK方面的作用，也涉及模型部署、云计算大数据区块链方面的底层研发，作用还是挺大的（面试官口中的模型部署是真正上线运行的那一套，而不是用python这种脚本语言train模型跑完就完事的那种）</p>
</blockquote>
<h4 id="亚控科技">亚控科技</h4>
<p>9.22——投简历——软件开发工程师（校招C++方向—非北京）——武汉</p>
<h4 id="比特大陆">比特大陆</h4>
<p>9.22——投简历——算法工程师——武汉</p>
<h4 id="x-比亚迪">x 比亚迪</h4>
<p>10.10——投简历——武汉</p>
<p>11.8——HR面</p>
<blockquote>
<p>都不预约，直接打电话当场开始面试，就离谱，我反手给他报期望薪资40w，他立刻就挂了，总共4分钟，笑死个人</p>
</blockquote>
<p>11.12——一面放弃</p>
<h3 id="国央企银行研究所">国央企银行研究所</h3>
<h4 id="九部">九部</h4>
<p>8.31——投简历——软件架构设计岗、数据中心基础架构设计岗——武汉</p>
<p>10.10——线下双选重新投简历（指定403室，老师说有cuda相关的工作）</p>
<h4 id="中国电信">中国电信</h4>
<p>9.4——投简历</p>
<ul>
<li>云计算研发工程师（广州）</li>
<li>算法工程师（上海）</li>
<li>研发工程师（武汉分公司）</li>
<li>云网运营工程师（武汉分公司）</li>
</ul>
<p>9.14——测评</p>
<p>9.20——一面</p>
<blockquote>
<p>四个面试官组一个腾讯会议，让我共享简历聊天，反正各方面都简单问了下吧，还有两个女生，感觉问题都不难，没有涉及到真正的技术细节</p>
<p>因为中国电信这几年在组建智算中心，也搞大模型去了，准备做从上到下的整套体系，今年的主要目标是跟国产GPU公司沟通，根据不同用户需求选用不同公司的卡来组建智算云，明年的工作主要是在这些卡的基础上搭建软件平台，这就涉及到对这些国产GPU公司的软件栈比较了解才行，因此我这边的工作还是比较匹配他们的需求的</p>
<p>有一个比较尴尬的问题，中国电信广州研究院是数据流项目课题五的参与单位，据说有一个上周还来华科开会了的老师对我特别感兴趣，不过今天没有到场，如果有下一面的话他应该会来，坏了，又有露馅的可能性了。。。</p>
</blockquote>
<p>10.14——笔试放弃</p>
<h4 id="农行">农行</h4>
<p>9.6——投简历——研发中心——武汉</p>
<h4 id="国家智能设计与数控技术创新中心">国家智能设计与数控技术创新中心</h4>
<p>9.7——线下双选会投简历</p>
<h4 id="√-x-东风商用车技术中心">√ x 东风商用车技术中心</h4>
<p>9.11——线下宣讲投简历</p>
<p>9.11——现场面试</p>
<blockquote>
<p>面试官是个大牛，以前在华科当过老师，也在华为干过，在外面闯荡了几十年后重回的东风，现在可能是商用车技术中心总监级别的人物。</p>
<p>整体面试体验非常好，这种面试没那么紧张，就是纯聊天，问了我项目一些基本情况，问了我做了一些什么工作，遇到了什么难点，怎么解决的，问了我父母的基本情况，问我了不了解自动驾驶这方面，我也反问了他整体做什么业务。</p>
<p>据他所说，东风是自动驾驶的国家队，负责牵头整合当前国内自动驾驶领域的研究，明面上百度是老大，但实际上百度华为这种公司都与东风有合作。除了整合资源以外，因为商用车领域还涉及到军方的一些项目，或者可能一些别的原因，东风自己也要做自动驾驶的研究，有一个十几个博士带领的研究团队在做这个事情。另外东风也有自己的东风云做自动驾驶的背后数据整合与分析，这也需要涉及大数据分析、云计算、算力等方面的工作，据他所说他就是带领大数据相关团队的负责人。</p>
<p>此外，从盈利的角度来讲，目前自动驾驶领域唯一能赚钱的方向还是在商用车这一块，特别是港口与矿场，这方面需求挺大的，所以业绩上可能不是问题，待遇这方面我问会不会更好一些他没有明说，听他额外的意思在奖金什么的方面可能比其他部门要高一些。</p>
<p>整体来看，他对我非常满意，我对他这个团队也有一定的兴趣。待遇这方面就不管了，反正整个武汉的国央企都是差不多的价，同学签的集团技术中心总包19w，我只要不比他低就行了。我更关心其他方面：</p>
<ul>
<li>网上对商用车技术中心的评价不高，没有隔壁集团技术中心好，在知乎上商用车技术中心都像要倒闭了的，但那边具体好在什么方面也都说不清楚，这方面还得再观望一下。（知乎上说乘用车自动驾驶转商用车好转，但商用车转乘用车不好转）</li>
<li>感觉他所谓的自动驾驶国家队有画饼的嫌疑（毕竟还有一汽上汽这种公司），而且提到百度这种公司的时候在下意识混淆商用车与乘用车的区别。综合目前的信息来看，只能说东风中规中矩，没有想象中那么牛，但稳步发展还是问题不大。</li>
<li>加班问题到时候得好好问问，网上有8106的说法；另外就是工作地点，如果在万达那块我还可以考虑，如果在朱山湖那趁早放弃。</li>
</ul>
<p>东风要压本科双证逼签的，违约金6k，基本上我只要投了过不了几天就要签了，所以慎重考虑，从目前的想法来看，如果在万达那块工作、加班程度低且总包&gt;20，那我可以考虑先签了再说，任何一条满足不了就算了。</p>
</blockquote>
<p>9.12——测评</p>
<p>9.14——HR宣讲</p>
<blockquote>
<ul>
<li>商用车技术中心总计1800人，1370人研发，央企，合资企业</li>
<li>总部十堰，研发中心武汉，大概率在珠山湖上班</li>
<li>6个月集中培训，其中所有员工都要去十堰工厂实习4个月，再回武汉培训两个月</li>
<li>培训完后汇总排名，再考核分配部门（次年1月）</li>
<li>双休，一天8小时，适当加班，可以调休或者支付加班费（没有提具体多少，肯定不高）</li>
<li>签约要验本科学历学位，四六级证书，没确定是线上签还是线下签，没有提压双证的事</li>
</ul>
<p>待遇：</p>
<ul>
<li>
<p>年目标工资——12.5w，每个月实际到手 12.5/12 * 80%（20%左右是其他个人需缴纳的部分）</p>
</li>
<li>
<p>津补贴——每个月700（交通、餐补、话费等）</p>
</li>
<li>
<p>奖励——年终，业绩</p>
<p>12.5w中大概分为7:3，30%属于业绩基础，70%属于年终基础</p>
<p>A绩效可以拿到的业绩基础的20%（忘了问一年哪几次，盲猜是季度或者年）</p>
<p>B绩效可以拿到业绩基础的10%</p>
<p>年终基础/12为一个月的年终收入</p>
<p>前几年平均6个月年终，这两年效益不好（盲猜基本上没什么年终了）</p>
</li>
<li>
<p>公积金个人单位都10%</p>
</li>
<li>
<p>七险二金，企业年金（自愿）个人2%-4%，单位5%，商业保险等其他都是正常的</p>
</li>
<li>
<p>春节1000慰问金，中秋500慰问金，生日200津贴，防暑降温费取暖费等未知</p>
</li>
<li>
<p>安家费1w5，两年支付</p>
</li>
<li>
<p>政府人才补贴，十堰研究生15w，三年支付（我们挂名在十堰，所以在武汉工作也能拿到这15w，这是商用车公司相比于东风其他公司特有的，但我担心拿了十堰的钱以后不跟十堰做事？不知道工作地点跟户口等方面会不会受影响）</p>
</li>
<li>
<p>七月底八月初共9-11天高温假，第一年高温假之后入职</p>
</li>
<li>
<p>3年免费宿舍，两人间（没有听说有租房补贴！）</p>
<ul>
<li>总包大概16-20w（大概率就是16w）</li>
</ul>
</li>
</ul>
<p>整体听下来完全提不起兴趣，没有一点满意的，HR的饼都吃不进去更别提实际情况了。唯一的正面印象就是15w人才补贴，但是担心的风险如上。基本上决定拒了。</p>
</blockquote>
<h4 id="x-汉江实验室">x 汉江实验室</h4>
<p>9.17——投简历——科研岗-研究员——武汉</p>
<p>11.3——约线下面试，放弃</p>
<h4 id="国药控股数字科技（上海）有限公司">国药控股数字科技（上海）有限公司</h4>
<p>9.19——投简历——软件开发方向（应用开发）——武汉</p>
<h4 id="启元实验室">启元实验室</h4>
<p>9.21——投简历——计算框架工程技术岗——北京</p>
<h4 id="湖北电网（提前批）">湖北电网（提前批）</h4>
<p>10.6——投简历</p>
<ul>
<li>第一志愿——电科院</li>
<li>第二志愿——本部（调控中心）</li>
<li>第三志愿——武汉供电公司</li>
</ul>
<h4 id="公安部第三研究所">公安部第三研究所</h4>
<p>10.9——投简历——算法工程师-物联网技术研发中心——上海</p>
<p>10.9——测评</p>
<h4 id="航天科工新型研发机构">航天科工新型研发机构</h4>
<p>10.10——线下双选投简历——北京</p>
<h2 id="秋招准备">秋招准备</h2>
<h3 id="自我介绍">自我介绍</h3>
<p>面试官您好，我叫文苏洋，本科毕业于西安电子科技大学电子信息工程专业，研究生现就读于华中科技大学计算机学院，研究方向为深度学习与计算机体系结构。</p>
<p>在校期间，我深度参与了一项国家重点研发计划从立项到研究的全部工作，目前产出两篇论文，均与图神经网络加速相关，两篇论文均处于撰写或在投阶段。</p>
<p>此外，我还参与了一项国家自然科学基金重点项目，研究内容为深度学习模型压缩，这也是我的毕业论文开题方向，目前产出一篇论文，已见刊Q1分区期刊FGCS。</p>
<p>在研二期间，我随课题组前往杭州的之江实验室实习，参与图计算系统的项目研发，主要负责推动（我们实验室自研的）图计算系统在国产GPU或AI加速器上的移植工作，在此期间我与多家国产GPU或AI加速器公司进行过交流与项目合作，同时我也参与推动图计算系统在高性能计算领域的应用。</p>
<p>以上是我的自我介绍，谢谢！</p>
<h3 id="数据流项目">数据流项目</h3>
<h4 id="详细介绍">详细介绍</h4>
<blockquote>
<p>数据流是一种<strong>区别于传统控制流冯诺依曼架构的新体系架构</strong>思想，最早在上个世纪70年代就被提出，它与控制流最大的区别在于控制流是<strong>指令驱动，按照顺序逐条执行</strong>的，而数据流是<strong>数据驱动，数据到了就执行</strong>，因此它是<strong>全局乱序</strong>的，根本就<strong>没有多线程同步这个说法</strong>，也<strong>不需要</strong>像控制流那样需要<strong>CPU来集中控制</strong>，可以在<strong>更细粒度的层面利用硬件资源</strong>，像控制流架构碰到的<strong>并行墙</strong>、<strong>内存墙</strong>等问题它都不会碰到，因此它<strong>更适合大规模的数据处理</strong>。</p>
<p>具体而言，这个项目的目标是<strong>构建一整套数据流生态</strong>，课题一上海交大牵头负责芯片架构设计，课题二阿里云牵头负责编译系统设计，课题三我们牵头负责运行时系统设计，课题四中科院计算所牵头负责集成流片，课题五之江实验室牵头负责应用示范。</p>
<p>运行时系统在我的理解中就是算子这一层，我们利用下层课题二编译系统提供的编程接口，为上层课题五各种应用比如天文、金融等提供算子支持，同时也包括了算子之间的动态调度、资源管理等等问题。</p>
</blockquote>
<h4 id="何东澳论文">何东澳论文</h4>
<h5 id="详细介绍-2">详细介绍</h5>
<blockquote>
<p>这篇论文分为Python冗余消除与CUDA内核融合两大块，是由一个博士与两个硕士合作完成的，博士负责总体把关与论文撰写，另一个硕士负责Python端冗余消除的实现，我负责CUDA端内核融合的实现。</p>
</blockquote>
<blockquote>
<p>冗余消除部分的核心思想是通过减少图的边数从而降低训练过程中的冗余计算，同时根据图的社区性对图进行分区，将冗余消除过程解耦，变成许多个可以并行的子问题</p>
</blockquote>
<p>面试官如果您对现实生活中的图数据有一定了解的话就会发现，这些图数据往往具有相当大的稀疏性，用数据结构来表示的话也就是图的邻接矩阵A非常稀疏，而图神经网络的训练本质上也就是AXW三个矩阵的乘法过程（A——邻接矩阵，X——图节点的特征矩阵，W——权重矩阵），所以您可以将GNN的训练加速简单理解为稀疏矩阵乘法加速。</p>
<p>以往的GNN加速论文大部分都是在CUDA Core上下功夫（因为Tensor Core通常都是用来处理密集矩阵乘法的）</p>
<p>而我们的Idea就是能不能同时利用Tensor Core与CUDA Core，我们首先对图进行极化，将极化之后密集的部分交给Tensor Core处理，稀疏的部分交给CUDA Core处理，把两个模块放在同一个kernel内，使用不同的warp同时进行调度，这就是所谓的内核融合。</p>
<blockquote>
<p>我通过实验发现Tensor Core模块的整体处理速度大概是CUDA Core模块的2-3倍左右，因此这篇论文我采用的是2:1或者3:1的静态混合比进行实验。</p>
</blockquote>
<p>具体的技术细节我也总结了几个亮点，如果面试官您感兴趣的话我们可以继续交流。</p>
<h5 id="亮点（CUDA部分）">亮点（CUDA部分）</h5>
<ul>
<li>
<p>bar.sync、cuda::barrier（计数arrive与等待wait不在一起，更灵活）、cooperate_group 做部分数据同步</p>
</li>
<li>
<blockquote>
<p>持久线程块（保持kernel驻留在SM上，减少kernel的启动次数，降低开销）</p>
</blockquote>
</li>
<li>
<p>对排列方式定制化（Tensor Core行列，符合计算习惯，wmma计算更高效；CUDA Core行行，便于进行合并内存访问优化）</p>
<blockquote>
<p><strong>每个threadgroup（warp的32个线程分为8个threadgroup，每个threadgroup包含4个线程）加载一个4×16子矩阵</strong></p>
<p>对于行主序布局的矩阵A ，threadgroup中的每个线程使用2个合并的128位宽load指令加载16个连续元素。对于列主序布局，threadgroup中的每个线程使用4个合并的64位宽load指令加载4块4个连续元素</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/75753718">https://zhuanlan.zhihu.com/p/75753718</a></p>
<p>每个时钟周期，每个Tensor Core可完成一个4×4矩阵乘累加（MACC，Matrix multiply and Accumulation）计算。WMMA API暴露给Tensor Core的tile大小（16×16）显然比Tensor Core每次操作的矩阵大小（4×4）更大。因此，每个wmma.mma操作需要<strong>64</strong>个Tensor Core操作才能完成。</p>
</blockquote>
<blockquote>
<p>L1 cache本质上跟共享内存是共享空间的，L2可以跨SM共享</p>
<p>当前的GPU架构允许通过编译选项来控制是否启用一级缓存。当一级缓存被禁用时，对全局内存的加载请求将直接进入二级缓存；如果二级缓存未命中，将由DRAM完成请求。核函数从全局内存DRAM中读取数据有两种粒度， 使用一级缓存时，每次按照128字节进行缓存；不使用一级缓存时，每次按照32字节进行缓存。</p>
<p>CUDA在Global Memory上访问粒度是32B，而每32B组成一个sector，一个cacheline则对应4个sector，总共大小为128B。</p>
<p>而CUDA执行指令的单位是线程束，当发生一次访存的时候，其实是该线程束的所有线程执行访存操作。每个线程访存粒度可以是1B,2B,4B,8B,16B。</p>
</blockquote>
</li>
<li>
<p>使用Nsight System与Compute做性能检测，分析kernel的资源占用情况，发现性能瓶颈在寄存器限制上，使用launch_bounds将部分寄存器数据移动到local memory上，增加一个SM上驻留的block数量，提高SM利用率</p>
<blockquote>
<p>编译器首先得计算得到kernel可以使用的寄存器数量上限 L</p>
<p>如果初始寄存器使用量高于 L，编译器会进一步减少它，直到它变得小于或等于 L，通常以更多的本地内存使用和更多的指令为代价；</p>
<p>如果初始寄存器使用量小于L，编译器可能会将寄存器使用率提高到 L，以减少指令的数量并更好地隐藏单线程指令延迟。</p>
</blockquote>
<blockquote>
<p>local memory本质上是一段显存，在片外，是线程私有，但它总是被L2 cache缓存</p>
</blockquote>
<blockquote>
<p>Nsight System我一般用来观察函数或者kernel的实际执行情况，看GPU利用率是否最大化，隐藏数据传输是否成功等等。</p>
<p>Nsight Compute一般观察什么参数？</p>
<ul>
<li>
<p>计算吞吐率/访存吞吐率</p>
</li>
<li>
<p>L1/L2命中率</p>
</li>
<li>
<p>每个线程使用的寄存器数量</p>
</li>
<li>
<p>每个block静态/动态共享内存使用量</p>
</li>
<li>
<p>理论占有率/实际占有率</p>
</li>
</ul>
<p><strong>Occupancy is the ratio of the number of active warps per multiprocessor to the maximum number of possible active warps</strong></p>
<p><strong>Higher occupancy does not always result in higher performance, however, low occupancy always reduces the ability to hide latencies, resulting in overall performance degradation</strong></p>
<p><strong>Large discrepancies between the theoretical and the achieved occupancy during execution typically indicates highly imbalanced workloads.</strong></p>
<p><strong>注意与GPU利用率区分：GPU利用率是反馈GPU上各种资源繁忙程度的指标，通常泛指GPU Core的利用率。</strong></p>
</blockquote>
</li>
</ul>
<h5 id="有什么困难（问题）">有什么困难（问题）</h5>
<ul>
<li>Tensor Core的输入矩阵有大小限制（对于half要求16 x 8，对于tf32要求16 x 16），所以怎么把矩阵进行分割就是个大问题，如果是训练过程中当场分割的话就要占据大量时间</li>
<li>静态混合比不灵活</li>
</ul>
<p>在第二篇论文中解决</p>
<h4 id="我的论文">我的论文</h4>
<h5 id="详细介绍-3">详细介绍</h5>
<p>这篇论文同样是加速AXW计算，但我不再使用内核融合的方式，而是使用CUDA Stream更加灵活地调整分配给Tensor Core与CUDA Core的计算时间，同时引入CUDA Pipeline双缓冲技术与生产者——消费者设计模式来隐藏数据读取时间</p>
<h5 id="亮点">亮点</h5>
<ul>
<li>
<p>引入 CUDA Stream</p>
<blockquote>
<ul>
<li>
<p>在CUDA当中，<strong>核函数kernel的执行总是异步的</strong>，可直接重叠主机和设备的计算，而cudaMemcpy数据传输总是同步的。</p>
</li>
<li>
<p>基于流的异步的内核启动和数据传输支持以下类型的粗粒度并发：</p>
<ul>
<li><strong>并发设备计算（我们用的是这种情况）</strong></li>
<li>重叠主机与设备间的数据传输和设备计算</li>
<li>重叠主机计算和主机与设备间的数据传输</li>
<li>重叠主机计算和设备计算</li>
</ul>
</li>
<li>
<p>==<strong>空流=默认流=隐式流=同步流	非空流=自己创建的流=显示流=异步流</strong>==</p>
</li>
<li>
<p><strong>主机上非空流是异步流，其上所有的操作都不会阻塞主机执行</strong>（也必须是异步的，使用cudaMemcpyAsync而不是cudaMemcpy进行数据拷贝）。相应地，<strong>隐式的空流是同步流，大多数添加到空流上的操作都会导致主机在先前所有的操作产生阻塞。</strong></p>
</li>
<li>
<p><strong>虽然非空流在主机上是非阻塞的，但非空流内的操作可以被空流中操作所阻塞</strong>，因此非空流可以分为阻塞流和非阻塞流</p>
<ul>
<li><strong>如果一个非空流是阻塞流，则空流可以阻塞该非空流中的操作。</strong>（如果显示的创建了一个阻塞流，则默认流可以阻塞创建的流）</li>
<li><strong>如果一个非空流是非阻塞流，则它不会受空流影响。</strong></li>
</ul>
</li>
<li>
<p>==<strong>cudaStreamCreate创建的流是阻塞流（默认）</strong>==，这就意味着流中操作可被阻塞，直到空流中的操作完成，直到空流的执行结束</p>
</li>
<li>
<p><strong>cudaStreamCreateWithFlags可以创建非阻塞流</strong></p>
<ul>
<li>cudaStreamDefault，cudaStreamCreate()函数的默认选项</li>
<li>cudaStreamNonBlocking，创建非阻塞流。</li>
</ul>
</li>
<li>
<p><strong>两个阻塞流之间是否可以并发执行要看设备支不支持Hyper-Q</strong></p>
<ul>
<li><strong>在没有Hyper-Q技术之前，CPU和GPU之间只有1个工作队列</strong>（1个工作队列包含1个内存复制引擎和1个核函数执行引擎），所有流共用这个工作队列。</li>
<li><strong>从Kepler架构开始，引入了Hyper-Q技术，CPU与GPU之间最多可以建立32个工作队列</strong>，每个流分配一个工作队列，如果创建的流超过32个，则多个流才共用一个工作队列。</li>
<li><strong>Hyper-Q技术另外一个重要的功能是使不同stream中的计算也能够重叠，重叠效果与GPU剩余资源（核心与显存带宽）有关。<strong>比如，stream1中的计算要占用30%的核心和50%的显存带宽，而stream2中的计算要占用80%的核心和60%的显存带宽，二者同时运行时会按一定的比率争用GPU资源。所以当一个stream的计算任务没有占满GPU资源时，还可以再运行另一个stream计算任务，以此最大化GPU的资源利用率。</strong>（我们用的是这种情况）</strong></li>
</ul>
</li>
</ul>
</blockquote>
</li>
<li>
<p>引入 CUDA Pipeline</p>
</li>
<li>
<p>改变了数据存储格式，在查阅cusparse文档的时候无意间发现的BSR（BCSR）存储格式，也就是按块进行CSR压缩，这样可以把训练过程中的矩阵分割过程转移到预处理部分，一次分割多次使用，还可以更灵活地进行数据读取，大大降低了训练时间。</p>
</li>
</ul>
<blockquote>
<p>如果面试官认为这篇论文的亮点不够充分，可以这么说：上一篇论文的重点是Idea的创新，采用新的冗余消除与内核融合算法实现GNN加速，这一篇论文的重点是在上一篇的基础上采用流水线与双缓冲的思想进行工程优化，同时据我的调研结果来看我们也是第一次将BCSR压缩格式引入到GNN预处理过程中来，可能听起来Idea不够让人眼前一亮，但里面需要克服的工程难点还是挺多的。</p>
</blockquote>
<h5 id="有什么困难（后续优化）">有什么困难（后续优化）</h5>
<ul>
<li>因为wmma的计算数据格式限制，经综合考虑后选择用half格式进行计算，但half的数据精度不高，实际实现过程中存在严重的误差累积问题，暂时没有想到更好的解决办法。</li>
</ul>
<h4 id="陈雨浩论文">陈雨浩论文</h4>
<h5 id="详细介绍-4">详细介绍</h5>
<p>这篇论文想要解决的问题是：我们很容易观察到CNN模型不同的网络层对模型压缩的敏感度不同，那么我们应该如何为不同网络层定制不同的剪枝率。</p>
<p>论文整体思路沿用可微神经网络结构搜索DARTS那一套算法，也就是为每一层的可选剪枝率设定候选集，所有层的候选集合在一起就构成了一个巨大的搜索空间，然后使用softmax连续松弛化之后就可以进行迭代搜索了。但是这里面最大的两个问题：</p>
<ul>
<li>候选集只能预先设计，非常有限</li>
<li>随着网络层数增加搜索计算量成几何倍数增长</li>
</ul>
<p>因此我们的解决方案是引入进化算法，可微搜索与进化更新交替进行，每经过几轮搜索就将最高概率的候选剪枝率作为父代来生成子代，然后替换掉最低概率的候选剪枝率。这样重复几次，能够在搜索效率与搜索质量直接取一个平衡。</p>
<p>当然对于一些更复杂的网络，比如ResNet、DenseNet等等，我们也有更复杂的优化方式，比如分区域搜索等等，我就不详细展开了。最后鉴于剪枝后的网络可能训练难度比较大，我们还采用了知识蒸馏对网络进行微调。</p>
<h3 id="之江实习">之江实习</h3>
<h4 id="与国产GPU-AI加速器公司的接触情况">与国产GPU/AI加速器公司的接触情况</h4>
<p>目的：解决图计算系统对NV卡的依赖问题，实现国产化</p>
<p>全功能GPU——AI加速、视频编解码、图形渲染、高性能计算四大功能，我们更关心AI加速与高性能计算两部分功能</p>
<p>芯动科技——主要工作重心在图形渲染上，在这两部分涉及不多，且很难直接从CUDA代码移植过去</p>
<p>摩尔线程——全功能GPU，支持我们需要的功能，且MUSA与CUDA相似性高，便于移植</p>
<blockquote>
<p>MUSA与CUDA的区别（S3000与V100的区别）：</p>
<ul>
<li>一个warp有128个线程（可以从这个角度扩充移植过程中的难点）</li>
<li>S3000 INT类型的core比V100少，FP32类型的core比V100多，在图计算算法上表现不佳。</li>
<li>S3000 有张量计算引擎，理论上类似Tensor Core进行高效计算，但当前开发文档完整度不高，暂不清楚应该如何从外部调用，文档上更多地还是将其当做一个内部优化的硬件结构。</li>
</ul>
</blockquote>
<p>燧原科技——专用AI训练、推理加速卡，初步沟通时尚未完成软件栈的构建，对稀疏矩阵计算支持力度不够，现在已经好多了，接下来的工作是重新与他们对接。</p>
<h4 id="与计算天文团队的对接情况">与计算天文团队的对接情况</h4>
<p>FAST首席科学家李菂在之江实验室有一个专门做数据处理的团队，我们希望把我们的图计算系统应用在天文的数据上，因此与他们有多次接触。根据他们的资料，FAST的数据接收速率平均在6GB/s左右，峰值速率可以达到38GB/s，每年可以新增10PB的数据，但是当前的数据处理速度仅仅只有每秒几M，因此大部分数据其实都是通过卡车拉到各研究机构慢慢的分析的。</p>
<p>而天文领域出成果的方式很有意思，他们就是采用各种手段从这海量的数据里面寻找想要的信号，比如脉冲信号，快速射电暴信号等等，只要运气好能找到有特点的东西，那基本上一篇Science就稳了，所以关键就在于寻找信号的方式。他们常用的那些消色散等等传统算法我也不是太懂，我们只关心能不能把这些数据用图来建模，只要能够将星体之间的关系用图来表示，那什么BFS、单源最短路径、PageRank等等算法就可以在我们自己的图计算加速器上跑起来，那说不定对信号寻找还有奇效。</p>
<p>这一部分最开始是我们课题组四个人在对接，我们当时阅读了大量的相关论文，包括怎么用深度学习处理时间序列频谱、怎么用图卷积学习节点间的依赖关系等等，也提出了几种建模思路，我办理离职之前正在对模型可行性进行分析，不清楚现在分析结果怎么样了。</p>
<h3 id="手撕代码">手撕代码</h3>
<h4 id="手撕GEMM优化">手撕GEMM优化</h4>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 最简单的一种，将A与B分块后调入共享内存，一个block计算C的一个块，block中一个线程计算一个值</span><br><span class="hljs-comment">// C=A*B，大小均为2048*2048，A分块M*K，B分块K*N，C分块M*N，M = 16, N = 16, K = 16;</span><br><span class="hljs-function">dim3 <span class="hljs-title">grid</span><span class="hljs-params">(<span class="hljs-number">16</span>, <span class="hljs-number">16</span>, <span class="hljs-number">1</span>)</span></span>;<br><span class="hljs-function">dim3 <span class="hljs-title">block</span><span class="hljs-params">(<span class="hljs-number">16</span>, <span class="hljs-number">16</span>, <span class="hljs-number">1</span>)</span></span>;<br>Gemm&lt;&lt;&lt;grid, block&gt;&gt;&gt;(A, B, C, <span class="hljs-number">16</span>, <span class="hljs-number">16</span>, <span class="hljs-number">16</span>, <span class="hljs-number">2048</span>);<br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">Gemm</span><span class="hljs-params">(<span class="hljs-type">float</span>* __restrict__ A,</span></span><br><span class="hljs-params"><span class="hljs-function">                     <span class="hljs-type">float</span>* __restrict__ B,</span></span><br><span class="hljs-params"><span class="hljs-function">                     <span class="hljs-type">float</span>* __restrict__ C,</span></span><br><span class="hljs-params"><span class="hljs-function">                     <span class="hljs-type">const</span> <span class="hljs-type">int</span> M,</span></span><br><span class="hljs-params"><span class="hljs-function">                     <span class="hljs-type">const</span> <span class="hljs-type">int</span> N,</span></span><br><span class="hljs-params"><span class="hljs-function">                     <span class="hljs-type">const</span> <span class="hljs-type">int</span> K,</span></span><br><span class="hljs-params"><span class="hljs-function">                     <span class="hljs-type">const</span> <span class="hljs-type">int</span> Width</span></span><br><span class="hljs-params"><span class="hljs-function">                    )</span> </span>&#123;<br>    	__shared__ <span class="hljs-type">float</span> shared_A[M][K];<br>    	__shared__ <span class="hljs-type">float</span> shared_B[K][N];<br><br>    	<span class="hljs-type">int</span> bx = blockIdx.x;<span class="hljs-type">int</span> by = blockIdx.y;<br>    	<span class="hljs-type">int</span> tx = threadIdx.x;<span class="hljs-type">int</span> ty = threadIdx.y;<br><br>    	<span class="hljs-type">int</span> row = by*M + ty;<br>    	<span class="hljs-type">int</span> col = by*N + tx;<br>    	<span class="hljs-type">int</span> value = <span class="hljs-number">0</span>;<br>    	<span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; Width/K; ++i) &#123;<br>            shared_A[ty][tx] = A[row * Width + i * K + tx];<br>            shared_B[ty][tx] = B[(i * K + ty) * Width + col];<br>            __syncthreads();<br><br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>; j &lt; K; ++j) &#123;<br>                value += shared_A[ty][j] * shared_B[j][tx];<br>            &#125;<br>            __syncthreads();<br>        &#125;<br>    	C[row*Width+col] = value;<br>    &#125;<br></code></pre></td></tr></table></figure>
<h4 id="手撕归约（滴滴）">手撕归约（滴滴）</h4>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">Reduction</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">float</span>* input, <span class="hljs-type">const</span> <span class="hljs-type">float</span>* output, <span class="hljs-type">const</span> <span class="hljs-type">int</span> n)</span> </span>&#123;<br>    <span class="hljs-type">int</span> tid = blockIdx.x * blockDim.x + threadIdx.x;<br>    <span class="hljs-type">int</span> total_thread_num = gridDim.x * blockDim.x;<br><br>    <span class="hljs-type">float</span> sum = <span class="hljs-number">0.0f</span>;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = tid; i &lt; n; i += total_thread_num) &#123;<br>        sum += input[i];<br>    &#125;<br><br>    <span class="hljs-keyword">extern</span> __shared__ <span class="hljs-type">float</span> shm[];<br>    shm[threadIdx.x] = sum;<br>    __syncthread();<br><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = blockDim.x / <span class="hljs-number">2</span>; i &gt;= <span class="hljs-number">1</span>; i /= <span class="hljs-number">2</span>) &#123;<br>        <span class="hljs-keyword">if</span> (threadIdx.x &lt; i) &#123;<br>            shm[threadIdx.x] += shm[threadIdx.x + i];<br>        &#125;<br>        __syncthreads();<br>    &#125;<br>    <span class="hljs-keyword">if</span> (threadIdx.x == <span class="hljs-number">0</span>) &#123;<br>        output[blockIdx.x] = shm[<span class="hljs-number">0</span>];<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h4 id="手撕π计算（hda）">手撕π计算（hda）</h4>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 原理——莱布尼兹级数：1- 1/3 + 1/5 - 1/7 + ... = π/4</span><br><span class="hljs-comment">// hda碰到的问题不能使用数学公式，要用采用和统计学分析去估算(向坐标0-1之间的正方形区域撒黄豆，每个线程一个坐标，到原点距离小于1的线程数/总线程数 的结果近似为π/4)</span><br><span class="hljs-comment">// CPU版本</span><br><span class="hljs-function"><span class="hljs-type">double</span> <span class="hljs-title">pi</span><span class="hljs-params">(<span class="hljs-type">int</span> n)</span> </span>&#123;<br>    <span class="hljs-type">double</span> res = <span class="hljs-number">1.0</span>;<br>    <span class="hljs-type">int</span> flag = <span class="hljs-number">-1</span>;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">1</span>; i &lt; n; ++i) &#123;<br>        res += flag * (<span class="hljs-number">1.0</span> / (<span class="hljs-number">2</span> * i + <span class="hljs-number">1</span>));<br>        flag *= <span class="hljs-number">-1</span>;<br>    &#125;<br>    <span class="hljs-keyword">return</span> res * <span class="hljs-number">4</span>;<br>    <span class="hljs-comment">/*</span><br><span class="hljs-comment">    	int m = 0;</span><br><span class="hljs-comment">    	double x, y;</span><br><span class="hljs-comment">    	srand(time(0));</span><br><span class="hljs-comment">    	for (int i = 0; i &lt; n; ++i) &#123;</span><br><span class="hljs-comment">    	    x = double(1.0*rand()/RAND_MAX);</span><br><span class="hljs-comment">    	    y = double(1.0*rand()/RAND_MAX);</span><br><span class="hljs-comment">    	    if (x*x+y*y &lt;= 1) ++m;</span><br><span class="hljs-comment">   		&#125;</span><br><span class="hljs-comment">    	return (double)m * 4 / n;</span><br><span class="hljs-comment">    */</span><br>&#125;<br><span class="hljs-comment">// GPU版本——规约——这个版本规约只能进行一次，对block级别的累加只能在CPU上执行</span><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">pi</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">double</span>* output, <span class="hljs-type">int</span> n)</span> </span>&#123;<br>    <span class="hljs-type">int</span> tid = blockIdx.x * blockDim.x + threadIdx.x;<br>    <span class="hljs-type">int</span> total_thread_num = blockDim.x * gridDim.x;<br><br>    <span class="hljs-type">double</span> res = <span class="hljs-number">0.0</span>;<br>    <span class="hljs-type">int</span> flag = <span class="hljs-number">-1</span>;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = tid; i &lt; n; i += total_thread_num) &#123;<br>        res += flag * (<span class="hljs-number">1.0</span> / (<span class="hljs-number">2</span> * i + <span class="hljs-number">1</span>));<br>        flag *= <span class="hljs-number">-1</span>;<br>    &#125;<br><br>    <span class="hljs-keyword">extern</span> __shared__ shm[];<br>    shm[threadIdx.x] = res;<br>    __syncthreads();<br><br>    <span class="hljs-comment">/*</span><br><span class="hljs-comment">    	srand(time(0));</span><br><span class="hljs-comment">    	double x = double(1.0*rand()/RAND_MAX);</span><br><span class="hljs-comment">    	double y = double(1.0*rand()/RAND_MAX);</span><br><span class="hljs-comment"></span><br><span class="hljs-comment">    	extern __shared__ shm[];</span><br><span class="hljs-comment">    	if (x*x+y*y &lt;= 1) &#123;</span><br><span class="hljs-comment">    		shm[threadIdx.x] = 1;</span><br><span class="hljs-comment">    	&#125; else &#123;</span><br><span class="hljs-comment">    		shm[threadIdx.x] = 0;</span><br><span class="hljs-comment">    	&#125;</span><br><span class="hljs-comment">    	__syncthreads();</span><br><span class="hljs-comment">    	...后面代码一样</span><br><span class="hljs-comment">    */</span><br><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = blockDim.x / <span class="hljs-number">2</span>; i &gt;= <span class="hljs-number">1</span>; i /= <span class="hljs-number">2</span>) &#123;<br>        <span class="hljs-keyword">if</span> (threadIdx.x &lt; i) &#123;<br>            shm[threadIdx.x] += shm[i + threadIdx.x];<br>        &#125;<br>        __syncthreads();<br>    &#125;<br>    <span class="hljs-keyword">if</span> (threadIdx.x == <span class="hljs-number">0</span>) &#123;<br>        output[blockIdx.x] = shm[<span class="hljs-number">0</span>];<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<h4 id="手撕前缀和（字节）">手撕前缀和（字节）</h4>
<h4 id="手撕矩阵转置">手撕矩阵转置</h4>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">cuda_transpose</span><span class="hljs-params">(<span class="hljs-type">int</span> *matrix,<span class="hljs-type">int</span> *tr_matrix,<span class="hljs-type">int</span> m,<span class="hljs-type">int</span> n)</span> </span>&#123;<br>	<span class="hljs-type">int</span> row = blockDim.y * blockIdx.y + threadIdx.y;<br>	<span class="hljs-type">int</span> col = blockDim.x * blockIdx.x + threadIdx.x;<br>	__shared__ <span class="hljs-type">int</span> smem_matrix[BLOCK_SIZE][BLOCK_SIZE];<br>	smem_matrix[threadIdx.y][threadIdx.x] = row &lt; m&amp;&amp; col &lt; n ? matrix[row*n+col] : <span class="hljs-number">0</span>;<br>	__syncthreads();<br>	<span class="hljs-keyword">if</span>(blockIdx.x * blockDim.x + threadIdx.y &lt; n &amp;&amp; threadIdx.x + blockIdx.y * blockDim.x &lt; m)<br>	tr_matrix[threadIdx.x+blockIdx.y*blockDim.x+m*(blockIdx.x*blockDim.x+threadIdx.y)] = smem_matrix[threadIdx.x][threadIdx.y];<br>&#125;<br></code></pre></td></tr></table></figure>
<h4 id="手撕COO、CSR（字节）">手撕COO、CSR（字节）</h4>
<h4 id="手撕快排">手撕快排</h4>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// CPU版本</span><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">quickSort</span><span class="hljs-params">(vector&lt;<span class="hljs-type">int</span>&gt;&amp; nums, <span class="hljs-type">int</span> start, <span class="hljs-type">int</span> end)</span> </span>&#123;<br>    <span class="hljs-keyword">if</span> (start &gt; end) <span class="hljs-keyword">return</span>;<br>    <span class="hljs-type">int</span> l = start, r = end;<br>    <span class="hljs-type">int</span> key = nums[l];<br>    <span class="hljs-keyword">while</span> (l &lt; r) &#123;<br>        <span class="hljs-keyword">while</span> (l &lt; r &amp;&amp; nums[r] &gt;= key) r--;<br>        <span class="hljs-keyword">if</span> (l &lt; r) nums[l] = nums[r];<br>        <span class="hljs-keyword">while</span> (l &lt; r &amp;&amp; nums[l] &lt; key) l++;<br>        <span class="hljs-keyword">if</span> (l &lt; r) nums[r] = nums[l];<br>    &#125;<br>    nums[l] = key;<br>    <span class="hljs-built_in">quickSort</span>(nums, start, l<span class="hljs-number">-1</span>);<br>    <span class="hljs-built_in">quickSort</span>(nums, l+<span class="hljs-number">1</span>, end);<br>    <span class="hljs-keyword">return</span>;<br>&#125;<br><br><span class="hljs-comment">// GPU版本</span><br><span class="hljs-comment">// GPU 架构 3.5 和 CUDA 5.0 引入了一个新特性，称为动态并行，动态并行允许内核中的线程从device上直接启动新内核，而无需将控制权交还给 CPU</span><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span> </span>&#123;<br>    ...<br>    quickSort&lt;&lt;&lt;<span class="hljs-number">1</span>, <span class="hljs-number">1</span>&gt;&gt;&gt;(nums, start, end);<br>&#125;<br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">quickSort</span><span class="hljs-params">(vector&lt;<span class="hljs-type">int</span>&gt;&amp; nums, <span class="hljs-type">int</span> start, <span class="hljs-type">int</span> end <span class="hljs-comment">/*, int depth*/</span>)</span> </span>&#123;<br>    <span class="hljs-comment">/*</span><br><span class="hljs-comment">    当递归的深度大于设定的MAX_DEPTH或者待排序的数组长度小于设定的阈值，直接调用简单选择排序</span><br><span class="hljs-comment">    我感觉真实面试的时候可以先不写这玩意，如果面试官要求了再说</span><br><span class="hljs-comment">    if (depth &gt;= MAX_DEPTH || right - left &lt;= INSERTION_SORT) &#123;</span><br><span class="hljs-comment">        selection_sort(nums, left, right);</span><br><span class="hljs-comment">        return;</span><br><span class="hljs-comment">    &#125;</span><br><span class="hljs-comment">    */</span><br><br>    <span class="hljs-type">int</span> l = start, r = end;<br>    <span class="hljs-type">int</span> key = nums[l];<br>    <span class="hljs-keyword">while</span> (l &lt; r) &#123;<br>        <span class="hljs-keyword">while</span> (l &lt; r &amp;&amp; nums[r] &gt;= key) r--;<br>        <span class="hljs-keyword">if</span> (l &lt; r) nums[l] = nums[r];<br>        <span class="hljs-keyword">while</span> (l &lt; r &amp;&amp; nums[l] &lt; key) l++;<br>        <span class="hljs-keyword">if</span> (l &lt; r) nums[r] = nums[l];<br>    &#125;<br>    nums[l] = key;<br><br>    cudaStream_t l_stream, r_stream;<br>    <span class="hljs-built_in">cudaStreamCreateWithFlags</span>(&amp;l_stream, cudaStreamNonBlocking);<br>    <span class="hljs-built_in">cudaStreamCreateWithFlags</span>(&amp;r_stream, cudaStreamNonBlocking);<br>    quickSort&lt;&lt;&lt;<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, l_stream&gt;&gt;&gt;(nums, start, l<span class="hljs-number">-1</span>);<br>    quickSort&lt;&lt;&lt;<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, r_stream&gt;&gt;&gt;(nums, l+<span class="hljs-number">1</span>, end);<br>    <span class="hljs-built_in">cudaStreamDestroy</span>(l_stream);<br>    <span class="hljs-built_in">cudaStreamDestroy</span>(r_stream);<br>&#125;<br></code></pre></td></tr></table></figure>
<h4 id="手撕智能指针（hda）">手撕智能指针（hda）</h4>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">/*</span><br><span class="hljs-comment">构造函数</span><br><span class="hljs-comment">析构函数</span><br><span class="hljs-comment">拷贝构造函数</span><br><span class="hljs-comment">拷贝赋值函数（赋值构造函数）</span><br><span class="hljs-comment">operator * ()</span><br><span class="hljs-comment">operator -&gt; ()</span><br><span class="hljs-comment">*/</span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;iostream&gt;</span></span><br><br><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> std;<br><br><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">template</span> T&gt;<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">my_shared_ptr</span> &#123;<br><span class="hljs-keyword">private</span>:<br>    T* _ptr;<br>    <span class="hljs-type">int</span>* _count;<br><br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-built_in">my_shared_ptr</span>(T* ptr = <span class="hljs-literal">nullptr</span>) :_ptr(ptr) &#123;<br>        <span class="hljs-keyword">if</span> (_ptr) &#123;<br>            _count = <span class="hljs-keyword">new</span> <span class="hljs-built_in">int</span>(<span class="hljs-number">1</span>);<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            _count = <span class="hljs-keyword">new</span> <span class="hljs-built_in">int</span>(<span class="hljs-number">0</span>);<br>        &#125;<br>    &#125;<br><br>    ~<span class="hljs-built_in">my_shared_ptr</span>() &#123;<br>        <span class="hljs-keyword">if</span> (<span class="hljs-keyword">this</span>-&gt;_ptr) &#123;<br>            <span class="hljs-keyword">if</span> (--(*<span class="hljs-keyword">this</span>-&gt;count) == <span class="hljs-number">0</span>) &#123;<br>            	<span class="hljs-keyword">delete</span> <span class="hljs-keyword">this</span>-&gt;_ptr;<br>            	<span class="hljs-keyword">delete</span> <span class="hljs-keyword">this</span>-&gt;_count;<br>        	&#125;<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            <span class="hljs-keyword">delete</span> <span class="hljs-keyword">this</span>-&gt;count;<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-built_in">my_shared_ptr</span>(<span class="hljs-type">const</span> my_shared_ptr&amp; ptr) &#123;<br>        <span class="hljs-keyword">if</span> (<span class="hljs-keyword">this</span> != &amp;ptr) &#123;<br>            <span class="hljs-keyword">this</span>-&gt;_ptr = ptr._ptr;<br>            <span class="hljs-keyword">this</span>-&gt;_count = ptr._count;<br><br>            ++(*<span class="hljs-keyword">this</span>-&gt;_count);<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-comment">// 如果当前指针count为1，那么在把指针指向新的对象前必须把当前对象的空间释放掉</span><br>    <span class="hljs-comment">// 这是拷贝赋值，不是移动赋值，移动需要传右值引用&amp;&amp;</span><br>    my_shared_ptr&amp; <span class="hljs-keyword">operator</span> = (<span class="hljs-type">const</span> my_shared_ptr&amp; ptr) &#123;<br>        <span class="hljs-keyword">if</span> (<span class="hljs-keyword">this</span>-&gt;_ptr == ptr._ptr) &#123;<br>            <span class="hljs-keyword">return</span> *<span class="hljs-keyword">this</span>;<br>        &#125;<br>        <span class="hljs-keyword">if</span> (<span class="hljs-keyword">this</span>-&gt;_ptr) &#123;<br>            <span class="hljs-keyword">if</span> (--(*<span class="hljs-keyword">this</span>-&gt;count) == <span class="hljs-number">0</span>) &#123;<br>                <span class="hljs-keyword">delete</span> <span class="hljs-keyword">this</span>-&gt;_ptr;<br>                <span class="hljs-keyword">delete</span> <span class="hljs-keyword">this</span>-&gt;_count;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">this</span>-&gt;_ptr = ptr._ptr;<br>        <span class="hljs-keyword">this</span>-&gt;_count = ptr._count;<br>        ++(*<span class="hljs-keyword">this</span>-&gt;_count);<br>        <span class="hljs-keyword">return</span> *<span class="hljs-keyword">this</span>;<br>    &#125;<br><br>    T&amp; <span class="hljs-keyword">operator</span> * () &#123;<br>        <span class="hljs-keyword">if</span> (<span class="hljs-keyword">this</span>-&gt;_ptr) <span class="hljs-keyword">return</span> *(<span class="hljs-keyword">this</span>-&gt;_ptr);<br>    &#125;<br><br>    T* <span class="hljs-keyword">operator</span> -&gt; () &#123;<br>        <span class="hljs-keyword">if</span> (<span class="hljs-keyword">this</span>-&gt;_ptr) <span class="hljs-keyword">return</span> <span class="hljs-keyword">this</span>-&gt;_ptr;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure>
<h3 id="谈offer阶段准备的问题">谈offer阶段准备的问题</h3>
<ul>
<li>
<p>基本工资、签字费</p>
</li>
<li>
<p>几险几金、社保基数</p>
</li>
<li>
<p>公积金比例多少，按什么基数算的（是月薪的比例还是总包的比例）</p>
</li>
<li>
<p>每个月的补贴有哪些（房补、餐补、话费、交通、保密等）</p>
</li>
<li>
<p>年终奖多少，跟绩效什么对应关系，平均多少</p>
</li>
<li>
<blockquote>
<p>有没有政府补贴</p>
</blockquote>
</li>
<li>
<p>试用期几个月，试用期期间工资怎么算</p>
</li>
<li>
<p>有没有食堂、健身房</p>
</li>
<li>
<p>加班情况怎么样（晚上有没有免费夜宵与打车报销），有没有加班费</p>
</li>
<li>
<blockquote>
<p>职级体系</p>
</blockquote>
</li>
<li>
<p>调薪情况</p>
</li>
<li>
<p>每天打卡时间什么时候（每个月异常考勤怎么处理）</p>
</li>
<li>
<blockquote>
<p>稳定性怎么样（部门近期离职率怎么样）</p>
</blockquote>
</li>
<li>
<blockquote>
<p>交通方不方便</p>
</blockquote>
</li>
<li>
<p>入职体检什么时候，什么标准，自己查（对医院级别有没有要求）还是公司统一组织，没过有什么补救措施</p>
</li>
<li>
<p>offer考虑时间</p>
</li>
<li>
<p>违约金多少</p>
</li>
</ul>


  

</article>



              </div>
            </div>
          </div>
        </div>
      </div>
    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> &amp;&amp; <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> <i class="iconfont icon-love"></i> <a href="https://www.bilibili.com/video/BV1r54y1B7sT" target="_blank" rel="nofollow noopener"><span>RuiXin</span></a> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="busuanzi_container_site_pv" style="display: none">
        总访问量 
        <span id="busuanzi_value_site_pv"></span>
         次
      </span>
    
    
      <span id="busuanzi_container_site_uv" style="display: none">
        总访客数 
        <span id="busuanzi_value_site_uv"></span>
         人
      </span>
    
    
  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>




  
<script src="/page.js"></script>



<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
